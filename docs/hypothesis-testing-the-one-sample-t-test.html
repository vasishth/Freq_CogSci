<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2.5 Hypothesis testing: The one sample t-test | Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction</title>
  <meta name="description" content="Linear Mixed Models for Linguistics and Psychology: A Comprehensive Introduction" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="2.5 Hypothesis testing: The one sample t-test | Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://github.com/vasishth/Freq_CogSci" />
  <meta property="og:image" content="https://github.com/vasishth/Freq_CogSci/images/temporarycover.jpg" />
  <meta property="og:description" content="Linear Mixed Models for Linguistics and Psychology: A Comprehensive Introduction" />
  <meta name="github-repo" content="https://github.com/vasishth/Freq_CogSci" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2.5 Hypothesis testing: The one sample t-test | Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction" />
  
  <meta name="twitter:description" content="Linear Mixed Models for Linguistics and Psychology: A Comprehensive Introduction" />
  <meta name="twitter:image" content="https://github.com/vasishth/Freq_CogSci/images/temporarycover.jpg" />

<meta name="author" content="Shravan Vasishth, Daniel Schad, Audrey Bürki, Reinhold Kliegl" />


<meta name="date" content="2021-12-19" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="the-confidence-interval-and-what-its-good-for.html"/>
<link rel="next" href="the-two-sample-t-test-vs.-the-paired-t-test.html"/>
<script src="libs/header-attrs/header-attrs.js"></script>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<script src="libs/kePrint/kePrint.js"></script>
<link href="libs/lightable/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Linear Mixed Models in Linguistics and Psychology</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="" data-path="how-to-read-this-book.html"><a href="how-to-read-this-book.html"><i class="fa fa-check"></i>How to read this book</a></li>
<li class="chapter" data-level="" data-path="online-materials.html"><a href="online-materials.html"><i class="fa fa-check"></i>Online materials</a></li>
<li class="chapter" data-level="" data-path="software-needed.html"><a href="software-needed.html"><i class="fa fa-check"></i>Software needed</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="part"><span><b>I Foundational ideas</b></span></li>
<li class="chapter" data-level="1" data-path="some-important-facts-about-distributions.html"><a href="some-important-facts-about-distributions.html"><i class="fa fa-check"></i><b>1</b> Some important facts about distributions</a>
<ul>
<li class="chapter" data-level="1.1" data-path="discrete-random-variables-an-example-using-the-binomial-distribution.html"><a href="discrete-random-variables-an-example-using-the-binomial-distribution.html"><i class="fa fa-check"></i><b>1.1</b> Discrete random variables: An example using the Binomial distribution</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="discrete-random-variables-an-example-using-the-binomial-distribution.html"><a href="discrete-random-variables-an-example-using-the-binomial-distribution.html#the-mean-and-variance-of-the-binomial-distribution"><i class="fa fa-check"></i><b>1.1.1</b> The mean and variance of the Binomial distribution</a></li>
<li class="chapter" data-level="1.1.2" data-path="discrete-random-variables-an-example-using-the-binomial-distribution.html"><a href="discrete-random-variables-an-example-using-the-binomial-distribution.html#what-information-does-a-probability-distribution-provide"><i class="fa fa-check"></i><b>1.1.2</b> What information does a probability distribution provide?</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="continuous-random-variables-an-example-using-the-normal-distribution.html"><a href="continuous-random-variables-an-example-using-the-normal-distribution.html"><i class="fa fa-check"></i><b>1.2</b> Continuous random variables: An example using the Normal distribution</a></li>
<li class="chapter" data-level="1.3" data-path="other-common-distributions.html"><a href="other-common-distributions.html"><i class="fa fa-check"></i><b>1.3</b> Other common distributions</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="other-common-distributions.html"><a href="other-common-distributions.html#the-standard-normal-mathitnormalmu0sigma1"><i class="fa fa-check"></i><b>1.3.1</b> The standard normal: <span class="math inline">\(\mathit{normal}(\mu=0,\sigma=1)\)</span></a></li>
<li class="chapter" data-level="1.3.2" data-path="other-common-distributions.html"><a href="other-common-distributions.html#the-uniform-distribution"><i class="fa fa-check"></i><b>1.3.2</b> The uniform distribution</a></li>
<li class="chapter" data-level="1.3.3" data-path="other-common-distributions.html"><a href="other-common-distributions.html#the-chi-square-distribution"><i class="fa fa-check"></i><b>1.3.3</b> The Chi-square distribution</a></li>
<li class="chapter" data-level="1.3.4" data-path="other-common-distributions.html"><a href="other-common-distributions.html#the-t-distribution"><i class="fa fa-check"></i><b>1.3.4</b> The t-distribution</a></li>
<li class="chapter" data-level="1.3.5" data-path="other-common-distributions.html"><a href="other-common-distributions.html#the-f-distribution"><i class="fa fa-check"></i><b>1.3.5</b> The F distribution</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="bivariate-and-multivariate-distributions.html"><a href="bivariate-and-multivariate-distributions.html"><i class="fa fa-check"></i><b>1.4</b> Bivariate and multivariate distributions</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="bivariate-and-multivariate-distributions.html"><a href="bivariate-and-multivariate-distributions.html#example-1-discrete-bivariate-distributions"><i class="fa fa-check"></i><b>1.4.1</b> Example 1: Discrete bivariate distributions</a></li>
<li class="chapter" data-level="1.4.2" data-path="bivariate-and-multivariate-distributions.html"><a href="bivariate-and-multivariate-distributions.html#example-2-continuous-bivariate-distributions"><i class="fa fa-check"></i><b>1.4.2</b> Example 2: Continuous bivariate distributions</a></li>
<li class="chapter" data-level="1.4.3" data-path="bivariate-and-multivariate-distributions.html"><a href="bivariate-and-multivariate-distributions.html#generate-simulated-bivariate-multivariate-data"><i class="fa fa-check"></i><b>1.4.3</b> Generate simulated bivariate (multivariate) data</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="likelihood-and-maximum-likelihood-estimation.html"><a href="likelihood-and-maximum-likelihood-estimation.html"><i class="fa fa-check"></i><b>1.5</b> Likelihood and maximum likelihood estimation</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="likelihood-and-maximum-likelihood-estimation.html"><a href="likelihood-and-maximum-likelihood-estimation.html#the-importance-of-the-mle"><i class="fa fa-check"></i><b>1.5.1</b> The importance of the MLE</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="useful-r-functions-relating-to-univariate-distributions.html"><a href="useful-r-functions-relating-to-univariate-distributions.html"><i class="fa fa-check"></i><b>1.6</b> Useful R functions relating to univariate distributions</a></li>
<li class="chapter" data-level="1.7" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.7</b> Summary</a></li>
<li class="chapter" data-level="1.8" data-path="further-reading.html"><a href="further-reading.html"><i class="fa fa-check"></i><b>1.8</b> Further reading</a></li>
<li class="chapter" data-level="1.9" data-path="sec:Foundationsexercises.html"><a href="sec:Foundationsexercises.html"><i class="fa fa-check"></i><b>1.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="hypothetical-repeated-sampling-and-the-t-test.html"><a href="hypothetical-repeated-sampling-and-the-t-test.html"><i class="fa fa-check"></i><b>2</b> Hypothetical repeated sampling and the t-test</a>
<ul>
<li class="chapter" data-level="2.1" data-path="some-terminology-surrounding-typical-experiment-designs-in-linguistics-and-psychology.html"><a href="some-terminology-surrounding-typical-experiment-designs-in-linguistics-and-psychology.html"><i class="fa fa-check"></i><b>2.1</b> Some terminology surrounding typical experiment designs in linguistics and psychology</a></li>
<li class="chapter" data-level="2.2" data-path="the-central-limit-theorem-using-simulation.html"><a href="the-central-limit-theorem-using-simulation.html"><i class="fa fa-check"></i><b>2.2</b> The central limit theorem using simulation</a></li>
<li class="chapter" data-level="2.3" data-path="three-examples-of-the-sampling-distribution.html"><a href="three-examples-of-the-sampling-distribution.html"><i class="fa fa-check"></i><b>2.3</b> Three examples of the sampling distribution</a></li>
<li class="chapter" data-level="2.4" data-path="the-confidence-interval-and-what-its-good-for.html"><a href="the-confidence-interval-and-what-its-good-for.html"><i class="fa fa-check"></i><b>2.4</b> The confidence interval, and what it’s good for</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="the-confidence-interval-and-what-its-good-for.html"><a href="the-confidence-interval-and-what-its-good-for.html#confidence-interals-are-often-misinterpreted"><i class="fa fa-check"></i><b>2.4.1</b> Confidence interals are often misinterpreted</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html"><i class="fa fa-check"></i><b>2.5</b> Hypothesis testing: The one sample t-test</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#the-one-sample-t-test"><i class="fa fa-check"></i><b>2.5.1</b> The one-sample t-test</a></li>
<li class="chapter" data-level="2.5.2" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#type-i-ii-error-and-power"><i class="fa fa-check"></i><b>2.5.2</b> Type I, II error, and power</a></li>
<li class="chapter" data-level="2.5.3" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#how-to-compute-power-for-the-one-sample-t-test"><i class="fa fa-check"></i><b>2.5.3</b> How to compute power for the one-sample t-test</a></li>
<li class="chapter" data-level="2.5.4" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#the-p-value"><i class="fa fa-check"></i><b>2.5.4</b> The p-value</a></li>
<li class="chapter" data-level="2.5.5" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#the-distribution-of-the-p-value-under-the-null-hypothesis"><i class="fa fa-check"></i><b>2.5.5</b> The distribution of the p-value under the null hypothesis</a></li>
<li class="chapter" data-level="2.5.6" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#type-m-and-s-error-in-the-face-of-low-power"><i class="fa fa-check"></i><b>2.5.6</b> Type M and S error in the face of low power</a></li>
<li class="chapter" data-level="2.5.7" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#searching-for-significance"><i class="fa fa-check"></i><b>2.5.7</b> Searching for significance</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="the-two-sample-t-test-vs.-the-paired-t-test.html"><a href="the-two-sample-t-test-vs.-the-paired-t-test.html"><i class="fa fa-check"></i><b>2.6</b> The two-sample t-test vs. the paired t-test</a></li>
<li class="chapter" data-level="2.7" data-path="using-paired-t-tests-in-complex-factorial-designs.html"><a href="using-paired-t-tests-in-complex-factorial-designs.html"><i class="fa fa-check"></i><b>2.7</b> Using paired t-tests in complex factorial designs</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="using-paired-t-tests-in-complex-factorial-designs.html"><a href="using-paired-t-tests-in-complex-factorial-designs.html#analyzing-a-2times-2-repeated-measures-design-using-paired-t-tests"><i class="fa fa-check"></i><b>2.7.1</b> Analyzing a <span class="math inline">\(2\times 2\)</span> repeated measures design using paired t-tests</a></li>
<li class="chapter" data-level="2.7.2" data-path="using-paired-t-tests-in-complex-factorial-designs.html"><a href="using-paired-t-tests-in-complex-factorial-designs.html#a-complication-with-multiple-t-tests-inflation-of-type-i-error-probability"><i class="fa fa-check"></i><b>2.7.2</b> A complication with multiple t-tests: Inflation of Type I error probability</a></li>
<li class="chapter" data-level="2.7.3" data-path="using-paired-t-tests-in-complex-factorial-designs.html"><a href="using-paired-t-tests-in-complex-factorial-designs.html#analyzing-a-2times-2times-2-repeated-measures-design-using-paired-t-tests"><i class="fa fa-check"></i><b>2.7.3</b> Analyzing a <span class="math inline">\(2\times 2\times 2\)</span> repeated measures design using paired t-tests</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="common-mistakes-involving-the-paired-t-test.html"><a href="common-mistakes-involving-the-paired-t-test.html"><i class="fa fa-check"></i><b>2.8</b> Common mistakes involving the (paired) t-test</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="common-mistakes-involving-the-paired-t-test.html"><a href="common-mistakes-involving-the-paired-t-test.html#ignoring-the-independence-assumption"><i class="fa fa-check"></i><b>2.8.1</b> Ignoring the independence assumption</a></li>
<li class="chapter" data-level="2.8.2" data-path="common-mistakes-involving-the-paired-t-test.html"><a href="common-mistakes-involving-the-paired-t-test.html#doing-a-by-subjects-and-by-items-paired-t-test-is-generally-dangerous"><i class="fa fa-check"></i><b>2.8.2</b> Doing a by-subjects and by-items paired t-test is generally dangerous</a></li>
<li class="chapter" data-level="2.8.3" data-path="common-mistakes-involving-the-paired-t-test.html"><a href="common-mistakes-involving-the-paired-t-test.html#the-difference-between-a-significant-and-a-non-significant-result-need-not-itself-be-significant"><i class="fa fa-check"></i><b>2.8.3</b> The difference between a significant and a non-significant result need not itself be significant</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>2.9</b> Summary</a></li>
<li class="chapter" data-level="2.10" data-path="further-readings.html"><a href="further-readings.html"><i class="fa fa-check"></i><b>2.10</b> Further readings</a></li>
<li class="chapter" data-level="2.11" data-path="sec:SamplingDistrnexercises.html"><a href="sec:SamplingDistrnexercises.html"><i class="fa fa-check"></i><b>2.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-models-and-linear-mixed-models.html"><a href="linear-models-and-linear-mixed-models.html"><i class="fa fa-check"></i><b>3</b> Linear models and linear mixed models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="from-the-t-test-to-the-linear-mixed-model.html"><a href="from-the-t-test-to-the-linear-mixed-model.html"><i class="fa fa-check"></i><b>3.1</b> From the t-test to the linear (mixed) model</a></li>
<li class="chapter" data-level="3.2" data-path="sum-coding.html"><a href="sum-coding.html"><i class="fa fa-check"></i><b>3.2</b> Sum coding</a></li>
<li class="chapter" data-level="3.3" data-path="checking-model-assumptions.html"><a href="checking-model-assumptions.html"><i class="fa fa-check"></i><b>3.3</b> Checking model assumptions</a></li>
<li class="chapter" data-level="3.4" data-path="from-the-paired-t-test-to-the-linear-mixed-model.html"><a href="from-the-paired-t-test-to-the-linear-mixed-model.html"><i class="fa fa-check"></i><b>3.4</b> From the paired t-test to the linear mixed model</a></li>
<li class="chapter" data-level="3.5" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>3.5</b> Linear mixed models</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#model-type-1-varying-intercepts"><i class="fa fa-check"></i><b>3.5.1</b> Model type 1: Varying intercepts</a></li>
<li class="chapter" data-level="3.5.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#the-formal-statement-of-the-varying-intercepts-model"><i class="fa fa-check"></i><b>3.5.2</b> The formal statement of the varying intercepts model</a></li>
<li class="chapter" data-level="3.5.3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#model-type-2-varying-intercepts-and-slopes-without-a-correlation"><i class="fa fa-check"></i><b>3.5.3</b> Model type 2: Varying intercepts and slopes, without a correlation</a></li>
<li class="chapter" data-level="3.5.4" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#model-type-3-varying-intercepts-and-varying-slopes-with-correlation"><i class="fa fa-check"></i><b>3.5.4</b> Model type 3: Varying intercepts and varying slopes, with correlation</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="shrinkage-in-linear-mixed-models.html"><a href="shrinkage-in-linear-mixed-models.html"><i class="fa fa-check"></i><b>3.6</b> Shrinkage in linear mixed models</a></li>
<li class="chapter" data-level="3.7" data-path="summary-2.html"><a href="summary-2.html"><i class="fa fa-check"></i><b>3.7</b> Summary</a></li>
<li class="chapter" data-level="3.8" data-path="further-reading-1.html"><a href="further-reading-1.html"><i class="fa fa-check"></i><b>3.8</b> Further reading</a></li>
<li class="chapter" data-level="3.9" data-path="sec:LMExercises1.html"><a href="sec:LMExercises1.html"><i class="fa fa-check"></i><b>3.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="hypothesis-testing-using-the-likelihood-ratio-test.html"><a href="hypothesis-testing-using-the-likelihood-ratio-test.html"><i class="fa fa-check"></i><b>4</b> Hypothesis testing using the likelihood ratio test</a>
<ul>
<li class="chapter" data-level="4.1" data-path="the-likelihood-ratio-test-the-theory.html"><a href="the-likelihood-ratio-test-the-theory.html"><i class="fa fa-check"></i><b>4.1</b> The likelihood ratio test: The theory</a></li>
<li class="chapter" data-level="4.2" data-path="a-practical-example-using-simulated-data.html"><a href="a-practical-example-using-simulated-data.html"><i class="fa fa-check"></i><b>4.2</b> A practical example using simulated data</a></li>
<li class="chapter" data-level="4.3" data-path="a-real-life-example-the-english-relative-clause-data.html"><a href="a-real-life-example-the-english-relative-clause-data.html"><i class="fa fa-check"></i><b>4.3</b> A real-life example: The English relative clause data</a></li>
<li class="chapter" data-level="4.4" data-path="summary-3.html"><a href="summary-3.html"><i class="fa fa-check"></i><b>4.4</b> Summary</a></li>
<li class="chapter" data-level="4.5" data-path="further-reading-2.html"><a href="further-reading-2.html"><i class="fa fa-check"></i><b>4.5</b> Further reading</a></li>
<li class="chapter" data-level="4.6" data-path="sec:HypTestExercises.html"><a href="sec:HypTestExercises.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch:LMtheory.html"><a href="ch:LMtheory.html"><i class="fa fa-check"></i><b>5</b> Linear modeling theory</a>
<ul>
<li class="chapter" data-level="5.1" data-path="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html"><a href="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html"><i class="fa fa-check"></i><b>5.1</b> A quick review of some basic concepts in matrix algebra</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html"><a href="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html#matrix-addition-subtraction-and-multiplication"><i class="fa fa-check"></i><b>5.1.1</b> Matrix addition, subtraction, and multiplication</a></li>
<li class="chapter" data-level="5.1.2" data-path="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html"><a href="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html#diagonal-matrix-and-identity-matrix"><i class="fa fa-check"></i><b>5.1.2</b> Diagonal matrix and identity matrix</a></li>
<li class="chapter" data-level="5.1.3" data-path="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html"><a href="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html#powers-of-matrices"><i class="fa fa-check"></i><b>5.1.3</b> Powers of matrices</a></li>
<li class="chapter" data-level="5.1.4" data-path="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html"><a href="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html#inverse-of-a-matrix"><i class="fa fa-check"></i><b>5.1.4</b> Inverse of a matrix</a></li>
<li class="chapter" data-level="5.1.5" data-path="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html"><a href="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html#linear-independence-and-rank"><i class="fa fa-check"></i><b>5.1.5</b> Linear independence, and rank</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="the-essentials-of-linear-modeling-theory.html"><a href="the-essentials-of-linear-modeling-theory.html"><i class="fa fa-check"></i><b>5.2</b> The essentials of linear modeling theory</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="the-essentials-of-linear-modeling-theory.html"><a href="the-essentials-of-linear-modeling-theory.html#least-squares-estimation-geometric-argument"><i class="fa fa-check"></i><b>5.2.1</b> Least squares estimation: Geometric argument</a></li>
<li class="chapter" data-level="5.2.2" data-path="the-essentials-of-linear-modeling-theory.html"><a href="the-essentials-of-linear-modeling-theory.html#the-expectation-and-variance-of-the-parameters-beta"><i class="fa fa-check"></i><b>5.2.2</b> The expectation and variance of the parameters beta</a></li>
<li class="chapter" data-level="5.2.3" data-path="the-essentials-of-linear-modeling-theory.html"><a href="the-essentials-of-linear-modeling-theory.html#hypothesis-testing-using-analysis-of-variance-anova"><i class="fa fa-check"></i><b>5.2.3</b> Hypothesis testing using Analysis of variance (ANOVA)</a></li>
<li class="chapter" data-level="5.2.4" data-path="the-essentials-of-linear-modeling-theory.html"><a href="the-essentials-of-linear-modeling-theory.html#some-further-important-topics-in-linear-modeling"><i class="fa fa-check"></i><b>5.2.4</b> Some further important topics in linear modeling</a></li>
<li class="chapter" data-level="5.2.5" data-path="the-essentials-of-linear-modeling-theory.html"><a href="the-essentials-of-linear-modeling-theory.html#generalized-linear-models"><i class="fa fa-check"></i><b>5.2.5</b> Generalized linear models</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="summary-4.html"><a href="summary-4.html"><i class="fa fa-check"></i><b>5.3</b> Summary</a></li>
<li class="chapter" data-level="5.4" data-path="further-reading-3.html"><a href="further-reading-3.html"><i class="fa fa-check"></i><b>5.4</b> Further reading</a></li>
<li class="chapter" data-level="5.5" data-path="sec:LMExercises2.html"><a href="sec:LMExercises2.html"><i class="fa fa-check"></i><b>5.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch:contr.html"><a href="ch:contr.html"><i class="fa fa-check"></i><b>6</b> Contrast coding</a>
<ul>
<li class="chapter" data-level="6.1" data-path="basic-concepts-illustrated-using-a-two-level-factor.html"><a href="basic-concepts-illustrated-using-a-two-level-factor.html"><i class="fa fa-check"></i><b>6.1</b> Basic concepts illustrated using a two-level factor</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="basic-concepts-illustrated-using-a-two-level-factor.html"><a href="basic-concepts-illustrated-using-a-two-level-factor.html#treatmentcontrasts"><i class="fa fa-check"></i><b>6.1.1</b> Default contrast coding: Treatment contrasts</a></li>
<li class="chapter" data-level="6.1.2" data-path="basic-concepts-illustrated-using-a-two-level-factor.html"><a href="basic-concepts-illustrated-using-a-two-level-factor.html#inverseMatrix"><i class="fa fa-check"></i><b>6.1.2</b> Defining hypotheses</a></li>
<li class="chapter" data-level="6.1.3" data-path="basic-concepts-illustrated-using-a-two-level-factor.html"><a href="basic-concepts-illustrated-using-a-two-level-factor.html#effectcoding"><i class="fa fa-check"></i><b>6.1.3</b> Sum contrasts</a></li>
<li class="chapter" data-level="6.1.4" data-path="basic-concepts-illustrated-using-a-two-level-factor.html"><a href="basic-concepts-illustrated-using-a-two-level-factor.html#sec:cellMeans"><i class="fa fa-check"></i><b>6.1.4</b> Cell means parameterization and posterior comparisons</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html"><a href="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html"><i class="fa fa-check"></i><b>6.2</b> The hypothesis matrix illustrated with a three-level factor</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html"><a href="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html#sumcontrasts"><i class="fa fa-check"></i><b>6.2.1</b> Sum contrasts</a></li>
<li class="chapter" data-level="6.2.2" data-path="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html"><a href="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html#the-hypothesis-matrix"><i class="fa fa-check"></i><b>6.2.2</b> The hypothesis matrix</a></li>
<li class="chapter" data-level="6.2.3" data-path="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html"><a href="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html#generating-contrasts-the-hypr-package"><i class="fa fa-check"></i><b>6.2.3</b> Generating contrasts: The <code>hypr</code> package</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="sec:4levelFactor.html"><a href="sec:4levelFactor.html"><i class="fa fa-check"></i><b>6.3</b> Further examples of contrasts illustrated with a factor with four levels</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="sec:4levelFactor.html"><a href="sec:4levelFactor.html#repeatedcontrasts"><i class="fa fa-check"></i><b>6.3.1</b> Repeated contrasts</a></li>
<li class="chapter" data-level="6.3.2" data-path="sec:4levelFactor.html"><a href="sec:4levelFactor.html#contrasts-in-linear-regression-analysis-the-design-or-model-matrix"><i class="fa fa-check"></i><b>6.3.2</b> Contrasts in linear regression analysis: The design or model matrix</a></li>
<li class="chapter" data-level="6.3.3" data-path="sec:4levelFactor.html"><a href="sec:4levelFactor.html#polynomialContrasts"><i class="fa fa-check"></i><b>6.3.3</b> Polynomial contrasts</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="nonOrthogonal.html"><a href="nonOrthogonal.html"><i class="fa fa-check"></i><b>6.4</b> What makes a good set of contrasts?</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="nonOrthogonal.html"><a href="nonOrthogonal.html#centered-contrasts"><i class="fa fa-check"></i><b>6.4.1</b> Centered contrasts</a></li>
<li class="chapter" data-level="6.4.2" data-path="nonOrthogonal.html"><a href="nonOrthogonal.html#orthogonal-contrasts"><i class="fa fa-check"></i><b>6.4.2</b> Orthogonal contrasts</a></li>
<li class="chapter" data-level="6.4.3" data-path="nonOrthogonal.html"><a href="nonOrthogonal.html#the-role-of-the-intercept-in-non-centered-contrasts"><i class="fa fa-check"></i><b>6.4.3</b> The role of the intercept in non-centered contrasts</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="summary-5.html"><a href="summary-5.html"><i class="fa fa-check"></i><b>6.5</b> Summary</a></li>
<li class="chapter" data-level="6.6" data-path="further-reading-4.html"><a href="further-reading-4.html"><i class="fa fa-check"></i><b>6.6</b> Further reading</a></li>
<li class="chapter" data-level="6.7" data-path="sec:Contrastsexercises.html"><a href="sec:Contrastsexercises.html"><i class="fa fa-check"></i><b>6.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch:coding2x2.html"><a href="ch:coding2x2.html"><i class="fa fa-check"></i><b>7</b> Contrast coding for designs with two predictor variables</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec:MR:ANOVA.html"><a href="sec:MR:ANOVA.html"><i class="fa fa-check"></i><b>7.1</b> Contrast coding in a factorial 2 x 2 design</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="sec:MR:ANOVA.html"><a href="sec:MR:ANOVA.html#the-difference-between-an-anova-and-a-multiple-regression"><i class="fa fa-check"></i><b>7.1.1</b> The difference between an ANOVA and a multiple regression</a></li>
<li class="chapter" data-level="7.1.2" data-path="sec:MR:ANOVA.html"><a href="sec:MR:ANOVA.html#nestedEffects"><i class="fa fa-check"></i><b>7.1.2</b> Nested effects</a></li>
<li class="chapter" data-level="7.1.3" data-path="sec:MR:ANOVA.html"><a href="sec:MR:ANOVA.html#interactions-between-contrasts"><i class="fa fa-check"></i><b>7.1.3</b> Interactions between contrasts</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="sec:contrast:covariate.html"><a href="sec:contrast:covariate.html"><i class="fa fa-check"></i><b>7.2</b> One factor and one covariate</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="sec:contrast:covariate.html"><a href="sec:contrast:covariate.html#estimating-a-group-difference-and-controlling-for-a-covariate"><i class="fa fa-check"></i><b>7.2.1</b> Estimating a group-difference and controlling for a covariate</a></li>
<li class="chapter" data-level="7.2.2" data-path="sec:contrast:covariate.html"><a href="sec:contrast:covariate.html#estimating-differences-in-slopes"><i class="fa fa-check"></i><b>7.2.2</b> Estimating differences in slopes</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="sec:interactions:NLM.html"><a href="sec:interactions:NLM.html"><i class="fa fa-check"></i><b>7.3</b> Interactions in generalized linear models (with non-linear link functions)</a></li>
<li class="chapter" data-level="7.4" data-path="summary-6.html"><a href="summary-6.html"><i class="fa fa-check"></i><b>7.4</b> Summary</a></li>
<li class="chapter" data-level="7.5" data-path="sec:Contrasts2x2exercises.html"><a href="sec:Contrasts2x2exercises.html"><i class="fa fa-check"></i><b>7.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="using-simulation-to-understand-your-model.html"><a href="using-simulation-to-understand-your-model.html"><i class="fa fa-check"></i><b>8</b> Using simulation to understand your model</a>
<ul>
<li class="chapter" data-level="8.1" data-path="a-reminder-the-maximal-linear-mixed-model.html"><a href="a-reminder-the-maximal-linear-mixed-model.html"><i class="fa fa-check"></i><b>8.1</b> A reminder: The maximal linear mixed model</a></li>
<li class="chapter" data-level="8.2" data-path="obtain-estimates-from-a-previous-study.html"><a href="obtain-estimates-from-a-previous-study.html"><i class="fa fa-check"></i><b>8.2</b> Obtain estimates from a previous study</a></li>
<li class="chapter" data-level="8.3" data-path="decide-on-a-range-of-plausible-values-of-the-effect-size.html"><a href="decide-on-a-range-of-plausible-values-of-the-effect-size.html"><i class="fa fa-check"></i><b>8.3</b> Decide on a range of plausible values of the effect size</a></li>
<li class="chapter" data-level="8.4" data-path="extract-parameter-estimates.html"><a href="extract-parameter-estimates.html"><i class="fa fa-check"></i><b>8.4</b> Extract parameter estimates</a></li>
<li class="chapter" data-level="8.5" data-path="define-a-function-for-generating-data.html"><a href="define-a-function-for-generating-data.html"><i class="fa fa-check"></i><b>8.5</b> Define a function for generating data</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="define-a-function-for-generating-data.html"><a href="define-a-function-for-generating-data.html#generate-a-latin-square-design"><i class="fa fa-check"></i><b>8.5.1</b> Generate a Latin-square design</a></li>
<li class="chapter" data-level="8.5.2" data-path="define-a-function-for-generating-data.html"><a href="define-a-function-for-generating-data.html#generate-data-row-by-row"><i class="fa fa-check"></i><b>8.5.2</b> Generate data row-by-row</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="repeated-generation-of-data-to-compute-power.html"><a href="repeated-generation-of-data-to-compute-power.html"><i class="fa fa-check"></i><b>8.6</b> Repeated generation of data to compute power</a></li>
<li class="chapter" data-level="8.7" data-path="what-you-can-now-do.html"><a href="what-you-can-now-do.html"><i class="fa fa-check"></i><b>8.7</b> What you can now do</a></li>
<li class="chapter" data-level="8.8" data-path="using-the-package-designr-to-simulate-data-and-compute-power.html"><a href="using-the-package-designr-to-simulate-data-and-compute-power.html"><i class="fa fa-check"></i><b>8.8</b> Using the package <code>designr</code> to simulate data and compute power</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="using-the-package-designr-to-simulate-data-and-compute-power.html"><a href="using-the-package-designr-to-simulate-data-and-compute-power.html#simulating-data-with-two-conditions"><i class="fa fa-check"></i><b>8.8.1</b> Simulating data with two conditions</a></li>
<li class="chapter" data-level="8.8.2" data-path="using-the-package-designr-to-simulate-data-and-compute-power.html"><a href="using-the-package-designr-to-simulate-data-and-compute-power.html#simulating-data-in-factorial-designs"><i class="fa fa-check"></i><b>8.8.2</b> Simulating data in factorial designs</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="sec:Simulationexercises.html"><a href="sec:Simulationexercises.html"><i class="fa fa-check"></i><b>8.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch:MultComp.html"><a href="ch:MultComp.html"><i class="fa fa-check"></i><b>9</b> Understanding Type I error inflation using simulation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html"><a href="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html"><i class="fa fa-check"></i><b>9.1</b> Overly simple random effects structure in LMMs inflate Type I error</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html"><a href="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html#type-i-error-with-a-varying-intercepts-only-model"><i class="fa fa-check"></i><b>9.1.1</b> Type I error with a varying intercepts-only model</a></li>
<li class="chapter" data-level="9.1.2" data-path="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html"><a href="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html#type-i-error-with-a-varying-intercepts-and-varying-slopes-model"><i class="fa fa-check"></i><b>9.1.2</b> Type I error with a varying intercepts and varying slopes model</a></li>
<li class="chapter" data-level="9.1.3" data-path="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html"><a href="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html#type-i-error-inflation-due-to-model-mis-specification"><i class="fa fa-check"></i><b>9.1.3</b> Type I error inflation due to model mis-specification</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="type-i-error-inflation-due-to-multiple-comparisons.html"><a href="type-i-error-inflation-due-to-multiple-comparisons.html"><i class="fa fa-check"></i><b>9.2</b> Type I error inflation due to multiple comparisons</a></li>
<li class="chapter" data-level="9.3" data-path="the-practical-implications.html"><a href="the-practical-implications.html"><i class="fa fa-check"></i><b>9.3</b> The practical implications</a></li>
<li class="chapter" data-level="9.4" data-path="summary-7.html"><a href="summary-7.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="further-reading-5.html"><a href="further-reading-5.html"><i class="fa fa-check"></i><b>9.5</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ch:reproducible.html"><a href="ch:reproducible.html"><i class="fa fa-check"></i><b>10</b> Developing a reproducible workflow</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-testing-the-one-sample-t-test" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> Hypothesis testing: The one sample t-test</h2>
<p>With the central limit theorem and the idea of hypothetical repeated sampling behind us, we turn now to one of the simplest statistical tests that one can do with continuous data: the t-test.</p>
<p>Due to its simplicity, it is tempting to take only a cursory look at the t-test and move on immediately to the linear (mixed) model. This would be a mistake. The humble t-test is surprising in many ways, and holds several important lessons for us. There are subtleties in this test, and a close connection to the linear mixed model. For these reasons, it is worth slowing down and spending some time understanding this test. Once the t-test is clear, more complex statistical tests will be easier to follow, because the logic of these more complex tests will essentially be more of the same, or variations on this general theme. You will see later that t-test can be seen as an analysis of variance or ANOVA; and the paired t-test is exactly the linear mixed model with varying intercepts.</p>
<div id="the-one-sample-t-test" class="section level3" number="2.5.1">
<h3><span class="header-section-number">2.5.1</span> The one-sample t-test</h3>
<p>As in our running example, suppose we have a random sample <span class="math inline">\(y\)</span> of size <span class="math inline">\(n\)</span>, and the data come from a <span class="math inline">\(N(\mu,\sigma)\)</span> distribution, with unknown parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. An assumption of the t-test is that the data points are independent in the sense discussed at the beginning of this chapter.
We can estimate <span class="math inline">\(\mu\)</span> from the sample mean <span class="math inline">\(\bar{y}\)</span>, which we will sometimes also write as <span class="math inline">\(\hat \mu\)</span>. We can also estimate <span class="math inline">\(\sigma\)</span> from the sample standard deviation <span class="math inline">\(s\)</span>, which we can also write as <span class="math inline">\(\hat\sigma\)</span>. These estimates in turn allow us to estimate the sampling distribution of the mean under (hypothetical) repeated sampling:</p>
<p><span class="math display">\[\begin{equation}
N(\hat\mu,\frac{\hat \sigma}{\sqrt{n}})
\end{equation}\]</span></p>
<p>It is important to realize here that the above sampling distribution is only as realistic as the estimates of the mean and standard deviation parameters—if those happen to be inaccurately estimated, then the sampling distribution is not realistic either.</p>
<p>Assume as before that we take an independent random sample of size <span class="math inline">\(1000\)</span> from a random variable <span class="math inline">\(Y\)</span> that is normally distributed, with mean 500 and standard deviation 100. As usual, begin by estimating the mean and SE:</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb122-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb122-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb122-2" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb122-3"><a href="hypothesis-testing-the-one-sample-t-test.html#cb122-3" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb122-4"><a href="hypothesis-testing-the-one-sample-t-test.html#cb122-4" aria-hidden="true" tabindex="-1"></a><span class="do">## generate simulated data:</span></span>
<span id="cb122-5"><a href="hypothesis-testing-the-one-sample-t-test.html#cb122-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">500</span>, <span class="at">sd =</span> <span class="dv">100</span>)</span>
<span id="cb122-6"><a href="hypothesis-testing-the-one-sample-t-test.html#cb122-6" aria-hidden="true" tabindex="-1"></a><span class="do">## compute summary statistics:</span></span>
<span id="cb122-7"><a href="hypothesis-testing-the-one-sample-t-test.html#cb122-7" aria-hidden="true" tabindex="-1"></a>y_bar <span class="ot">&lt;-</span> <span class="fu">mean</span>(y)</span>
<span id="cb122-8"><a href="hypothesis-testing-the-one-sample-t-test.html#cb122-8" aria-hidden="true" tabindex="-1"></a>SE <span class="ot">&lt;-</span> <span class="fu">sd</span>(y) <span class="sc">/</span> <span class="fu">sqrt</span>(n)</span></code></pre></div>
<p>The null hypothesis significance testing (NHST) approach as practised in psychology and other areas is to set up a null hypothesis that <span class="math inline">\(\mu\)</span> has some fixed value. Just as an example, assume that our null hypothesis is:</p>
<p><span class="math display">\[\begin{equation}
H_0: \mu = 450
\end{equation}\]</span></p>
<p>This amounts to assuming that the true sampling distribution of sample means is (approximately) normally distributed and centered around 450, with the standard error estimated from the data.</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-42"></span>
<img src="Freq_CogSci_files/figure-html/unnamed-chunk-42-1.svg" alt="The sampling distribution of the mean when the null hypothesis is that the mean is 450. Also shown is the observed sample mean." width="672" />
<p class="caption">
FIGURE 2.7: The sampling distribution of the mean when the null hypothesis is that the mean is 450. Also shown is the observed sample mean.
</p>
</div>
<p>The intuitive idea here is that</p>
<ul>
<li>if the sample mean <span class="math inline">\(\bar{y}\)</span> is “near” the hypothesized <span class="math inline">\(\mu\)</span> (here, 450), the data are possibly (but by no means necessarily) consistent with the null hypothesis distribution.</li>
<li>if the sample mean <span class="math inline">\(\bar{y}\)</span> is “far” from the hypothesized <span class="math inline">\(\mu\)</span>, the data are inconsistent with the null hypothesis distribution.</li>
</ul>
<p>The terms “near” and “far” will be quantified by determining how many standard error units the sample mean is from the hypothesized mean. This way of thinking shifts the focus away from the sampling distribution above, towards the distance measured in standard error units from the null hypothesis mean.</p>
<p>The distance between the sample mean and the hypothesized mean can be written in SE units as follows. We will say that the sample mean is <span class="math inline">\(t\)</span> standard errors away from the hypothesized mean:</p>
<p><span class="math display">\[\begin{equation}
t \times SE = \bar{x} - \mu 
\end{equation}\]</span></p>
<p>If we divide both sides with the standard error, we obtain the so-called observed t-statistic:</p>
<p><span class="math display">\[\begin{equation}
t  = \frac{\bar{x} - \mu}{SE}
\end{equation}\]</span></p>
<p>This observed t-value, an expression of the distance between the sample mean and the hypothesized mean, becomes the basis for the statistical test.</p>
<p>Notice that the t-value is a random variable: it is a transformation of <span class="math inline">\(\bar{X}\)</span>, the random variable generating the sample means. The t-value can therefore be seen as an instance of the following transformed random variable <span class="math inline">\(T\)</span>:</p>
<p><span class="math display">\[\begin{equation}
T  = \frac{\bar{X} - \mu}{SE}
\end{equation}\]</span></p>
<p>This random variable has a pdf associated with it, the t-distribution, which is defined in terms of the sample size <span class="math inline">\(n\)</span>; the pdf is written <span class="math inline">\(t(n-1)\)</span>. Under repeated sampling, the t-distribution is generated from this random variable <span class="math inline">\(T\)</span>.</p>
<p>Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:tdistrn">2.8</a> quickly visualizes this: sample 10000 times from a <span class="math inline">\(Y\sim Normal(\mu=450,\sigma=100)\)</span>. Assume that the null hypothesis is <span class="math inline">\(\mu_0=450\)</span>; that is, the null hypothesis is in fact true in this case. The sample size is <span class="math inline">\(n=5\)</span>. Then compute the t statistic each time, and plot the distribution of the t-values as a histogram. Plot a <span class="math inline">\(t(n-1)\)</span> distribution on top of this histogram to compare to the two distributions. A Normal(0,1) distribution is plotted as a broken line for comparison with the <span class="math inline">\(t(df=4)\)</span> distribution.</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4321</span>)</span>
<span id="cb123-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-2" aria-hidden="true" tabindex="-1"></a>nsim <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb123-3"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb123-4"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-4" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">450</span></span>
<span id="cb123-5"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-5" aria-hidden="true" tabindex="-1"></a><span class="do">## null hypothesis mean:</span></span>
<span id="cb123-6"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-6" aria-hidden="true" tabindex="-1"></a>mu0 <span class="ot">&lt;-</span> <span class="dv">450</span></span>
<span id="cb123-7"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-7" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb123-8"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-8" aria-hidden="true" tabindex="-1"></a>tval <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, nsim)</span>
<span id="cb123-9"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-9" aria-hidden="true" tabindex="-1"></a>se <span class="ot">&lt;-</span> sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n)</span>
<span id="cb123-10"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nsim) {</span>
<span id="cb123-11"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-11" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mu, <span class="at">sd =</span> sigma)</span>
<span id="cb123-12"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-12" aria-hidden="true" tabindex="-1"></a>  xbar <span class="ot">&lt;-</span> <span class="fu">mean</span>(y)</span>
<span id="cb123-13"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-13" aria-hidden="true" tabindex="-1"></a>  tval[i] <span class="ot">&lt;-</span> (xbar <span class="sc">-</span> mu0) <span class="sc">/</span> se</span>
<span id="cb123-14"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb123-15"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb123-16"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-16" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(tval, <span class="at">freq =</span> <span class="cn">FALSE</span>, <span class="at">main =</span> <span class="st">&quot;t-value distribution&quot;</span>)</span>
<span id="cb123-17"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-17" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="at">by =</span> <span class="fl">0.001</span>)</span>
<span id="cb123-18"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-18" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fu">dt</span>(x, <span class="at">df =</span> n <span class="sc">-</span> <span class="dv">1</span>))</span>
<span id="cb123-19"><a href="hypothesis-testing-the-one-sample-t-test.html#cb123-19" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(x, <span class="fu">dnorm</span>(x), <span class="at">lty =</span> <span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:tdistrn"></span>
<img src="Freq_CogSci_files/figure-html/tdistrn-1.svg" alt="The distribution of the t-value under repeated sampling assuming that the null hypothesis is true, compared with a t(n-1) distribution (solid line) and a Normal(0,1) distribution (broken line)." width="672" />
<p class="caption">
FIGURE 2.8: The distribution of the t-value under repeated sampling assuming that the null hypothesis is true, compared with a t(n-1) distribution (solid line) and a Normal(0,1) distribution (broken line).
</p>
</div>
<p>We will compactly express the statement that “the observed t-value is assumed to be generated (under repeated sampling) from a t-distribution with n-1 degrees of freedom” as:</p>
<p><span class="math display">\[\begin{equation}
T \sim t(n-1)
\end{equation}\]</span></p>
<p>For large <span class="math inline">\(n\)</span>, the pdf of the random variable <span class="math inline">\(T\)</span> approaches <span class="math inline">\(N(0,1)\)</span>. This is illustrated in Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:tnormal">2.9</a>; notice that the t-distribution has fatter tails than the normal for small <span class="math inline">\(n\)</span>, say <span class="math inline">\(n&lt;20\)</span>, but for larger n, the t-distribution and the normal become increasingly similar in shape. Incidentally, when n=2, the t-distribution <span class="math inline">\(t(1)\)</span> is the Cauchy distribution we saw earlier; this distribution is characterized by fat tails, and has no mean or variance defined for it.</p>
<div class="figure"><span style="display:block;" id="fig:tnormal"></span>
<img src="Freq_CogSci_files/figure-html/tnormal-1.svg" alt="A visual comparison of the t-distribution (with degrees of freedom ranging from 1 to 50) with the standard normal distribution (N(0,1)). The dashed line represents the standard normal distribution, and the solid line the t-distribution with the relevant degrees of freedom." width="672" />
<p class="caption">
FIGURE 2.9: A visual comparison of the t-distribution (with degrees of freedom ranging from 1 to 50) with the standard normal distribution (N(0,1)). The dashed line represents the standard normal distribution, and the solid line the t-distribution with the relevant degrees of freedom.
</p>
</div>
<p>Thus, given a sample size <span class="math inline">\(n\)</span>, we can define a t-distribution corresponding to the null hypothesis distribution. For large values of <span class="math inline">\(n\)</span>, we could even use <span class="math inline">\(N(0,1)\)</span>, although it is traditional in psychology and linguistics to always use the t-distribution no matter how large <span class="math inline">\(n\)</span> is.</p>
<p>The null hypothesis testing procedure proceeds as follows:</p>
<ul>
<li>Define the null hypothesis: in our example, the null hypothesis was that <span class="math inline">\(\mu = 450\)</span>. This amounts to making a commitment about what fixed value we think the true underlying distribution of sample means is centered at.</li>
<li>Given data of size <span class="math inline">\(n\)</span>, estimate <span class="math inline">\(\bar{y}\)</span>, standard deviation <span class="math inline">\(s\)</span>, and from that, estimate the standard error <span class="math inline">\(s/\sqrt{n}\)</span>. The standard error will be used to describe the sampling distribution’s standard deviation.</li>
<li>Compute the observed t-value:</li>
</ul>
<p><span class="math display">\[\begin{equation}
t=\frac{\bar{y}-\mu}{s/\sqrt{n}}
\end{equation}\]</span></p>
<ul>
<li>Reject null hypothesis if the observed t-value is “large” (to be made more precise next).</li>
<li>Fail to reject the null hypothesis, or (under some conditions, to be made clear later) even go so far as to accept the null hypothesis, if the observed t-value is “small.”</li>
</ul>
<p>What constitutes a large or small observed t-value?
Intuitively, the t-value from the sample is large when we end up far in <em>either</em> tail of the distribution. The two tails of the t-distribution will be referred to as the <em>rejection region</em>. The word <em>region</em> here refers to the real number line along the x-axis, under the tails of the distribution. The rejection region will go off to infinity on the outer sides, and is demarcated by a vertical line on the inner side of each tail. This is shown in Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:tails">2.10</a>. It goes off to infinity because the support—the range of possible values—of the random variable that the t-distribution belongs to stretches from minus infinity to plus infinity.</p>
<div class="figure"><span style="display:block;" id="fig:tails"></span>
<img src="Freq_CogSci_files/figure-html/tails-1.svg" alt="The rejection region in a t-distribution (sample size 20) assuming that the null hypothesis is true. The rejection region is the x-axis under the gray-colored area." width="672" />
<p class="caption">
FIGURE 2.10: The rejection region in a t-distribution (sample size 20) assuming that the null hypothesis is true. The rejection region is the x-axis under the gray-colored area.
</p>
</div>
<p>The location of the vertical lines is determined by the so-called <em>absolute critical t-value</em> along the x-axis of the t-distribution. This is the value such that the area under the curve in the tails to the left or right of the tails is 0.025. As discussed in chapter 1, this area under the curve represents the probability of observing a value as extreme as the critical t-value, or some value that is more extreme. Notice that if we ask ourselves what the probability is of observing some particular t-value (a point value), the answer must necessarily be <span class="math inline">\(0\)</span> (if you are unclear about why, re-read chapter 1). But we can ask the question: what is the absolute t-value, written <span class="math inline">\(|t|\)</span>, such that <span class="math inline">\(P(T&gt;|t|)=0.05\)</span>? That’s the critical t-value. We call it the critical t-value because it demarcates the rejection region shown in Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:tails">2.10</a>: we are adopting the convention that any observed t-value larger than this critical t-value allows us to reject the null hypothesis.</p>
<p>For a given sample size <span class="math inline">\(n\)</span>, we can identify the rejection region by using the <code>qt</code> function, whose usage is analogous to the <code>qnorm</code> function discussed in chapter 1.</p>
<p>Because the shape of the t-distribution depends on the degrees of freedom (n-1), the absolute critical t-value beyond which we reject the null hypothesis will change depending on sample size. For large sample sizes, say <span class="math inline">\(n&gt;50\)</span>, the rejection point is about 2.</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="fu">abs</span>(<span class="fu">qt</span>(<span class="fl">0.025</span>, <span class="at">df =</span> <span class="dv">15</span>))</span></code></pre></div>
<pre><code>## [1] 2.131</code></pre>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="fu">abs</span>(<span class="fu">qt</span>(<span class="fl">0.025</span>, <span class="at">df =</span> <span class="dv">50</span>))</span></code></pre></div>
<pre><code>## [1] 2.009</code></pre>
<p>Consider the observed t-value from our sample in our running example:</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb128-1" aria-hidden="true" tabindex="-1"></a><span class="do">## null hypothesis mean:</span></span>
<span id="cb128-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb128-2" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">450</span></span>
<span id="cb128-3"><a href="hypothesis-testing-the-one-sample-t-test.html#cb128-3" aria-hidden="true" tabindex="-1"></a>(t_value <span class="ot">&lt;-</span> (y_bar <span class="sc">-</span> mu) <span class="sc">/</span> SE)</span></code></pre></div>
<pre><code>## [1] 17.43</code></pre>
<p>This observed t-value is huge and is telling you the distance of the sample mean from the null hypothesis mean <span class="math inline">\(\mu\)</span> in standard error units.</p>
<p><span class="math display">\[\begin{equation}
t=\frac{\bar{y}-\mu_0}{s/\sqrt{n}} \hbox{ or } t\frac{s}{\sqrt{n}}=\bar{y}-\mu_0
\end{equation}\]</span></p>
<p>For large sample sizes, if the absolute t-value <span class="math inline">\(|t|\)</span> is greater than <span class="math inline">\(2\)</span>, we will reject the null hypothesis.</p>
<p>For a smaller sample size <span class="math inline">\(n\)</span>, you can compute the exact critical t-value:</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb130-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qt</span>(<span class="fl">0.025</span>, <span class="at">df =</span> n <span class="sc">-</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] -2.093</code></pre>
<p>Why is this critical t-value negative in sign? That is because it is on the left-hand side of the t-distribution, which is symmetric.
The corresponding value on the right-hand side is:</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb132-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="at">df =</span> n <span class="sc">-</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] 2.093</code></pre>
<p>These values are of course identical if we ignore the sign. This is why we always frame our discussion around the absolute t-value.</p>
<p>In R, the built-in function <code>t.test</code> delivers the observed t-value. Given our running example, with the null hypothesis <span class="math inline">\(\mu=450\)</span>, R returns the following:</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb134-1" aria-hidden="true" tabindex="-1"></a><span class="do">## observed t-value from t-test function:</span></span>
<span id="cb134-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb134-2" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(y, <span class="at">mu =</span> <span class="dv">450</span>)<span class="sc">$</span>statistic</span></code></pre></div>
<pre><code>##       t 
## -0.8859</code></pre>
<p>The default value for the null hypothesis mean <span class="math inline">\(\mu\)</span> in this function is 0; so if one doesn’t define a null hypothesis mean, the statistical test is done with reference to a null hypothesis that <span class="math inline">\(\mu=0\)</span>. That is why this t-value does not match our calculation above:</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb136-1" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(y)<span class="sc">$</span>statistic</span></code></pre></div>
<pre><code>##     t 
## 8.399</code></pre>
<p>In the most common usage of the t-test, the null hypothesis mean will be <span class="math inline">\(0\)</span>, because usually one is comparing a difference in means between two conditions or two sets of conditions. So the above line of code will work out correctly in those cases; but if you ever have a different null hypothesis mean than <span class="math inline">\(0\)</span>, then you have to specify it in the <code>t.test</code> function.</p>
<p>So, the way that the t-test is used in psychology and related areas is to implement a <em>decision</em>: either reject the null hypothesis or fail to reject it. Whenever we do an experiment and carry out a t-test, we use the t-test to make this binary decision: reject or fail to reject the null hypothesis.</p>
<p>Recall that behind the t-test lies the assumption that the observed t-value is coming from a random variable, <span class="math inline">\(T\sim t(n-1)\)</span>. The particular t-value we observe from a particular data-set belongs to a distribution of t-values under hypothetical repeated sampling. Thus, implicit in the logic of the t-test—and indeed every frequentist statistical test—is the assumption that the experiment is in principle repeatable: the experiment can in principle be re-run as many times as we want, assuming we have the necessary resources and time.</p>
<p>A quick simulation of t-values under repeated sampling makes this clear. Suppose that our null hypothesis mean is <span class="math inline">\(450\)</span>, and our sample size <span class="math inline">\(n=100\)</span>. Assume that the data come from <span class="math inline">\(Normal(\mu=450,\sigma=100)\)</span>. Thus, in this case the null hypothesis is in fact true. Let’s do <span class="math inline">\(10000\)</span> simulations, compute the sample mean each time, and then store the observed t-value. The t-distribution that results is shown in Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:simt">2.11</a>.</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb138-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb138-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb138-2" aria-hidden="true" tabindex="-1"></a>nsim <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb138-3"><a href="hypothesis-testing-the-one-sample-t-test.html#cb138-3" aria-hidden="true" tabindex="-1"></a>tvals <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, nsim)</span>
<span id="cb138-4"><a href="hypothesis-testing-the-one-sample-t-test.html#cb138-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nsim) {</span>
<span id="cb138-5"><a href="hypothesis-testing-the-one-sample-t-test.html#cb138-5" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">450</span>, <span class="at">sd =</span> <span class="dv">100</span>)</span>
<span id="cb138-6"><a href="hypothesis-testing-the-one-sample-t-test.html#cb138-6" aria-hidden="true" tabindex="-1"></a>  SE <span class="ot">&lt;-</span> <span class="fu">sd</span>(y) <span class="sc">/</span> <span class="fu">sqrt</span>(n)</span>
<span id="cb138-7"><a href="hypothesis-testing-the-one-sample-t-test.html#cb138-7" aria-hidden="true" tabindex="-1"></a>  tvals[i] <span class="ot">&lt;-</span> (<span class="fu">mean</span>(y) <span class="sc">-</span> <span class="dv">450</span>) <span class="sc">/</span> SE</span>
<span id="cb138-8"><a href="hypothesis-testing-the-one-sample-t-test.html#cb138-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb138-9"><a href="hypothesis-testing-the-one-sample-t-test.html#cb138-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(tvals),</span>
<span id="cb138-10"><a href="hypothesis-testing-the-one-sample-t-test.html#cb138-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Simulated t-distribution&quot;</span>,</span>
<span id="cb138-11"><a href="hypothesis-testing-the-one-sample-t-test.html#cb138-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;t-values under repeated sampling&quot;</span></span>
<span id="cb138-12"><a href="hypothesis-testing-the-one-sample-t-test.html#cb138-12" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:simt"></span>
<img src="Freq_CogSci_files/figure-html/simt-1.svg" alt="The distribution of t-values under repeated sampling. The null hypothesis is true." width="672" />
<p class="caption">
FIGURE 2.11: The distribution of t-values under repeated sampling. The null hypothesis is true.
</p>
</div>
<p>What would the t-distribution look like if the null hypothesis were false? Assume now that the null hypothesis is that <span class="math inline">\(\mu=450\)</span> as before, but that in fact the true <span class="math inline">\(\mu\)</span> is 470. Now the null hypothesis is false. Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:simtnullfalse">2.12</a> shows the t-distribution under repeated sampling. The t-distribution is now centered around 2; why? This is because if we plug in the hypothesized mean (450) and the true mean (470) and the standard error (<span class="math inline">\(100/\sqrt(100)=10\)</span>) into the equation for computing the t-value, the expected value of the t-distribution (its mean) is <span class="math inline">\(2\)</span>.</p>
<p><span class="math display">\[\begin{equation}
\frac{470-450}{10} = 2
\end{equation}\]</span></p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb139-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb139-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb139-2" aria-hidden="true" tabindex="-1"></a>nsim <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb139-3"><a href="hypothesis-testing-the-one-sample-t-test.html#cb139-3" aria-hidden="true" tabindex="-1"></a>tvals <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, nsim)</span>
<span id="cb139-4"><a href="hypothesis-testing-the-one-sample-t-test.html#cb139-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nsim) {</span>
<span id="cb139-5"><a href="hypothesis-testing-the-one-sample-t-test.html#cb139-5" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">470</span>, <span class="at">sd =</span> <span class="dv">100</span>)</span>
<span id="cb139-6"><a href="hypothesis-testing-the-one-sample-t-test.html#cb139-6" aria-hidden="true" tabindex="-1"></a>  SE <span class="ot">&lt;-</span> <span class="fu">sd</span>(y) <span class="sc">/</span> <span class="fu">sqrt</span>(n)</span>
<span id="cb139-7"><a href="hypothesis-testing-the-one-sample-t-test.html#cb139-7" aria-hidden="true" tabindex="-1"></a>  tvals[i] <span class="ot">&lt;-</span> (<span class="fu">mean</span>(y) <span class="sc">-</span> <span class="dv">450</span>) <span class="sc">/</span> SE</span>
<span id="cb139-8"><a href="hypothesis-testing-the-one-sample-t-test.html#cb139-8" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb139-9"><a href="hypothesis-testing-the-one-sample-t-test.html#cb139-9" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(tvals),</span>
<span id="cb139-10"><a href="hypothesis-testing-the-one-sample-t-test.html#cb139-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Simulated t-distribution&quot;</span>,</span>
<span id="cb139-11"><a href="hypothesis-testing-the-one-sample-t-test.html#cb139-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;t-values under repeated sampling&quot;</span></span>
<span id="cb139-12"><a href="hypothesis-testing-the-one-sample-t-test.html#cb139-12" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:simtnullfalse"></span>
<img src="Freq_CogSci_files/figure-html/simtnullfalse-1.svg" alt="The distribution of t-values under repeated sampling. The null hypothesis is false, with the true mean being 470 (the null hypothesis is that the true mean is 450)." width="672" />
<p class="caption">
FIGURE 2.12: The distribution of t-values under repeated sampling. The null hypothesis is false, with the true mean being 470 (the null hypothesis is that the true mean is 450).
</p>
</div>
<p>This implicit idea of the experiment’s repeatability leads to an important aspect of the t-test: once certain assumptions about the null hypothesis and the alternative hypothesis are fixed, we can using simulation to compute the proportion of times that the null hypothesis would be rejected under repeated sampling. One has to consider two alternative possible scenarios: the null is either true, or it is false. In other words, this simulation-based approach allows us to study the t-test’s ability (at least in theory) to lead the researchers to the correct decision under (hypothetical) repeated sampling. We turn to this issue next.</p>
</div>
<div id="type-i-ii-error-and-power" class="section level3" number="2.5.2">
<h3><span class="header-section-number">2.5.2</span> Type I, II error, and power</h3>
<p>When we do a hypothesis test using the t-test, the observed t-value will either fall in the rejection region, leading us to reject the null hypothesis,
or it will land in the non-rejection region, leading us to fail to reject the null. For a particular experiment, that is a single, one-time event.</p>
<p>So suppose we have made our decision based on the observed t-value. Now, the null hypothesis can be either true or not true; we don’t know which of those two possibilities is the reality.
When we decide (based on the observed t-value) that the null is true, we are asserting that the parameter <span class="math inline">\(\mu\)</span> actually does have the hypothesized value <span class="math inline">\(\mu_0\)</span>; when we decide that the null is false, we are asserting that the parameter <span class="math inline">\(\mu\)</span> has some <em>specific</em> value <span class="math inline">\(\mu_{alt}\)</span> other than <span class="math inline">\(\mu_0\)</span>.
We can represent these two alternative possible realities in a tabular form, as shown in Table <a href="#tab:type12"><strong>??</strong></a>. The two columns show the two possible worlds, one in which the null is true, and the other in which it is false. The two rows show the two possible decisions we can take based on the observed t-value: reject the null or fail to reject it.</p>
<p>As the table shows, we can make two kinds of mistakes:</p>
<ul>
<li>Type I error or <span class="math inline">\(\alpha\)</span>: Reject the null when it’s true.</li>
<li>Type II error or <span class="math inline">\(\beta\)</span>: Accept the null when it’s false.</li>
</ul>
<p>In psychology and related areas, Type I error is usually fixed a priori at 0.05. This stipulated Type I error value is why the absolute critical t-value is kept at approximately <span class="math inline">\(2\)</span>; if, following recommendations from <span class="citation"><a href="#ref-benjamin2018redefine" role="doc-biblioref">Benjamin et al.</a> (<a href="#ref-benjamin2018redefine" role="doc-biblioref">2018</a>)</span>, we were to stipulate that the Type I error be 0.005, then the critical t-value would have had to be set at:</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb140-1" aria-hidden="true" tabindex="-1"></a><span class="fu">abs</span>(<span class="fu">qt</span>(<span class="fl">0.0025</span>, <span class="at">df =</span> n <span class="sc">-</span> <span class="dv">1</span>))</span></code></pre></div>
<pre><code>## [1] 2.871</code></pre>
<p>This suggested change in convention hasn’t been taken up yet in cognitive science, but this could well change one day.</p>
<p>Type II error, the probability of incorrectly accepting the null hypothesis when it is false with some particular value for the parameter <span class="math inline">\(\mu\)</span>, is conventionally recommended <span class="citation">(<a href="#ref-powerbookcohen" role="doc-biblioref">Cohen 1988</a>)</span> to be kept at 0.20 or lower. This implies that the probability of correctly rejecting a null hypothesis for some particular true value of <span class="math inline">\(\mu\)</span> is 1-Type II error. This probability, called statistical power, or just power, should then obviously be larger than 0.80. Again, there is nothing special about these stipulations; they are conventions that became the norm over time.</p>
<p>Next, we will consider the trade-off between Type I and II error. For simplicity, assume that the standard error is 1, and the null hypothesis is that <span class="math inline">\(\mu=0\)</span>. This means that the observed t-value is really the sample mean.</p>
<p>Consider the concrete situation where, in reality, the true value of <span class="math inline">\(\mu\)</span> is <span class="math inline">\(2\)</span>. Let’s assume for simplicity that the standard error is 1; this means that the true <span class="math inline">\(\mu\)</span> is also the t-value. This allows us to talk about the hypothesis test in terms of the t-distribution.</p>
<p>As mentioned above, the null hypothesis <span class="math inline">\(H_0\)</span> is that <span class="math inline">\(\mu=0\)</span>. Now the <span class="math inline">\(H_0\)</span> is false because <span class="math inline">\(\mu=2\)</span> and not <span class="math inline">\(0\)</span>. Type I and II error can be visualized graphically as shown in Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:type12">2.13</a>.</p>
<div class="figure"><span style="display:block;" id="fig:type12"></span>
<img src="Freq_CogSci_files/figure-html/type12-1.svg" alt="A visualization of Type I  and II error. The dark-shaded tails of the left-hand side distribution represent Type I error; and  the light-colored shaded region of the right-hand side distribution represents Type II error. Power is the unshaded area under the curve in  the right-hand side distribution." width="672" />
<p class="caption">
FIGURE 2.13: A visualization of Type I and II error. The dark-shaded tails of the left-hand side distribution represent Type I error; and the light-colored shaded region of the right-hand side distribution represents Type II error. Power is the unshaded area under the curve in the right-hand side distribution.
</p>
</div>
<p>To understand Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:type12">2.13</a>, one has to consider two distributions side by side. First, consider the null hypothesis distribution, centered at 0. Under the null hypothesis distribution, the rejection region lies below the dark colored tails of the distributions. The area under the curve in these dark-colored tails is the Type I error (conventionally set at 0.05) that we decide on even before we conduct the experiment and collect the data. Because the Type I error is set at 0.05, and because the t-distribution is symmetric, the area under the curve in each tail is 0.025. The absolute critical t-value helps us demarcate the boundaries of the rejection regions through the vertical lines shown in the figure. These vertical lines play a crucial role in helping us understand Type II error and power. This becomes clear when we consider the distribution representing the alternative possible value of <span class="math inline">\(\mu\)</span>, the distribution centered around 2. In this second distribution, consider now the area under the curve between the vertical lines demarcating the rejection region under the null. This area under the curve is the probability of accepting the null hypothesis when the null hypothesis is false with some specific value (here, when <span class="math inline">\(\mu\)</span> has value 2).</p>
<p>Some interesting observations follow. Suppose that the true mean is in fact <span class="math inline">\(\mu=2\)</span>, as in the above illustration. Then,</p>
<ul>
<li>Simply decreasing Type I error to a smaller value like 0.005 will increase Type II error, which means that power (1-Type II error) will fall.</li>
<li>Increasing sample size will squeeze the vertical lines closer to each other because standard error will go down with increasing sample size. This will reduce Type II error, and therefore increase power. Decreasing sample size will have the opposite effect.</li>
<li>If we design an experiment with a larger effect size, e.g., by setting up a stronger manipulation (concete examples will be discussed in this book later on), our Type II error will go down, and therefore power will go up. Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:highpower">2.14</a> shows a graphical visualization of a situation where the true mean is <span class="math inline">\(\mu=4\)</span>. Here, Type II error is much smaller compared to Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:type12">2.13</a>, where <span class="math inline">\(\mu=2\)</span>.</li>
</ul>
<div class="figure"><span style="display:block;" id="fig:highpower"></span>
<img src="Freq_CogSci_files/figure-html/highpower-1.svg" alt="The change in Type II error if the true mean is 4." width="672" />
<p class="caption">
FIGURE 2.14: The change in Type II error if the true mean is 4.
</p>
</div>
<p>In summary, when we plan out an experiment, we are also required to specify the Type I and II error associated with the design. Both sources of error are within our control, at least to some extent. The Type I error we decide to use will determine our critical t-value and therefore our decision criterion for rejecting, failing to reject, or even (under certain conditions, to be discussed below) accepting the null hypothesis.</p>
<p>The Type II error we decide on will determine the long-run probability of incorrectly ``accepting’’ the null hypothesis; its inverse (1-Type II error), statistical power, will determine the long-run probability of correctly rejecting the null hypothesis under the assumption that the <span class="math inline">\(\mu\)</span> has some particular value other than the null hypothesis mean.</p>
<p>That’s the theory anyway. In practice, researchers only rarely consider the power properties of their experiment design; the focus is almost exclusively on Type I error. The neglect of power in experiment design has had interesting consequences for theory development, as we will see later in this book. For a case study in psycholinguistics, see <span class="citation"><a href="#ref-VasishthMertzenJaegerGelman2018" role="doc-biblioref">S. Vasishth et al.</a> (<a href="#ref-VasishthMertzenJaegerGelman2018" role="doc-biblioref">2018</a>)</span>.</p>
</div>
<div id="how-to-compute-power-for-the-one-sample-t-test" class="section level3" number="2.5.3">
<h3><span class="header-section-number">2.5.3</span> How to compute power for the one-sample t-test</h3>
<p>Power (which is 1-Type II error) is a function of three variables:</p>
<ul>
<li>the effect size</li>
<li>the standard deviation</li>
<li>the sample size.</li>
</ul>
<p>There are two ways that one can compute power in connection with the t-test: either one can use the built-in R function, <code>power.t.test</code>, or one can use simulation.</p>
<div id="power-calculation-using-the-power.t.test-function" class="section level4" number="2.5.3.1">
<h4><span class="header-section-number">2.5.3.1</span> Power calculation using the <code>power.t.test</code> function</h4>
<p>Suppose that we have an expectation that an effect size is 15 ms <span class="math inline">\(\pm 5\)</span> ms (this could be based on the predictions of a theoretical model, or prior data); suppose also that prior experiments show standard deviations ranging from 100 to 300 ms. Given a particular sample size, this is enough information to compute a power curve as a function of effect size and standard deviation. See Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:powercurve">2.15</a> and the associated code below.</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-1" aria-hidden="true" tabindex="-1"></a>sds <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">100</span>, <span class="dv">300</span>, <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb142-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-2" aria-hidden="true" tabindex="-1"></a>lower <span class="ot">&lt;-</span> <span class="fu">power.t.test</span>(</span>
<span id="cb142-3"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">delta =</span> <span class="dv">15</span> <span class="sc">-</span> <span class="dv">5</span>,</span>
<span id="cb142-4"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd =</span> sds, <span class="at">n =</span> <span class="dv">10</span>,</span>
<span id="cb142-5"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">strict =</span> <span class="cn">TRUE</span></span>
<span id="cb142-6"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-6" aria-hidden="true" tabindex="-1"></a>)<span class="sc">$</span>power</span>
<span id="cb142-7"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-7" aria-hidden="true" tabindex="-1"></a>upper <span class="ot">&lt;-</span> <span class="fu">power.t.test</span>(</span>
<span id="cb142-8"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">delta =</span> <span class="dv">15</span> <span class="sc">+</span> <span class="dv">5</span>,</span>
<span id="cb142-9"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd =</span> sds, <span class="at">n =</span> <span class="dv">10</span>,</span>
<span id="cb142-10"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">strict =</span> <span class="cn">TRUE</span></span>
<span id="cb142-11"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-11" aria-hidden="true" tabindex="-1"></a>)<span class="sc">$</span>power</span>
<span id="cb142-12"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-12" aria-hidden="true" tabindex="-1"></a>meanval <span class="ot">&lt;-</span> <span class="fu">power.t.test</span>(</span>
<span id="cb142-13"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">delta =</span> <span class="dv">15</span>,</span>
<span id="cb142-14"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">sd =</span> sds, <span class="at">n =</span> <span class="dv">10</span>,</span>
<span id="cb142-15"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">strict =</span> <span class="cn">TRUE</span></span>
<span id="cb142-16"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-16" aria-hidden="true" tabindex="-1"></a>)<span class="sc">$</span>power</span>
<span id="cb142-17"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb142-18"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-18" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(sds, meanval,</span>
<span id="cb142-19"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;l&quot;</span>,</span>
<span id="cb142-20"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Power curve (n=10)</span><span class="sc">\n</span></span>
<span id="cb142-21"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-21" aria-hidden="true" tabindex="-1"></a><span class="st">     using power.t.test&quot;</span>,</span>
<span id="cb142-22"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;standard deviation&quot;</span>,</span>
<span id="cb142-23"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;power&quot;</span>,</span>
<span id="cb142-24"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">yaxs =</span> <span class="st">&quot;i&quot;</span>,</span>
<span id="cb142-25"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylim =</span> <span class="fu">c</span>(<span class="fl">0.05</span>, <span class="fl">0.12</span>)</span>
<span id="cb142-26"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-26" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb142-27"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-27" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(sds, lower, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb142-28"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-28" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(sds, upper, <span class="at">lty =</span> <span class="dv">2</span>)</span>
<span id="cb142-29"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-29" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">125</span>, <span class="fl">0.053</span>, <span class="st">&quot;10&quot;</span>)</span>
<span id="cb142-30"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-30" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">150</span>, <span class="fl">0.054</span>, <span class="st">&quot;15&quot;</span>)</span>
<span id="cb142-31"><a href="hypothesis-testing-the-one-sample-t-test.html#cb142-31" aria-hidden="true" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">175</span>, <span class="fl">0.056</span>, <span class="st">&quot;20&quot;</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:powercurve"></span>
<img src="Freq_CogSci_files/figure-html/powercurve-1.svg" alt="An illustration of a power curve for 10 participants, as a function of standard deviation, and three estimates of the effect: 15, 10, and 20." width="672" />
<p class="caption">
FIGURE 2.15: An illustration of a power curve for 10 participants, as a function of standard deviation, and three estimates of the effect: 15, 10, and 20.
</p>
</div>
</div>
<div id="power-calculations-using-simulation" class="section level4" number="2.5.3.2">
<h4><span class="header-section-number">2.5.3.2</span> Power calculations using simulation</h4>
<p>An analogous calculation as the one shown above using the <code>power.t.test</code> function can also be done using simulated data.
First, generate simulated data repeatedly for each possible combination of parameter values (here, effect size and standard deviation), and compute the proportion of significant effects for each parameter combination. This can be done by defining a function that takes as input the number of simulations, sample size, effect size, and standard deviation:</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb143-1" aria-hidden="true" tabindex="-1"></a>compute_power <span class="ot">&lt;-</span> <span class="cf">function</span>(<span class="at">nsim =</span> <span class="dv">100000</span>, <span class="at">n =</span> <span class="dv">10</span>,</span>
<span id="cb143-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb143-2" aria-hidden="true" tabindex="-1"></a>                          <span class="at">effect =</span> <span class="cn">NULL</span>,</span>
<span id="cb143-3"><a href="hypothesis-testing-the-one-sample-t-test.html#cb143-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">stddev =</span> <span class="cn">NULL</span>) {</span>
<span id="cb143-4"><a href="hypothesis-testing-the-one-sample-t-test.html#cb143-4" aria-hidden="true" tabindex="-1"></a>  crit_t <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">qt</span>(<span class="fl">0.025</span>, <span class="at">df =</span> n <span class="sc">-</span> <span class="dv">1</span>))</span>
<span id="cb143-5"><a href="hypothesis-testing-the-one-sample-t-test.html#cb143-5" aria-hidden="true" tabindex="-1"></a>  temp_power <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, nsim)</span>
<span id="cb143-6"><a href="hypothesis-testing-the-one-sample-t-test.html#cb143-6" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nsim) {</span>
<span id="cb143-7"><a href="hypothesis-testing-the-one-sample-t-test.html#cb143-7" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> effect, <span class="at">sd =</span> stddev)</span>
<span id="cb143-8"><a href="hypothesis-testing-the-one-sample-t-test.html#cb143-8" aria-hidden="true" tabindex="-1"></a>    temp_power[i] <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(<span class="fu">abs</span>(<span class="fu">t.test</span>(y)<span class="sc">$</span>statistic)</span>
<span id="cb143-9"><a href="hypothesis-testing-the-one-sample-t-test.html#cb143-9" aria-hidden="true" tabindex="-1"></a>    <span class="sc">&gt;</span> crit_t, <span class="dv">1</span>, <span class="dv">0</span>)</span>
<span id="cb143-10"><a href="hypothesis-testing-the-one-sample-t-test.html#cb143-10" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb143-11"><a href="hypothesis-testing-the-one-sample-t-test.html#cb143-11" aria-hidden="true" tabindex="-1"></a>  <span class="do">## return power calculation:</span></span>
<span id="cb143-12"><a href="hypothesis-testing-the-one-sample-t-test.html#cb143-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(temp_power)</span>
<span id="cb143-13"><a href="hypothesis-testing-the-one-sample-t-test.html#cb143-13" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Then, plot the power curves as a function of effect size and standard deviation, exactly as in Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:powercurve">2.15</a>. Power calculations using simulations are shown in Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:powercurve2">2.16</a>. It is clear that simulation-based power estimation is going to be noisy; this is because each time we are generating simulated data and then carrying out a statistical test on it. This is no longer a closed-form mathematical calculation as done in <code>power.t.test</code> (this function simply implements a formula for power calculation specified for this simple case). Because the power estimates will be noisy, we show a smoothed lowess line for each effect size estimate.</p>
<div class="figure"><span style="display:block;" id="fig:powercurve2"></span>
<img src="Freq_CogSci_files/figure-html/powercurve2-1.svg" alt="An illustration of a power curve using simulation, for 10 participants, as a function of standard deviation, and three estimates of the effect: 15, 10, and 20. The power curves are lowess-smoothed." width="672" />
<p class="caption">
FIGURE 2.16: An illustration of a power curve using simulation, for 10 participants, as a function of standard deviation, and three estimates of the effect: 15, 10, and 20. The power curves are lowess-smoothed.
</p>
</div>
<p>In the above example, simulation-based power calculation is overkill, and completely unnecessary because we have <code>power.t.test</code>. However, the technique shown above will be extended and will become our bread-and-butter method once we switch to power calculations for complicated linear mixed models. There, no closed form calculation can be done to compute power, at least not without oversimplifying the model; simulation will be the only practical way to calculate power.</p>
<p>It is important to appreciate the fact that power is a <em>function</em>; it isn’t a single number. Because we can never be sure what the true effect size is, or what the true standard deviation is, power functions (power as a function of plausible values for the relevant parameters) are much more useful than single numbers.</p>
</div>
</div>
<div id="the-p-value" class="section level3" number="2.5.4">
<h3><span class="header-section-number">2.5.4</span> The p-value</h3>
<p>Continuing with our t-test example, the <code>t.test</code> function in R will not only print out a t-value as shown above, but also a probability known as a <em>p-value</em>. This is the probability of obtaining the observed t-value that we obtained, or some value more extreme than that, conditional on the assumption that the null hypothesis is true.</p>
<p>We can compute the p-value “by hand.” This can be computed, as done earlier, simply by calculating the area under the curve that lies beyond the absolute observed t-value on either side of the t-distribution. It is standard practice to take the tail probability on both sides of the t-distribution.</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb144-1" aria-hidden="true" tabindex="-1"></a>(abs_t_value <span class="ot">&lt;-</span> <span class="fu">abs</span>(<span class="fu">t.test</span>(y, <span class="at">mu =</span> <span class="dv">450</span>)<span class="sc">$</span>statistic))</span></code></pre></div>
<pre><code>##     t 
## 2.498</code></pre>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span> <span class="sc">*</span> <span class="fu">pt</span>(abs_t_value, <span class="at">df =</span> n <span class="sc">-</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>##       t 
## 0.03396</code></pre>
<p>The area from both sides of the tail is taken because it is conventional to do a so-called <em>two-sided t-test</em>: our null hypothesis is that <span class="math inline">\(\mu=450\)</span>, and our alternative hypothesis is two-sided: <span class="math inline">\(\mu\)</span> is either less than <span class="math inline">\(450\)</span> or <span class="math inline">\(\mu\)</span> is larger than <span class="math inline">\(450\)</span>. When we reject the null hypothesis, we are accepting this alternative, that <span class="math inline">\(\mu\)</span> could be some value other than <span class="math inline">\(450\)</span>. Notice that this alternative hypothesis is remarkably vague; we would reject the null hypothesis regardless of whether the sample mean turns out to be <span class="math inline">\(600\)</span> or <span class="math inline">\(-600\)</span>, for example. The practical implication is that the p-value gives us the strength of the evidence against the null hypothesis; it doesn’t give us evidence in favor of a specific alternative. The p-value will reject the null hypothesis regardless of whether our sample mean is positive or negative in sign. In psychology and allied disciplines, whenever the p-value falls below <span class="math inline">\(0.05\)</span>, it is common practice to write something along the lines that “there was reliable evidence for the predicted effect.” This statement is incorrect! We only ever have evidence against the null. By looking at the sample mean and its sign, we are making a very big leap that we have evidence for the specific sample mean we happened to get. As we will see below, when power is low, the sample mean can be wildly far from the true mean that produced the data.</p>
<p>One need not have a two-sided alternative; one could have defined the alternative to be one-sided (for example, that <span class="math inline">\(mu&gt;450\)</span>). In that case, one would compute only one side of the area under the curve. This kind of one-sided test is not normally done, but one can imagine a situation where a one-sided test is justified (for example, when only one sign of the effect is possible, or if there is a strong theoretical reason to expect only one particular sign—positive or negative—on an effect). That said, in their scientific career, only one of the authors of this book has ever had occasion to use a one-sided test. In this book, we will not use one-sided t-tests.</p>
<p>The p-value is always interpreted with reference to the pre-defined Type I error. Conventionally, we reject the null if <span class="math inline">\(p&lt;0.05\)</span>. This is because we set the Type I error probability at 0.05. Keep in mind that Type I error probability and the p-value are two distinct things.
The Type I error probability is the probability of your incorrectly rejecting the null under repeated sampling. This is not the same thing as your p-value. The latter probability will be obtained from a particular experiment, and will vary from experiment to experiment; it is a random variable. By contrast, the Type I error probability is a value we fix in advance.</p>
</div>
<div id="the-distribution-of-the-p-value-under-the-null-hypothesis" class="section level3" number="2.5.5">
<h3><span class="header-section-number">2.5.5</span> The distribution of the p-value under the null hypothesis</h3>
<p>We have been talking about a continuous random variable as a dependent measure, and have learnt about the standard two-sided t-test, with a point null hypothesis. When we do such a test, we usually use the p-value to decide whether to reject the null hypothesis or not.</p>
<p>Sometimes, you will hear statisticians (e.g., Andrew Gelman on his blog) criticize p-values by saying that the null hypothesis significance test is a “specific random number generator.” For example, a blog post from May 5, 2016 (shorturl.at/irHS9) quotes Daniel Lakeland: ``A p-value is the probability of seeing data as extreme or more extreme than the result, under the assumption that the result was produced by a specific random number generator (called the null hypothesis).’’</p>
<p>What does that sentence mean? We explain this point here because it is very helpful in understanding the absurdity of the p-value.</p>
<p>Suppose that the null hypothesis is in fact true. We will now simulate the distribution of the p-value under repeated sampling, given this assumption. See Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:pvalnulltrue">2.17</a>.</p>
<div class="figure"><span style="display:block;" id="fig:pvalnulltrue"></span>
<img src="Freq_CogSci_files/figure-html/pvalnulltrue-1.svg" alt="The p-value has a uniform distribution when the null hypothesis is true; a demonstration using simulation." width="672" />
<p class="caption">
FIGURE 2.17: The p-value has a uniform distribution when the null hypothesis is true; a demonstration using simulation.
</p>
</div>
<p>The distribution of the p-value is uniform—every value between 0 and 1 is equally likely. The practical implication of this criticism of p-values is that when we do a single experiment and obtain a p-value under the assumption that the null is true, if the null were in fact true, then we are just using a random number generator (generating a random number between 0 and 1, <span class="math inline">\(Z\sim uniform(0,1)\)</span>) to make a decision that the effect is present or absent. Using the output of a <span class="math inline">\(uniform(0,1)\)</span> distribution to decide to reject the null hypothesis makes no sense at all.</p>
<p>Here is the scientific procedure in R code, in the case where the null hypothesis is in fact true:</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb148-1" aria-hidden="true" tabindex="-1"></a>pval <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1</span>, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">1</span>)</span>
<span id="cb148-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb148-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> (pval <span class="sc">&lt;</span> <span class="fl">0.05</span>) {</span>
<span id="cb148-3"><a href="hypothesis-testing-the-one-sample-t-test.html#cb148-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(<span class="st">&quot;reject&quot;</span>)</span>
<span id="cb148-4"><a href="hypothesis-testing-the-one-sample-t-test.html#cb148-4" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb148-5"><a href="hypothesis-testing-the-one-sample-t-test.html#cb148-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;fail to reject&quot;</span></span>
<span id="cb148-6"><a href="hypothesis-testing-the-one-sample-t-test.html#cb148-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<pre><code>## [1] &quot;fail to reject&quot;</code></pre>
<p>A broader implication is that we should not place our theory development exclusively at the feet of the p-value. As we discuss in this book, other considerations (such as replicability, uncertainty of the estimates, and power) are more important than the p-value.</p>
<div class="blackbox">
<div data-latex="">
<p><strong>Proof that the p-value is uniformly distributed under the null: The probability integral transform</strong></p>
</div>
<p>The fact that the p-value comes from a uniform distribution with bounds 0 and 1 when the null hypothesis is true can be formally derived using the random variable theory in chapter 1.</p>
<p>Consider the fact that the p-value is a random variable; call it <span class="math inline">\(Z\)</span>. The p-value is the cumulative distribution function (CDF) of the random variable <span class="math inline">\(T\)</span>, which itself is a transformation of the random variable that represents the mean of the data <span class="math inline">\(\bar{Y}\)</span>:</p>
<p><span class="math inline">\(T=(\bar{Y}-\mu)/(\sigma/\sqrt{n})\)</span></p>
<p>This random variable <span class="math inline">\(T\)</span> itself has some CDF <span class="math inline">\(F(T)\)</span>. It is possible to show that if a random variable <span class="math inline">\(Z=F(T)\)</span>, i.e., if <span class="math inline">\(Z\)</span> is the CDF for the random variable <span class="math inline">\(T\)</span>, then <span class="math inline">\(Z\)</span> has a uniform distribution ranging from 0 to 1, <span class="math inline">\(Z \sim Uniform(0,1)\)</span>.</p>
<p>This is an amazing fact. To get a grip on this, let’s first think about the fact that when a random variable <span class="math inline">\(Z\)</span> comes from a <span class="math inline">\(Uniform(0,1)\)</span> distribution, then <span class="math inline">\(P(Z&lt;z)=z\)</span>. Consider some examples:</p>
<ul>
<li>when <span class="math inline">\(z=0\)</span>, then <span class="math inline">\(P(Z&lt;0)=0\)</span>;</li>
<li>when <span class="math inline">\(z=0.25\)</span>, then <span class="math inline">\(P(Z&lt;0.25)=0.25\)</span>;</li>
<li>when <span class="math inline">\(z=0.5\)</span>, then <span class="math inline">\(P(Z&lt;0.5)=0.5\)</span>;</li>
<li>when <span class="math inline">\(z=0.75\)</span>, then <span class="math inline">\(P(Z&lt;0.75)=0.75\)</span>;</li>
<li>when <span class="math inline">\(z=1\)</span>, then <span class="math inline">\(P(Z&lt;1)=1\)</span>.</li>
</ul>
<p>You can verify this by typing:</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb150-1" aria-hidden="true" tabindex="-1"></a>z <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="dv">1</span>)</span>
<span id="cb150-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb150-2" aria-hidden="true" tabindex="-1"></a><span class="fu">punif</span>(z, <span class="at">min =</span> <span class="dv">0</span>, <span class="at">max =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] 0.00 0.25 0.50 0.75 1.00</code></pre>
<p>Next, we will prove the above statement, that if a random variable <span class="math inline">\(Z=F(T)\)</span>, i.e., if <span class="math inline">\(Z\)</span> is the
CDF for a random variable <span class="math inline">\(T\)</span>, then <span class="math inline">\(Z \sim Uniform(0,1)\)</span>.
The proof is actually quite astonishing and even has a name: it’s called the <em>probability integral transform</em>.</p>
<p>Suppose that <span class="math inline">\(Z\)</span> is the CDF of a random variable <span class="math inline">\(T\)</span>: <span class="math inline">\(Z=F(T)\)</span>. Then, it follows that <span class="math inline">\(P(Z\leq z)\)</span> can be rewritten in terms of the CDF of T: <span class="math inline">\(P(F(T)\leq z)\)</span>. Now, if we apply the inverse of the CDF (<span class="math inline">\(F^{-1}\)</span>) to both the left and right sides of the inequality, we get <span class="math inline">\(P(F^{-1}F(T)\leq F^{-1}(z))\)</span>.
But <span class="math inline">\(F^{-1}F(T)\)</span> gives us back <span class="math inline">\(T\)</span>; this holds because if we have a one-to-one onto function <span class="math inline">\(f(x)\)</span>, then applying the inverse <span class="math inline">\(f^{-1}\)</span> to this function gives us back <span class="math inline">\(x\)</span>.</p>
<p>The fact that <span class="math inline">\(F^{-1}F(T)\)</span> gives us back <span class="math inline">\(T\)</span> means that we can rewrite <span class="math inline">\(P(F^{-1}F(T)\leq F^{-1}(z))\)</span> as <span class="math inline">\(P(T\leq F^{-1}(z) )\)</span>. But this probabilityy is the CDF <span class="math inline">\(F(F^{-1}(z))\)</span>, which simplifies to <span class="math inline">\(z\)</span>. This shows that <span class="math inline">\(P(Z\leq z) = z\)</span>; i.e., that the p-value has a uniform distribution under the null hypothesis.</p>
<p>The above proof is restated below compactly:</p>
<p><span class="math display">\[\begin{equation}
\begin{split}
P(Z\leq z) =&amp; P(F(T)\leq z)\\
=&amp; P(F^{-1}F(T)\leq F^{-1}(z))\\
=&amp; P(T\leq F^{-1}(z) ) \\
=&amp; F(F^{-1} (z))\\
=&amp; z\\
\end{split}
\end{equation}\]</span></p>
<p>It is for this reason that statisticians like Andrew Gelman periodically point out that “the null hypothesis significance test is a specific random number generator.”</p>
</div>
</div>
<div id="type-m-and-s-error-in-the-face-of-low-power" class="section level3" number="2.5.6">
<h3><span class="header-section-number">2.5.6</span> Type M and S error in the face of low power</h3>
<p>Beyond Type I and II error, there are also two other kinds of error to be aware of. These are Type M(agnitude) and S(ign) error; both sources of error are closely related to statistical power.</p>
<p>The terms Type M and S error were introduced by <span class="citation"><a href="#ref-Gelman14" role="doc-biblioref">Gelman et al.</a> (<a href="#ref-Gelman14" role="doc-biblioref">2014</a>)</span>, but the ideas have been in existence for some time <span class="citation">(<a href="#ref-hedges1984estimation" role="doc-biblioref">Hedges 1984</a>)</span>,<span class="citation">(<a href="#ref-lane1978estimating" role="doc-biblioref">Lane and Dunlap 1978</a>)</span>. <span class="citation"><a href="#ref-powerfailure" role="doc-biblioref">Button et al.</a> (<a href="#ref-powerfailure" role="doc-biblioref">2013</a>)</span> refer to Type M and S error as the “winner’s curse” and “the vibration of effects.” In related work, <span class="citation"><a href="#ref-ioannidis2008most" role="doc-biblioref">Ioannidis</a> (<a href="#ref-ioannidis2008most" role="doc-biblioref">2008</a>)</span> refers to the vibration ratio in the context of epidemiology.</p>
<p>Type S and M error can be illustrated with the following example.
Suppose your true effect size is believed to be <span class="math inline">\(D=15\)</span>,
then we can compute (apart from statistical power) the following error rates, which are defined as follows:</p>
<ul>
<li><strong>Type S error</strong>: the probability that the sign of the effect is incorrect, given that the result is statistically significant.</li>
<li><strong>Type M error</strong>: the expectation of the ratio of the absolute magnitude of the effect to the hypothesized true effect size, given that the result is significant.
Gelman and Carlin also call this the exaggeration ratio, which is perhaps more descriptive than “Type M error.”</li>
</ul>
<p>Suppose that a particular study has standard error <span class="math inline">\(46\)</span>, and sample size <span class="math inline">\(37\)</span>. And suppose that the true <span class="math inline">\(\mu=15\)</span>, as in the example discussed above. Then, we can compute statistical power, Type S and M error through simulation in the following manner:</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="do">## probable effect size, derived from past studies:</span></span>
<span id="cb152-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb152-2" aria-hidden="true" tabindex="-1"></a>D <span class="ot">&lt;-</span> <span class="dv">15</span></span>
<span id="cb152-3"><a href="hypothesis-testing-the-one-sample-t-test.html#cb152-3" aria-hidden="true" tabindex="-1"></a><span class="do">## SE from the study of interest:</span></span>
<span id="cb152-4"><a href="hypothesis-testing-the-one-sample-t-test.html#cb152-4" aria-hidden="true" tabindex="-1"></a>se <span class="ot">&lt;-</span> <span class="dv">46</span></span>
<span id="cb152-5"><a href="hypothesis-testing-the-one-sample-t-test.html#cb152-5" aria-hidden="true" tabindex="-1"></a>stddev <span class="ot">&lt;-</span> se <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="dv">37</span>)</span>
<span id="cb152-6"><a href="hypothesis-testing-the-one-sample-t-test.html#cb152-6" aria-hidden="true" tabindex="-1"></a>nsim <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb152-7"><a href="hypothesis-testing-the-one-sample-t-test.html#cb152-7" aria-hidden="true" tabindex="-1"></a>drep <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, nsim)</span>
<span id="cb152-8"><a href="hypothesis-testing-the-one-sample-t-test.html#cb152-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nsim) {</span>
<span id="cb152-9"><a href="hypothesis-testing-the-one-sample-t-test.html#cb152-9" aria-hidden="true" tabindex="-1"></a>  samp <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">37</span>, <span class="at">mean =</span> D, <span class="at">sd =</span> stddev)</span>
<span id="cb152-10"><a href="hypothesis-testing-the-one-sample-t-test.html#cb152-10" aria-hidden="true" tabindex="-1"></a>  drep[i] <span class="ot">&lt;-</span> <span class="fu">mean</span>(samp)</span>
<span id="cb152-11"><a href="hypothesis-testing-the-one-sample-t-test.html#cb152-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Power can be computed by simply determining the proportion of times that the absolute observed t-value is larger than 2:</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb153-1" aria-hidden="true" tabindex="-1"></a><span class="do">## power: the proportion of cases where</span></span>
<span id="cb153-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb153-2" aria-hidden="true" tabindex="-1"></a><span class="do">## we reject the null hypothesis correctly:</span></span>
<span id="cb153-3"><a href="hypothesis-testing-the-one-sample-t-test.html#cb153-3" aria-hidden="true" tabindex="-1"></a>(pow <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">ifelse</span>(<span class="fu">abs</span>(drep <span class="sc">/</span> se) <span class="sc">&gt;</span> <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>)))</span></code></pre></div>
<pre><code>## [1] 0.0576</code></pre>
<p>Power is quite low here (we deliberately chose an example with low power to illustrate Type S and M error).</p>
<p>Next, we figure out which of the samples are statistically significant (which simulated values yield <span class="math inline">\(p&lt;0.05\)</span>). As a criterion, use a t-value of 2 to reject the null; this could have been done more precisely by working out an exact critical t-value for the given sample size.</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb155-1" aria-hidden="true" tabindex="-1"></a><span class="do">## which results in drep are significant at alpha=0.05?</span></span>
<span id="cb155-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb155-2" aria-hidden="true" tabindex="-1"></a>signif <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">abs</span>(drep <span class="sc">/</span> se) <span class="sc">&gt;</span> <span class="dv">2</span>)</span></code></pre></div>
<p>Type S error is the proportion of significant cases with the wrong sign (sign error), and Type M error is the ratio by which the true effect (of <span class="math inline">\(\mu=15\)</span>) is exaggerated in those simulations that happened to come out significant.</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Type S error rate | signif:</span></span>
<span id="cb156-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb156-2" aria-hidden="true" tabindex="-1"></a>(types_sig <span class="ot">&lt;-</span> <span class="fu">mean</span>(drep[signif] <span class="sc">&lt;</span> <span class="dv">0</span>))</span></code></pre></div>
<pre><code>## [1] 0.1615</code></pre>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb158-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Type M error rate | signif:</span></span>
<span id="cb158-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb158-2" aria-hidden="true" tabindex="-1"></a>(typem_sig <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">abs</span>(drep[signif]) <span class="sc">/</span> D))</span></code></pre></div>
<pre><code>## [1] 7.306</code></pre>
<p>In this scenario, when power is approximately 6%, whenever we get a significant effect, the probability of obtaining the wrong sign is a whopping 16% and the effect is likely to be 7.31 times larger than its true magnitude. The practical implication is as follows.</p>
<p>When power is low, relying on the p-value (statistical significance) to declare an effect as being present will be misleading <strong>even if the result is statistically significant</strong>. This is because the significant effect will be based on an overestimate of the effect (Type M error), and even the sign of the effect could be wrong. This isn’t just a theoretical point; it has real-world consequences for theory development. For an example from psycholinguistics regarding this point, see <span class="citation"><a href="#ref-VasishthMertzenJaegerGelman2018" role="doc-biblioref">S. Vasishth et al.</a> (<a href="#ref-VasishthMertzenJaegerGelman2018" role="doc-biblioref">2018</a>)</span>, <span class="citation"><a href="#ref-JaegerMertzenVanDykeVasishth2019" role="doc-biblioref">Lena A. Jäger et al.</a> (<a href="#ref-JaegerMertzenVanDykeVasishth2019" role="doc-biblioref">2020a</a>)</span>, and <span class="citation"><a href="#ref-MertzenEtAl2021" role="doc-biblioref">Mertzen et al.</a> (<a href="#ref-MertzenEtAl2021" role="doc-biblioref">2021</a>)</span>. In all these studies, an attempt was made to re-estimate published estimates of effects using larger sample sizes; in all cases, the larger sample sizes showed smaller estimates. In other words, the original published estimates, which were all based on low-powered studies, were over-estimates that did not replicate. A practical implication of Type M error is that “statistically significant effects” will not be “reliable” in any meaningful sense if power is low.</p>
<p>Another useful way to visualize Type M and S error is through the so-called funnel plot. As shown in Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:funnel">2.18</a>, estimates obtained from low-powered studies will tend to be exaggerated (the lower part of the funnel), and as power goes up, the effect estimates start to cluster tightly around the true value of the effect.</p>
<div class="figure"><span style="display:block;" id="fig:funnel"></span>
<img src="Freq_CogSci_files/figure-html/funnel-1.svg" alt="An illustration of a funnel plot. Shown are repeated samples of an effect estimate under different values of power, where the true value  of the effect is 15 (marked by the vertical line). Significant effects are shaded gray. The lower the power, the wider the fluctuation of the effect; under low power, it is the exaggerated effects that end up statistically significant, even though they are very biased relative to the true value. As power goes up, the effect estimates start to cluster around the true value, and significant effects are also accurate estimates of the effect. Thus, low power leads to exaggerated estimates of the effect, especially if the data are filtered by statistical significance." width="672" />
<p class="caption">
FIGURE 2.18: An illustration of a funnel plot. Shown are repeated samples of an effect estimate under different values of power, where the true value of the effect is 15 (marked by the vertical line). Significant effects are shaded gray. The lower the power, the wider the fluctuation of the effect; under low power, it is the exaggerated effects that end up statistically significant, even though they are very biased relative to the true value. As power goes up, the effect estimates start to cluster around the true value, and significant effects are also accurate estimates of the effect. Thus, low power leads to exaggerated estimates of the effect, especially if the data are filtered by statistical significance.
</p>
</div>
<p>What is important to appreciate here is the fact that significant effects “point to the truth” just in case power is high; when power is low, either null results will frequently be found <strong>even if the null is false</strong>, and those results that turn out significant will be based on Type M error. Thus, when power is low, <strong>all</strong> possible outcomes (significant or non-significant) from a statistical analysis based on a p-value will be meaningless in the sense that non-significant effects don’t allow us to accept the null hypothesis (due to low power), and significant effects are going to be based on exaggerated estimates that don’t reflect the true value.</p>
<p>In many fields, it is practically impossible to conduct a high-powered study. What should one do in this situation? When reporting results that are likely based on an underpowered study, the best approach is to (i) simply report estimates with confidence intervals and not make binary decisions like “effect present/absent,” (ii) openly acknowledge the power limitation, (iii) attempt to conduct a direct replication of the effect to establish robustness, and (iv) attempt to synthesize the evidence from existing knowledge <span class="citation">(<a href="#ref-cumming2014new" role="doc-biblioref">Cumming 2014</a>)</span>.</p>
<p>One can focus on reporting estimates in a paper as follows. For example, one can state that “the estimate of the mean effect was 50 ms, with 95% confidence interval [-10,110] ms. This estimate is consistent with the effect being present.” Such a wording does not make any discovery claim; it just reports that the estimate is consistent with the predicted direction. Such a reported estimate can be used in meta-analyses, facilitating cumulative acquisition of knowledge.</p>
<p>By direct replication, we mean that the study should be run multiple times with the same materials and design but new participants, to establish whether effect estimates in the original study and the replication study are consistent with each other. Direct replications stand in contrast to so-called conceptual replications, which are not exact repetitions of the original design, but involve some further or slightly different but related experimental manipulations. Conceptual replications are also a very useful tool for cross-validating the existence of an effect, but direct replications should be a standard way to validate the consistency of an effect.</p>
<p>Of course, truly direct replications are impossible to conduct because repeating a study will always differ from the original one in some way or another—the lab may differ, the protocols might differ slightly, the experimenter may be different, etc. Such between-study variability is obviously unavoidable in direct-replication attempts, but they are still worthwhile for establishing the existence of an effect. To make clearer the idea of establishing robustness through replication attempts, detailed examples of different kinds of replication attempts of published studies will be presented in this book’s example data sets.</p>
<p>Finally, meta-analysis is a very important tool for developing a good understanding of what has been learned in a field about a particular phenomenon. Meta-analysis has been largely neglected in psycholinguistics, with researchers classifying previous work using a voting method: researchers routinely count the number of studies that showed a significant vs. non-significant effect. As an example, <span class="citation"><a href="#ref-hammerly2019grammaticality" role="doc-biblioref">Hammerly, Staub, and Dillon</a> (<a href="#ref-hammerly2019grammaticality" role="doc-biblioref">2019</a>)</span> summarize the literature on a particular psycholinguistic phenomenon in this binary manner: “In our review, only 11 of the 22 studies that tested for the interaction indicative of the grammaticality asymmetry found a significant effect. Of the studies that ran contrasts to test for an effect of attractor number in grammatical sentences, 7 of the 20 studies found a significant effect, while all of the 16 studies that tested for effects of attractor number in ungrammatical sentences found a significant effect.” As discussed above, this kind of summary is quite meaningless if the power of the experiments is not known to be high. It is much better to summarize the literatuee using a meta-analysis, which reports an estimate based on all existing studies, along with an uncertainty interval. Later in the book, concrete examples of meta-analyses will be discussed.</p>
</div>
<div id="searching-for-significance" class="section level3" number="2.5.7">
<h3><span class="header-section-number">2.5.7</span> Searching for significance</h3>
<p>The NHST procedure is essentially a decision procedure: if <span class="math inline">\(p&lt;0.05\)</span>, we reject the null hypothesis; otherwise, we fail to reject the null. Because significant results are easier to publish than non-significant results, a common approach taken by researchers (including the first author of this book, when he was a graduate student) is to run the experiment and periodically check if statistical significance has been reached. The procedure can be described as follows:</p>
<ul>
<li>The experimenter gathers <span class="math inline">\(n\)</span> data points, then checks for significance (is <span class="math inline">\(p&lt;0.05\)</span> or not?).</li>
<li>If the result is not significant, they get more data (say, <span class="math inline">\(n\)</span> more data points). Then they check for significance again.</li>
</ul>
<p>Since time and money (and patience) are limited, the researcher might decide to stop collecting data after some multiple of <span class="math inline">\(n\)</span> have been collected.</p>
<p>One can simulate different scenarios here. Suppose that <span class="math inline">\(n\)</span> is initially <span class="math inline">\(15\)</span> subjects.<br />
Under the standard assumptions, set Type I error probability to be <span class="math inline">\(0.05\)</span>. Suppose that the null hypothesis that <span class="math inline">\(\mu=0\)</span> is in fact true, and that the standard deviation is <span class="math inline">\(250\)</span> ms (assuming a reading study).</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb160-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Standard properties of the t-test:</span></span>
<span id="cb160-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb160-2" aria-hidden="true" tabindex="-1"></a>pvals <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb160-3"><a href="hypothesis-testing-the-one-sample-t-test.html#cb160-3" aria-hidden="true" tabindex="-1"></a>tstat_standard <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb160-4"><a href="hypothesis-testing-the-one-sample-t-test.html#cb160-4" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">15</span></span>
<span id="cb160-5"><a href="hypothesis-testing-the-one-sample-t-test.html#cb160-5" aria-hidden="true" tabindex="-1"></a>nsim <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb160-6"><a href="hypothesis-testing-the-one-sample-t-test.html#cb160-6" aria-hidden="true" tabindex="-1"></a><span class="do">## assume a standard dev of 250:</span></span>
<span id="cb160-7"><a href="hypothesis-testing-the-one-sample-t-test.html#cb160-7" aria-hidden="true" tabindex="-1"></a>stddev <span class="ot">&lt;-</span> <span class="dv">250</span></span>
<span id="cb160-8"><a href="hypothesis-testing-the-one-sample-t-test.html#cb160-8" aria-hidden="true" tabindex="-1"></a>mn <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb160-9"><a href="hypothesis-testing-the-one-sample-t-test.html#cb160-9" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nsim) {</span>
<span id="cb160-10"><a href="hypothesis-testing-the-one-sample-t-test.html#cb160-10" aria-hidden="true" tabindex="-1"></a>  samp <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mn, <span class="at">sd =</span> stddev)</span>
<span id="cb160-11"><a href="hypothesis-testing-the-one-sample-t-test.html#cb160-11" aria-hidden="true" tabindex="-1"></a>  pvals[i] <span class="ot">&lt;-</span> <span class="fu">t.test</span>(samp)<span class="sc">$</span>p.value</span>
<span id="cb160-12"><a href="hypothesis-testing-the-one-sample-t-test.html#cb160-12" aria-hidden="true" tabindex="-1"></a>  tstat_standard[i] <span class="ot">&lt;-</span> <span class="fu">t.test</span>(samp)<span class="sc">$</span>statistic</span>
<span id="cb160-13"><a href="hypothesis-testing-the-one-sample-t-test.html#cb160-13" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Type I error rate is about 5%, consistent with our expectations:</p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb161-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">mean</span>(pvals <span class="sc">&lt;</span> <span class="fl">0.05</span>), <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.05</code></pre>
<p>But the situation quickly deteriorates as soon as we adopt the strategy outlined above. Below, we will also track the distribution of the t-statistic.</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-1" aria-hidden="true" tabindex="-1"></a>pvals <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb163-2"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-2" aria-hidden="true" tabindex="-1"></a>tstat <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb163-3"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-3" aria-hidden="true" tabindex="-1"></a><span class="do">## how many subjects can I run?</span></span>
<span id="cb163-4"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-4" aria-hidden="true" tabindex="-1"></a>upper_bound <span class="ot">&lt;-</span> n <span class="sc">*</span> <span class="dv">6</span></span>
<span id="cb163-5"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb163-6"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nsim) {</span>
<span id="cb163-7"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-7" aria-hidden="true" tabindex="-1"></a>  significant <span class="ot">&lt;-</span> <span class="cn">FALSE</span></span>
<span id="cb163-8"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-8" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mn, <span class="at">sd =</span> stddev) <span class="do">## take sample</span></span>
<span id="cb163-9"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">while</span> (<span class="sc">!</span>significant <span class="sc">&amp;</span> <span class="fu">length</span>(x) <span class="sc">&lt;</span> upper_bound) {</span>
<span id="cb163-10"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-10" aria-hidden="true" tabindex="-1"></a>    <span class="do">## if not significant:</span></span>
<span id="cb163-11"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">t.test</span>(x)<span class="sc">$</span>p.value <span class="sc">&gt;</span> <span class="fl">0.05</span>) {</span>
<span id="cb163-12"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-12" aria-hidden="true" tabindex="-1"></a>      <span class="do">## get more data</span></span>
<span id="cb163-13"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-13" aria-hidden="true" tabindex="-1"></a>      x <span class="ot">&lt;-</span> <span class="fu">append</span>(x, <span class="fu">rnorm</span>(n, <span class="at">mean =</span> mn, <span class="at">sd =</span> stddev))</span>
<span id="cb163-14"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-14" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> {</span>
<span id="cb163-15"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-15" aria-hidden="true" tabindex="-1"></a>      significant <span class="ot">&lt;-</span> <span class="cn">TRUE</span></span>
<span id="cb163-16"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-16" aria-hidden="true" tabindex="-1"></a>    } <span class="do">## otherwise stop:</span></span>
<span id="cb163-17"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-17" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb163-18"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-18" aria-hidden="true" tabindex="-1"></a>  pvals[i] <span class="ot">&lt;-</span> <span class="fu">t.test</span>(x)<span class="sc">$</span>p.value</span>
<span id="cb163-19"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-19" aria-hidden="true" tabindex="-1"></a>  tstat[i] <span class="ot">&lt;-</span> <span class="fu">t.test</span>(x)<span class="sc">$</span>statistic</span>
<span id="cb163-20"><a href="hypothesis-testing-the-one-sample-t-test.html#cb163-20" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Now, Type I error rate is much higher than 5%:</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="hypothesis-testing-the-one-sample-t-test.html#cb164-1" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">mean</span>(pvals <span class="sc">&lt;</span> <span class="fl">0.05</span>), <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.16</code></pre>
<p>Figure <a href="hypothesis-testing-the-one-sample-t-test.html#fig:stoppingrule">2.19</a> shows the distributions of the t-statistic in the standard case vs/ with the above stopping rule:</p>
<div class="figure"><span style="display:block;" id="fig:stoppingrule"></span>
<img src="Freq_CogSci_files/figure-html/stoppingrule-1.svg" alt="A comparison of the distribution of t-values with an a priori fixed stopping rule (solid line), versus a flexible stopping rule conditional on finding significance (broken line)." width="672" />
<p class="caption">
FIGURE 2.19: A comparison of the distribution of t-values with an a priori fixed stopping rule (solid line), versus a flexible stopping rule conditional on finding significance (broken line).
</p>
</div>
<p>What is important to realize here is that the inflation in the Type I error probability observed above was due to the fact that the t-distribution is no longer a t-distribution: there are bumps in the tails when we use the flexible stopping rule, and these raise the Type I error. This demonstrates why one should fix one’s sample size in advance, based on a power analysis. One should not deploy a stopping rule like the one above; if one uses such a stopping rule, there is a higher than 5% probability of incorrectly declaring a result as statistically significant than the original Type I error rate of 0.05.</p>
<p>There can be compelling reasons to adopt the above peek-and-run strategy; e.g., if one wants to avoid exposing patients to a treatment that might turn out to be harmful. In such situations, one can run an adaptive experimental trial by correcting for Type I error inflation <span class="citation">(<a href="#ref-pocock2013clinical" role="doc-biblioref">Pocock 2013</a>)</span>.</p>
<p>In this book, we will aim to develop a workflow whereby the sample size is fixed through power analysis, in advance of running an experiment.</p>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-benjamin2018redefine" class="csl-entry">
Benjamin, Daniel J, James O Berger, Magnus Johannesson, Brian A Nosek, E-J Wagenmakers, Richard Berk, Kenneth A Bollen, et al. 2018. <span>“Redefine Statistical Significance.”</span> <em>Nature Human Behaviour</em> 2 (1): 6.
</div>
<div id="ref-powerfailure" class="csl-entry">
Button, Katherine S, John PA Ioannidis, Claire Mokrysz, Brian A Nosek, Jonathan Flint, Emma SJ Robinson, and Marcus R Munafò. 2013. <span>“Power Failure: Why Small Sample Size Undermines the Reliability of Neuroscience.”</span> <em>Nature Reviews Neuroscience</em> 14 (5): 365–76.
</div>
<div id="ref-powerbookcohen" class="csl-entry">
Cohen, Jacob. 1988. <em><span class="nocase">Statistical power analysis for the behavioral sciences</span></em>. 2nd ed. Hillsdale, NJ: Lawrence Erlbaum.
</div>
<div id="ref-cumming2014new" class="csl-entry">
Cumming, Geoff. 2014. <span>“The New Statistics: Why and How.”</span> <em>Psychological Science</em> 25 (1): 7–29.
</div>
<div id="ref-Gelman14" class="csl-entry">
Gelman, Andrew, John B. Carlin, Hal S. Stern, David B. Dunson, Aki Vehtari, and Donald B. Rubin. 2014. <em>Bayesian Data Analysis</em>. Third. Boca Raton, FL: Chapman; Hall/CRC.
</div>
<div id="ref-hammerly2019grammaticality" class="csl-entry">
Hammerly, Christopher, Adrian Staub, and Brian W. Dillon. 2019. <span>“The Grammaticality Asymmetry in Agreement Attraction Reflects Response Bias: <span>E</span>xperimental and Modeling Evidence.”</span> <em>Cognitive Psychology</em> 110: 70–104.
</div>
<div id="ref-hedges1984estimation" class="csl-entry">
Hedges, Larry V. 1984. <span>“Estimation of Effect Size Under Nonrandom Sampling: The Effects of Censoring Studies Yielding Statistically Insignificant Mean Differences.”</span> <em>Journal of Educational Statistics</em> 9 (1): 61–85.
</div>
<div id="ref-ioannidis2008most" class="csl-entry">
Ioannidis, John PA. 2008. <span>“Why Most Discovered True Associations Are Inflated.”</span> <em>Epidemiology</em> 19 (5): 640–48.
</div>
<div id="ref-JaegerMertzenVanDykeVasishth2019" class="csl-entry">
Jäger, Lena A., Daniela Mertzen, Julie A. Van Dyke, and Shravan Vasishth. 2020a. <span>“Interference Patterns in Subject-Verb Agreement and Reflexives Revisited: <span>A</span> Large-Sample Study.”</span> <em>Journal of Memory and Language</em> 111. https://doi.org/<a href="https://doi.org/10.1016/j.jml.2019.104063">https://doi.org/10.1016/j.jml.2019.104063</a>.
</div>
<div id="ref-lane1978estimating" class="csl-entry">
Lane, David M, and William P Dunlap. 1978. <span>“Estimating Effect Size: Bias Resulting from the Significance Criterion in Editorial Decisions.”</span> <em>British Journal of Mathematical and Statistical Psychology</em> 31 (2): 107–12.
</div>
<div id="ref-MertzenEtAl2021" class="csl-entry">
Mertzen, Daniela, Dario Paape, Brian W. Dillon, Ralf Engbert, and Shravan Vasishth. 2021. <span>“Syntactic and Semantic Interference in Sentence Comprehension: <span class="nocase">Support from English and German eye-tracking data</span>.”</span>
</div>
<div id="ref-pocock2013clinical" class="csl-entry">
Pocock, Stuart J. 2013. <em>Clinical Trials: <span>A</span> Practical Approach</em>. John Wiley &amp; Sons.
</div>
<div id="ref-VasishthMertzenJaegerGelman2018" class="csl-entry">
Vasishth, Shravan, Daniela Mertzen, Lena A. Jäger, and Andrew Gelman. 2018. <span>“The Statistical Significance Filter Leads to Overoptimistic Expectations of Replicability.”</span> <em>Journal of Memory and Language</em> 103: 151–75. https://doi.org/<a href="https://doi.org/10.1016/j.jml.2018.07.004">https://doi.org/10.1016/j.jml.2018.07.004</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="the-confidence-interval-and-what-its-good-for.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="the-two-sample-t-test-vs.-the-paired-t-test.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown/edit/master/inst/examples/02-SamplingDistributions.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Freq_CogSci.pdf", "Freq_CogSci.epub", "Freq_CogSci.mobi"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
