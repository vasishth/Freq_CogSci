<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.6 Shrinkage in linear mixed models | Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction</title>
  <meta name="description" content="Linear Mixed Models for Linguistics and Psychology: A Comprehensive Introduction" />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="3.6 Shrinkage in linear mixed models | Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://github.com/vasishth/Freq_CogSci/images/temporarycover.jpg" />
  <meta property="og:description" content="Linear Mixed Models for Linguistics and Psychology: A Comprehensive Introduction" />
  <meta name="github-repo" content="https://github.com/vasishth/Freq_CogSci" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.6 Shrinkage in linear mixed models | Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction" />
  
  <meta name="twitter:description" content="Linear Mixed Models for Linguistics and Psychology: A Comprehensive Introduction" />
  <meta name="twitter:image" content="https://github.com/vasishth/Freq_CogSci/images/temporarycover.jpg" />

<meta name="author" content="Shravan Vasishth, Daniel Schad, Audrey Bürki, Reinhold Kliegl" />


<meta name="date" content="2022-08-14" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="linear-mixed-models.html"/>
<link rel="next" href="summary-2.html"/>
<script src="libs/jquery/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections/anchor-sections.js"></script>
<script src="libs/kePrint/kePrint.js"></script>
<link href="libs/lightable/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Linear Mixed Models in Linguistics and Psychology</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="" data-path="how-to-read-this-book.html"><a href="how-to-read-this-book.html"><i class="fa fa-check"></i>How to read this book</a></li>
<li class="chapter" data-level="" data-path="online-materials.html"><a href="online-materials.html"><i class="fa fa-check"></i>Online materials</a></li>
<li class="chapter" data-level="" data-path="software-needed.html"><a href="software-needed.html"><i class="fa fa-check"></i>Software needed</a></li>
<li class="chapter" data-level="" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="part"><span><b>I Foundational ideas</b></span></li>
<li class="chapter" data-level="1" data-path="some-important-facts-about-distributions.html"><a href="some-important-facts-about-distributions.html"><i class="fa fa-check"></i><b>1</b> Some important facts about distributions</a>
<ul>
<li class="chapter" data-level="1.1" data-path="discrete-random-variables-an-example-using-the-binomial-distribution.html"><a href="discrete-random-variables-an-example-using-the-binomial-distribution.html"><i class="fa fa-check"></i><b>1.1</b> Discrete random variables: An example using the Binomial distribution</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="discrete-random-variables-an-example-using-the-binomial-distribution.html"><a href="discrete-random-variables-an-example-using-the-binomial-distribution.html#the-mean-and-variance-of-the-binomial-distribution"><i class="fa fa-check"></i><b>1.1.1</b> The mean and variance of the Binomial distribution</a></li>
<li class="chapter" data-level="1.1.2" data-path="discrete-random-variables-an-example-using-the-binomial-distribution.html"><a href="discrete-random-variables-an-example-using-the-binomial-distribution.html#what-information-does-a-probability-distribution-provide"><i class="fa fa-check"></i><b>1.1.2</b> What information does a probability distribution provide?</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="continuous-random-variables-an-example-using-the-normal-distribution.html"><a href="continuous-random-variables-an-example-using-the-normal-distribution.html"><i class="fa fa-check"></i><b>1.2</b> Continuous random variables: An example using the Normal distribution</a></li>
<li class="chapter" data-level="1.3" data-path="other-common-distributions.html"><a href="other-common-distributions.html"><i class="fa fa-check"></i><b>1.3</b> Other common distributions</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="other-common-distributions.html"><a href="other-common-distributions.html#the-standard-normal-mathitnormalmu0sigma1"><i class="fa fa-check"></i><b>1.3.1</b> The standard normal: <span class="math inline">\(\mathit{normal}(\mu=0,\sigma=1)\)</span></a></li>
<li class="chapter" data-level="1.3.2" data-path="other-common-distributions.html"><a href="other-common-distributions.html#the-uniform-distribution"><i class="fa fa-check"></i><b>1.3.2</b> The uniform distribution</a></li>
<li class="chapter" data-level="1.3.3" data-path="other-common-distributions.html"><a href="other-common-distributions.html#the-chi-square-distribution"><i class="fa fa-check"></i><b>1.3.3</b> The Chi-square distribution</a></li>
<li class="chapter" data-level="1.3.4" data-path="other-common-distributions.html"><a href="other-common-distributions.html#the-t-distribution"><i class="fa fa-check"></i><b>1.3.4</b> The t-distribution</a></li>
<li class="chapter" data-level="1.3.5" data-path="other-common-distributions.html"><a href="other-common-distributions.html#the-f-distribution"><i class="fa fa-check"></i><b>1.3.5</b> The F distribution</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="bivariate-and-multivariate-distributions.html"><a href="bivariate-and-multivariate-distributions.html"><i class="fa fa-check"></i><b>1.4</b> Bivariate and multivariate distributions</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="bivariate-and-multivariate-distributions.html"><a href="bivariate-and-multivariate-distributions.html#example-1-discrete-bivariate-distributions"><i class="fa fa-check"></i><b>1.4.1</b> Example 1: Discrete bivariate distributions</a></li>
<li class="chapter" data-level="1.4.2" data-path="bivariate-and-multivariate-distributions.html"><a href="bivariate-and-multivariate-distributions.html#example-2-continuous-bivariate-distributions"><i class="fa fa-check"></i><b>1.4.2</b> Example 2: Continuous bivariate distributions</a></li>
<li class="chapter" data-level="1.4.3" data-path="bivariate-and-multivariate-distributions.html"><a href="bivariate-and-multivariate-distributions.html#generate-simulated-bivariate-multivariate-data"><i class="fa fa-check"></i><b>1.4.3</b> Generate simulated bivariate (multivariate) data</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="likelihood-and-maximum-likelihood-estimation.html"><a href="likelihood-and-maximum-likelihood-estimation.html"><i class="fa fa-check"></i><b>1.5</b> Likelihood and maximum likelihood estimation</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="likelihood-and-maximum-likelihood-estimation.html"><a href="likelihood-and-maximum-likelihood-estimation.html#the-importance-of-the-mle"><i class="fa fa-check"></i><b>1.5.1</b> The importance of the MLE</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="useful-r-functions-relating-to-univariate-distributions.html"><a href="useful-r-functions-relating-to-univariate-distributions.html"><i class="fa fa-check"></i><b>1.6</b> Useful R functions relating to univariate distributions</a></li>
<li class="chapter" data-level="1.7" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>1.7</b> Summary</a></li>
<li class="chapter" data-level="1.8" data-path="further-reading.html"><a href="further-reading.html"><i class="fa fa-check"></i><b>1.8</b> Further reading</a></li>
<li class="chapter" data-level="1.9" data-path="sec:Foundationsexercises.html"><a href="sec:Foundationsexercises.html"><i class="fa fa-check"></i><b>1.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="hypothetical-repeated-sampling-and-the-t-test.html"><a href="hypothetical-repeated-sampling-and-the-t-test.html"><i class="fa fa-check"></i><b>2</b> Hypothetical repeated sampling and the t-test</a>
<ul>
<li class="chapter" data-level="2.1" data-path="some-terminology-surrounding-typical-experiment-designs-in-linguistics-and-psychology.html"><a href="some-terminology-surrounding-typical-experiment-designs-in-linguistics-and-psychology.html"><i class="fa fa-check"></i><b>2.1</b> Some terminology surrounding typical experiment designs in linguistics and psychology</a></li>
<li class="chapter" data-level="2.2" data-path="the-central-limit-theorem-using-simulation.html"><a href="the-central-limit-theorem-using-simulation.html"><i class="fa fa-check"></i><b>2.2</b> The central limit theorem using simulation</a></li>
<li class="chapter" data-level="2.3" data-path="three-examples-of-the-sampling-distribution.html"><a href="three-examples-of-the-sampling-distribution.html"><i class="fa fa-check"></i><b>2.3</b> Three examples of the sampling distribution</a></li>
<li class="chapter" data-level="2.4" data-path="the-confidence-interval-and-what-its-good-for.html"><a href="the-confidence-interval-and-what-its-good-for.html"><i class="fa fa-check"></i><b>2.4</b> The confidence interval, and what it’s good for</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="the-confidence-interval-and-what-its-good-for.html"><a href="the-confidence-interval-and-what-its-good-for.html#confidence-interals-are-often-misinterpreted"><i class="fa fa-check"></i><b>2.4.1</b> Confidence interals are often misinterpreted</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html"><i class="fa fa-check"></i><b>2.5</b> Hypothesis testing: The one sample t-test</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#the-one-sample-t-test"><i class="fa fa-check"></i><b>2.5.1</b> The one-sample t-test</a></li>
<li class="chapter" data-level="2.5.2" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#type-i-ii-error-and-power"><i class="fa fa-check"></i><b>2.5.2</b> Type I, II error, and power</a></li>
<li class="chapter" data-level="2.5.3" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#how-to-compute-power-for-the-one-sample-t-test"><i class="fa fa-check"></i><b>2.5.3</b> How to compute power for the one-sample t-test</a></li>
<li class="chapter" data-level="2.5.4" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#the-p-value"><i class="fa fa-check"></i><b>2.5.4</b> The p-value</a></li>
<li class="chapter" data-level="2.5.5" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#the-distribution-of-the-p-value-under-the-null-hypothesis"><i class="fa fa-check"></i><b>2.5.5</b> The distribution of the p-value under the null hypothesis</a></li>
<li class="chapter" data-level="2.5.6" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#type-m-and-s-error-in-the-face-of-low-power"><i class="fa fa-check"></i><b>2.5.6</b> Type M and S error in the face of low power</a></li>
<li class="chapter" data-level="2.5.7" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#searching-for-significance"><i class="fa fa-check"></i><b>2.5.7</b> Searching for significance</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="the-two-sample-t-test-vs.html"><a href="the-two-sample-t-test-vs.html"><i class="fa fa-check"></i><b>2.6</b> The two-sample t-test vs. the paired t-test</a></li>
<li class="chapter" data-level="2.7" data-path="using-paired-t-tests-in-complex-factorial-designs.html"><a href="using-paired-t-tests-in-complex-factorial-designs.html"><i class="fa fa-check"></i><b>2.7</b> Using paired t-tests in complex factorial designs</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="using-paired-t-tests-in-complex-factorial-designs.html"><a href="using-paired-t-tests-in-complex-factorial-designs.html#analyzing-a-2times-2-repeated-measures-design-using-paired-t-tests"><i class="fa fa-check"></i><b>2.7.1</b> Analyzing a <span class="math inline">\(2\times 2\)</span> repeated measures design using paired t-tests</a></li>
<li class="chapter" data-level="2.7.2" data-path="using-paired-t-tests-in-complex-factorial-designs.html"><a href="using-paired-t-tests-in-complex-factorial-designs.html#a-complication-with-multiple-t-tests-inflation-of-type-i-error-probability"><i class="fa fa-check"></i><b>2.7.2</b> A complication with multiple t-tests: Inflation of Type I error probability</a></li>
<li class="chapter" data-level="2.7.3" data-path="using-paired-t-tests-in-complex-factorial-designs.html"><a href="using-paired-t-tests-in-complex-factorial-designs.html#analyzing-a-2times-2times-2-repeated-measures-design-using-paired-t-tests"><i class="fa fa-check"></i><b>2.7.3</b> Analyzing a <span class="math inline">\(2\times 2\times 2\)</span> repeated measures design using paired t-tests</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="common-mistakes-involving-the-paired-t-test.html"><a href="common-mistakes-involving-the-paired-t-test.html"><i class="fa fa-check"></i><b>2.8</b> Common mistakes involving the (paired) t-test</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="common-mistakes-involving-the-paired-t-test.html"><a href="common-mistakes-involving-the-paired-t-test.html#ignoring-the-independence-assumption"><i class="fa fa-check"></i><b>2.8.1</b> Ignoring the independence assumption</a></li>
<li class="chapter" data-level="2.8.2" data-path="common-mistakes-involving-the-paired-t-test.html"><a href="common-mistakes-involving-the-paired-t-test.html#doing-a-by-subjects-and-by-items-paired-t-test-is-generally-dangerous"><i class="fa fa-check"></i><b>2.8.2</b> Doing a by-subjects and by-items paired t-test is generally dangerous</a></li>
<li class="chapter" data-level="2.8.3" data-path="common-mistakes-involving-the-paired-t-test.html"><a href="common-mistakes-involving-the-paired-t-test.html#the-difference-between-a-significant-and-a-non-significant-result-need-not-itself-be-significant"><i class="fa fa-check"></i><b>2.8.3</b> The difference between a significant and a non-significant result need not itself be significant</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>2.9</b> Summary</a></li>
<li class="chapter" data-level="2.10" data-path="further-readings.html"><a href="further-readings.html"><i class="fa fa-check"></i><b>2.10</b> Further readings</a></li>
<li class="chapter" data-level="2.11" data-path="sec:SamplingDistrnexercises.html"><a href="sec:SamplingDistrnexercises.html"><i class="fa fa-check"></i><b>2.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-models-and-linear-mixed-models.html"><a href="linear-models-and-linear-mixed-models.html"><i class="fa fa-check"></i><b>3</b> Linear models and linear mixed models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="from-the-t-test-to-the-linear-mixed-model.html"><a href="from-the-t-test-to-the-linear-mixed-model.html"><i class="fa fa-check"></i><b>3.1</b> From the t-test to the linear (mixed) model</a></li>
<li class="chapter" data-level="3.2" data-path="sum-coding.html"><a href="sum-coding.html"><i class="fa fa-check"></i><b>3.2</b> Sum coding</a></li>
<li class="chapter" data-level="3.3" data-path="checking-model-assumptions.html"><a href="checking-model-assumptions.html"><i class="fa fa-check"></i><b>3.3</b> Checking model assumptions</a></li>
<li class="chapter" data-level="3.4" data-path="from-the-paired-t-test-to-the-linear-mixed-model.html"><a href="from-the-paired-t-test-to-the-linear-mixed-model.html"><i class="fa fa-check"></i><b>3.4</b> From the paired t-test to the linear mixed model</a></li>
<li class="chapter" data-level="3.5" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>3.5</b> Linear mixed models</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#model-type-1-varying-intercepts"><i class="fa fa-check"></i><b>3.5.1</b> Model type 1: Varying intercepts</a></li>
<li class="chapter" data-level="3.5.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#the-formal-statement-of-the-varying-intercepts-model"><i class="fa fa-check"></i><b>3.5.2</b> The formal statement of the varying intercepts model</a></li>
<li class="chapter" data-level="3.5.3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#model-type-2-varying-intercepts-and-varying-slopes-without-a-correlation"><i class="fa fa-check"></i><b>3.5.3</b> Model type 2: Varying intercepts and varying slopes, without a correlation</a></li>
<li class="chapter" data-level="3.5.4" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#model-type-3-varying-intercepts-and-varying-slopes-with-correlation"><i class="fa fa-check"></i><b>3.5.4</b> Model type 3: Varying intercepts and varying slopes, with correlation</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="shrinkage-in-linear-mixed-models.html"><a href="shrinkage-in-linear-mixed-models.html"><i class="fa fa-check"></i><b>3.6</b> Shrinkage in linear mixed models</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="shrinkage-in-linear-mixed-models.html"><a href="shrinkage-in-linear-mixed-models.html#shrinkage-of-extreme-estimates-from-individual-subjects"><i class="fa fa-check"></i><b>3.6.1</b> Shrinkage of extreme estimates from individual subjects</a></li>
<li class="chapter" data-level="3.6.2" data-path="shrinkage-in-linear-mixed-models.html"><a href="shrinkage-in-linear-mixed-models.html#shrinkage-when-data-are-missing"><i class="fa fa-check"></i><b>3.6.2</b> Shrinkage when data are missing</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="summary-2.html"><a href="summary-2.html"><i class="fa fa-check"></i><b>3.7</b> Summary</a></li>
<li class="chapter" data-level="3.8" data-path="further-reading-1.html"><a href="further-reading-1.html"><i class="fa fa-check"></i><b>3.8</b> Further reading</a></li>
<li class="chapter" data-level="3.9" data-path="sec:LMExercises1.html"><a href="sec:LMExercises1.html"><i class="fa fa-check"></i><b>3.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="hypothesis-testing-using-the-likelihood-ratio-test.html"><a href="hypothesis-testing-using-the-likelihood-ratio-test.html"><i class="fa fa-check"></i><b>4</b> Hypothesis testing using the likelihood ratio test</a>
<ul>
<li class="chapter" data-level="4.1" data-path="the-likelihood-ratio-test-the-theory.html"><a href="the-likelihood-ratio-test-the-theory.html"><i class="fa fa-check"></i><b>4.1</b> The likelihood ratio test: The theory</a></li>
<li class="chapter" data-level="4.2" data-path="a-practical-example-using-simulated-data.html"><a href="a-practical-example-using-simulated-data.html"><i class="fa fa-check"></i><b>4.2</b> A practical example using simulated data</a></li>
<li class="chapter" data-level="4.3" data-path="a-real-life-example-the-english-relative-clause-data.html"><a href="a-real-life-example-the-english-relative-clause-data.html"><i class="fa fa-check"></i><b>4.3</b> A real-life example: The English relative clause data</a></li>
<li class="chapter" data-level="4.4" data-path="summary-3.html"><a href="summary-3.html"><i class="fa fa-check"></i><b>4.4</b> Summary</a></li>
<li class="chapter" data-level="4.5" data-path="further-reading-2.html"><a href="further-reading-2.html"><i class="fa fa-check"></i><b>4.5</b> Further reading</a></li>
<li class="chapter" data-level="4.6" data-path="sec:HypTestExercises.html"><a href="sec:HypTestExercises.html"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="ch:LMtheory.html"><a href="ch:LMtheory.html"><i class="fa fa-check"></i><b>5</b> Linear modeling theory</a>
<ul>
<li class="chapter" data-level="5.1" data-path="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html"><a href="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html"><i class="fa fa-check"></i><b>5.1</b> A quick review of some basic concepts in matrix algebra</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html"><a href="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html#matrix-addition-subtraction-and-multiplication"><i class="fa fa-check"></i><b>5.1.1</b> Matrix addition, subtraction, and multiplication</a></li>
<li class="chapter" data-level="5.1.2" data-path="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html"><a href="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html#diagonal-matrix-and-identity-matrix"><i class="fa fa-check"></i><b>5.1.2</b> Diagonal matrix and identity matrix</a></li>
<li class="chapter" data-level="5.1.3" data-path="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html"><a href="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html#powers-of-matrices"><i class="fa fa-check"></i><b>5.1.3</b> Powers of matrices</a></li>
<li class="chapter" data-level="5.1.4" data-path="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html"><a href="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html#inverse-of-a-matrix"><i class="fa fa-check"></i><b>5.1.4</b> Inverse of a matrix</a></li>
<li class="chapter" data-level="5.1.5" data-path="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html"><a href="a-quick-review-of-some-basic-concepts-in-matrix-algebra.html#linear-independence-and-rank"><i class="fa fa-check"></i><b>5.1.5</b> Linear independence, and rank</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="the-essentials-of-linear-modeling-theory.html"><a href="the-essentials-of-linear-modeling-theory.html"><i class="fa fa-check"></i><b>5.2</b> The essentials of linear modeling theory</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="the-essentials-of-linear-modeling-theory.html"><a href="the-essentials-of-linear-modeling-theory.html#least-squares-estimation-geometric-argument"><i class="fa fa-check"></i><b>5.2.1</b> Least squares estimation: Geometric argument</a></li>
<li class="chapter" data-level="5.2.2" data-path="the-essentials-of-linear-modeling-theory.html"><a href="the-essentials-of-linear-modeling-theory.html#the-expectation-and-variance-of-the-parameters-beta"><i class="fa fa-check"></i><b>5.2.2</b> The expectation and variance of the parameters beta</a></li>
<li class="chapter" data-level="5.2.3" data-path="the-essentials-of-linear-modeling-theory.html"><a href="the-essentials-of-linear-modeling-theory.html#hypothesis-testing-using-analysis-of-variance-anova"><i class="fa fa-check"></i><b>5.2.3</b> Hypothesis testing using Analysis of variance (ANOVA)</a></li>
<li class="chapter" data-level="5.2.4" data-path="the-essentials-of-linear-modeling-theory.html"><a href="the-essentials-of-linear-modeling-theory.html#some-further-important-topics-in-linear-modeling"><i class="fa fa-check"></i><b>5.2.4</b> Some further important topics in linear modeling</a></li>
<li class="chapter" data-level="5.2.5" data-path="the-essentials-of-linear-modeling-theory.html"><a href="the-essentials-of-linear-modeling-theory.html#generalized-linear-models"><i class="fa fa-check"></i><b>5.2.5</b> Generalized linear models</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="summary-4.html"><a href="summary-4.html"><i class="fa fa-check"></i><b>5.3</b> Summary</a></li>
<li class="chapter" data-level="5.4" data-path="further-reading-3.html"><a href="further-reading-3.html"><i class="fa fa-check"></i><b>5.4</b> Further reading</a></li>
<li class="chapter" data-level="5.5" data-path="sec:LMExercises2.html"><a href="sec:LMExercises2.html"><i class="fa fa-check"></i><b>5.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="ch:contr.html"><a href="ch:contr.html"><i class="fa fa-check"></i><b>6</b> Contrast coding</a>
<ul>
<li class="chapter" data-level="6.1" data-path="basic-concepts-illustrated-using-a-two-level-factor.html"><a href="basic-concepts-illustrated-using-a-two-level-factor.html"><i class="fa fa-check"></i><b>6.1</b> Basic concepts illustrated using a two-level factor</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="basic-concepts-illustrated-using-a-two-level-factor.html"><a href="basic-concepts-illustrated-using-a-two-level-factor.html#treatmentcontrasts"><i class="fa fa-check"></i><b>6.1.1</b> Default contrast coding: Treatment contrasts</a></li>
<li class="chapter" data-level="6.1.2" data-path="basic-concepts-illustrated-using-a-two-level-factor.html"><a href="basic-concepts-illustrated-using-a-two-level-factor.html#inverseMatrix"><i class="fa fa-check"></i><b>6.1.2</b> Defining hypotheses</a></li>
<li class="chapter" data-level="6.1.3" data-path="basic-concepts-illustrated-using-a-two-level-factor.html"><a href="basic-concepts-illustrated-using-a-two-level-factor.html#effectcoding"><i class="fa fa-check"></i><b>6.1.3</b> Sum contrasts</a></li>
<li class="chapter" data-level="6.1.4" data-path="basic-concepts-illustrated-using-a-two-level-factor.html"><a href="basic-concepts-illustrated-using-a-two-level-factor.html#sec:cellMeans"><i class="fa fa-check"></i><b>6.1.4</b> Cell means parameterization and posterior comparisons</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html"><a href="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html"><i class="fa fa-check"></i><b>6.2</b> The hypothesis matrix illustrated with a three-level factor</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html"><a href="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html#sumcontrasts"><i class="fa fa-check"></i><b>6.2.1</b> Sum contrasts</a></li>
<li class="chapter" data-level="6.2.2" data-path="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html"><a href="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html#the-hypothesis-matrix"><i class="fa fa-check"></i><b>6.2.2</b> The hypothesis matrix</a></li>
<li class="chapter" data-level="6.2.3" data-path="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html"><a href="the-hypothesis-matrix-illustrated-with-a-three-level-factor.html#generating-contrasts-the-hypr-package"><i class="fa fa-check"></i><b>6.2.3</b> Generating contrasts: The <code>hypr</code> package</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="sec:4levelFactor.html"><a href="sec:4levelFactor.html"><i class="fa fa-check"></i><b>6.3</b> Further examples of contrasts illustrated with a factor with four levels</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="sec:4levelFactor.html"><a href="sec:4levelFactor.html#repeatedcontrasts"><i class="fa fa-check"></i><b>6.3.1</b> Repeated contrasts</a></li>
<li class="chapter" data-level="6.3.2" data-path="sec:4levelFactor.html"><a href="sec:4levelFactor.html#contrasts-in-linear-regression-analysis-the-design-or-model-matrix"><i class="fa fa-check"></i><b>6.3.2</b> Contrasts in linear regression analysis: The design or model matrix</a></li>
<li class="chapter" data-level="6.3.3" data-path="sec:4levelFactor.html"><a href="sec:4levelFactor.html#polynomialContrasts"><i class="fa fa-check"></i><b>6.3.3</b> Polynomial contrasts</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="nonOrthogonal.html"><a href="nonOrthogonal.html"><i class="fa fa-check"></i><b>6.4</b> What makes a good set of contrasts?</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="nonOrthogonal.html"><a href="nonOrthogonal.html#centered-contrasts"><i class="fa fa-check"></i><b>6.4.1</b> Centered contrasts</a></li>
<li class="chapter" data-level="6.4.2" data-path="nonOrthogonal.html"><a href="nonOrthogonal.html#orthogonal-contrasts"><i class="fa fa-check"></i><b>6.4.2</b> Orthogonal contrasts</a></li>
<li class="chapter" data-level="6.4.3" data-path="nonOrthogonal.html"><a href="nonOrthogonal.html#the-role-of-the-intercept-in-non-centered-contrasts"><i class="fa fa-check"></i><b>6.4.3</b> The role of the intercept in non-centered contrasts</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="summary-5.html"><a href="summary-5.html"><i class="fa fa-check"></i><b>6.5</b> Summary</a></li>
<li class="chapter" data-level="6.6" data-path="further-reading-4.html"><a href="further-reading-4.html"><i class="fa fa-check"></i><b>6.6</b> Further reading</a></li>
<li class="chapter" data-level="6.7" data-path="sec:Contrastsexercises.html"><a href="sec:Contrastsexercises.html"><i class="fa fa-check"></i><b>6.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="ch:coding2x2.html"><a href="ch:coding2x2.html"><i class="fa fa-check"></i><b>7</b> Contrast coding for designs with two predictor variables</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sec:MR:ANOVA.html"><a href="sec:MR:ANOVA.html"><i class="fa fa-check"></i><b>7.1</b> Contrast coding in a factorial 2 x 2 design</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="sec:MR:ANOVA.html"><a href="sec:MR:ANOVA.html#the-difference-between-an-anova-and-a-multiple-regression"><i class="fa fa-check"></i><b>7.1.1</b> The difference between an ANOVA and a multiple regression</a></li>
<li class="chapter" data-level="7.1.2" data-path="sec:MR:ANOVA.html"><a href="sec:MR:ANOVA.html#nestedEffects"><i class="fa fa-check"></i><b>7.1.2</b> Nested effects</a></li>
<li class="chapter" data-level="7.1.3" data-path="sec:MR:ANOVA.html"><a href="sec:MR:ANOVA.html#interactions-between-contrasts"><i class="fa fa-check"></i><b>7.1.3</b> Interactions between contrasts</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="sec:contrast:covariate.html"><a href="sec:contrast:covariate.html"><i class="fa fa-check"></i><b>7.2</b> One factor and one covariate</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="sec:contrast:covariate.html"><a href="sec:contrast:covariate.html#estimating-a-group-difference-and-controlling-for-a-covariate"><i class="fa fa-check"></i><b>7.2.1</b> Estimating a group-difference and controlling for a covariate</a></li>
<li class="chapter" data-level="7.2.2" data-path="sec:contrast:covariate.html"><a href="sec:contrast:covariate.html#estimating-differences-in-slopes"><i class="fa fa-check"></i><b>7.2.2</b> Estimating differences in slopes</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="sec:interactions:NLM.html"><a href="sec:interactions:NLM.html"><i class="fa fa-check"></i><b>7.3</b> Interactions in generalized linear models (with non-linear link functions)</a></li>
<li class="chapter" data-level="7.4" data-path="summary-6.html"><a href="summary-6.html"><i class="fa fa-check"></i><b>7.4</b> Summary</a></li>
<li class="chapter" data-level="7.5" data-path="sec:Contrasts2x2exercises.html"><a href="sec:Contrasts2x2exercises.html"><i class="fa fa-check"></i><b>7.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="using-simulation-to-understand-your-model.html"><a href="using-simulation-to-understand-your-model.html"><i class="fa fa-check"></i><b>8</b> Using simulation to understand your model</a>
<ul>
<li class="chapter" data-level="8.1" data-path="a-reminder-the-maximal-linear-mixed-model.html"><a href="a-reminder-the-maximal-linear-mixed-model.html"><i class="fa fa-check"></i><b>8.1</b> A reminder: The maximal linear mixed model</a></li>
<li class="chapter" data-level="8.2" data-path="obtain-estimates-from-a-previous-study.html"><a href="obtain-estimates-from-a-previous-study.html"><i class="fa fa-check"></i><b>8.2</b> Obtain estimates from a previous study</a></li>
<li class="chapter" data-level="8.3" data-path="decide-on-a-range-of-plausible-values-of-the-effect-size.html"><a href="decide-on-a-range-of-plausible-values-of-the-effect-size.html"><i class="fa fa-check"></i><b>8.3</b> Decide on a range of plausible values of the effect size</a></li>
<li class="chapter" data-level="8.4" data-path="extract-parameter-estimates.html"><a href="extract-parameter-estimates.html"><i class="fa fa-check"></i><b>8.4</b> Extract parameter estimates</a></li>
<li class="chapter" data-level="8.5" data-path="define-a-function-for-generating-data.html"><a href="define-a-function-for-generating-data.html"><i class="fa fa-check"></i><b>8.5</b> Define a function for generating data</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="define-a-function-for-generating-data.html"><a href="define-a-function-for-generating-data.html#generate-a-latin-square-design"><i class="fa fa-check"></i><b>8.5.1</b> Generate a Latin-square design</a></li>
<li class="chapter" data-level="8.5.2" data-path="define-a-function-for-generating-data.html"><a href="define-a-function-for-generating-data.html#generate-data-row-by-row"><i class="fa fa-check"></i><b>8.5.2</b> Generate data row-by-row</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="repeated-generation-of-data-to-compute-power.html"><a href="repeated-generation-of-data-to-compute-power.html"><i class="fa fa-check"></i><b>8.6</b> Repeated generation of data to compute power</a></li>
<li class="chapter" data-level="8.7" data-path="what-you-can-now-do.html"><a href="what-you-can-now-do.html"><i class="fa fa-check"></i><b>8.7</b> What you can now do</a></li>
<li class="chapter" data-level="8.8" data-path="using-the-package-designr-to-simulate-data-and-compute-power.html"><a href="using-the-package-designr-to-simulate-data-and-compute-power.html"><i class="fa fa-check"></i><b>8.8</b> Using the package <code>designr</code> to simulate data and compute power</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="using-the-package-designr-to-simulate-data-and-compute-power.html"><a href="using-the-package-designr-to-simulate-data-and-compute-power.html#simulating-data-with-two-conditions"><i class="fa fa-check"></i><b>8.8.1</b> Simulating data with two conditions</a></li>
<li class="chapter" data-level="8.8.2" data-path="using-the-package-designr-to-simulate-data-and-compute-power.html"><a href="using-the-package-designr-to-simulate-data-and-compute-power.html#simulating-data-in-factorial-designs"><i class="fa fa-check"></i><b>8.8.2</b> Simulating data in factorial designs</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="sec:Simulationexercises.html"><a href="sec:Simulationexercises.html"><i class="fa fa-check"></i><b>8.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ch:MultComp.html"><a href="ch:MultComp.html"><i class="fa fa-check"></i><b>9</b> Understanding Type I error inflation using simulation</a>
<ul>
<li class="chapter" data-level="9.1" data-path="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html"><a href="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html"><i class="fa fa-check"></i><b>9.1</b> Overly simple random effects structure in LMMs inflate Type I error</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html"><a href="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html#type-i-error-with-a-varying-intercepts-only-model"><i class="fa fa-check"></i><b>9.1.1</b> Type I error with a varying intercepts-only model</a></li>
<li class="chapter" data-level="9.1.2" data-path="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html"><a href="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html#type-i-error-with-a-varying-intercepts-and-varying-slopes-model"><i class="fa fa-check"></i><b>9.1.2</b> Type I error with a varying intercepts and varying slopes model</a></li>
<li class="chapter" data-level="9.1.3" data-path="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html"><a href="overly-simple-random-effects-structure-in-lmms-inflate-type-i-error.html#type-i-error-inflation-due-to-model-mis-specification"><i class="fa fa-check"></i><b>9.1.3</b> Type I error inflation due to model mis-specification</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="type-i-error-inflation-due-to-multiple-comparisons.html"><a href="type-i-error-inflation-due-to-multiple-comparisons.html"><i class="fa fa-check"></i><b>9.2</b> Type I error inflation due to multiple comparisons</a></li>
<li class="chapter" data-level="9.3" data-path="the-practical-implications.html"><a href="the-practical-implications.html"><i class="fa fa-check"></i><b>9.3</b> The practical implications</a></li>
<li class="chapter" data-level="9.4" data-path="summary-7.html"><a href="summary-7.html"><i class="fa fa-check"></i><b>9.4</b> Summary</a></li>
<li class="chapter" data-level="9.5" data-path="further-reading-5.html"><a href="further-reading-5.html"><i class="fa fa-check"></i><b>9.5</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="shrinkage-in-linear-mixed-models" class="section level2 hasAnchor" number="3.6">
<h2><span class="header-section-number">3.6</span> Shrinkage in linear mixed models<a href="shrinkage-in-linear-mixed-models.html#shrinkage-in-linear-mixed-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The estimate of the effect for each participant computed from a linear mixed model “gravitates” towards the grand mean effect compared to when we fit a separate linear model to each subject’s data.
This is called shrinkage in linear mixed models. We say that the individual-level estimates are shrunk towards the mean estimates over the entire data (the intercept and slope parameter estimates for <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>).
The more extreme the data from a given subject relative to the mean estimates from the data set, or the less data we have from a given subject, the greater the shrinkage. Let’s think about these two situations next.</p>
<div id="shrinkage-of-extreme-estimates-from-individual-subjects" class="section level3 hasAnchor" number="3.6.1">
<h3><span class="header-section-number">3.6.1</span> Shrinkage of extreme estimates from individual subjects<a href="shrinkage-in-linear-mixed-models.html#shrinkage-of-extreme-estimates-from-individual-subjects" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Figure <a href="shrinkage-in-linear-mixed-models.html#fig:shrinkage">3.16</a> shows the data from three subjects who exhibit implausibly large effects of the OR-SR effect in the data. Subjects 28, 36, and 37’s estimates from the <code>lmList</code> model are as follows. These three subjects’ intercept and slope estimates are both in the upper third quantile of the respective distributions.</p>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb363-1"><a href="shrinkage-in-linear-mixed-models.html#cb363-1" aria-hidden="true" tabindex="-1"></a>lmlist_m1 <span class="ot">&lt;-</span> <span class="fu">lmList</span>(logrt <span class="sc">~</span> so <span class="sc">|</span> subject, gg05e1)</span>
<span id="cb363-2"><a href="shrinkage-in-linear-mixed-models.html#cb363-2" aria-hidden="true" tabindex="-1"></a>coefs <span class="ot">&lt;-</span> <span class="fu">coef</span>(lmlist_m1)</span>
<span id="cb363-3"><a href="shrinkage-in-linear-mixed-models.html#cb363-3" aria-hidden="true" tabindex="-1"></a>intercepts <span class="ot">&lt;-</span> coefs[<span class="dv">1</span>]</span>
<span id="cb363-4"><a href="shrinkage-in-linear-mixed-models.html#cb363-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(intercepts)</span></code></pre></div>
<pre><code>##   (Intercept)  
##  Min.   :5.14  
##  1st Qu.:5.71  
##  Median :5.84  
##  Mean   :5.88  
##  3rd Qu.:6.05  
##  Max.   :6.62</code></pre>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb365-1"><a href="shrinkage-in-linear-mixed-models.html#cb365-1" aria-hidden="true" tabindex="-1"></a>intercepts<span class="sc">$</span><span class="st">`</span><span class="at">(Intercept)</span><span class="st">`</span>[<span class="dv">28</span>];</span></code></pre></div>
<pre><code>## [1] 6.1</code></pre>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb367-1"><a href="shrinkage-in-linear-mixed-models.html#cb367-1" aria-hidden="true" tabindex="-1"></a>intercepts<span class="sc">$</span><span class="st">`</span><span class="at">(Intercept)</span><span class="st">`</span>[<span class="dv">36</span>];</span></code></pre></div>
<pre><code>## [1] 6.009</code></pre>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="shrinkage-in-linear-mixed-models.html#cb369-1" aria-hidden="true" tabindex="-1"></a>intercepts<span class="sc">$</span><span class="st">`</span><span class="at">(Intercept)</span><span class="st">`</span>[<span class="dv">37</span>]</span></code></pre></div>
<pre><code>## [1] 6.617</code></pre>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="shrinkage-in-linear-mixed-models.html#cb371-1" aria-hidden="true" tabindex="-1"></a>slopes <span class="ot">&lt;-</span> coefs[<span class="dv">2</span>]</span>
<span id="cb371-2"><a href="shrinkage-in-linear-mixed-models.html#cb371-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(slopes)</span></code></pre></div>
<pre><code>##        so         
##  Min.   :-0.1610  
##  1st Qu.:-0.0218  
##  Median : 0.0503  
##  Mean   : 0.0620  
##  3rd Qu.: 0.1281  
##  Max.   : 0.4481</code></pre>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="shrinkage-in-linear-mixed-models.html#cb373-1" aria-hidden="true" tabindex="-1"></a>slopes<span class="sc">$</span>so[<span class="dv">28</span>];slopes<span class="sc">$</span>so[<span class="dv">36</span>];slopes<span class="sc">$</span>so[<span class="dv">37</span>]</span></code></pre></div>
<pre><code>## [1] 0.4481</code></pre>
<pre><code>## [1] 0.3825</code></pre>
<pre><code>## [1] 0.3554</code></pre>
<p>On the millisecond scale, the median reading times are implausibly large:</p>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb377-1"><a href="shrinkage-in-linear-mixed-models.html#cb377-1" aria-hidden="true" tabindex="-1"></a><span class="do">## subject 28&#39;s RC effect estimate:</span></span>
<span id="cb377-2"><a href="shrinkage-in-linear-mixed-models.html#cb377-2" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(intercepts<span class="sc">$</span><span class="st">`</span><span class="at">(Intercept)</span><span class="st">`</span>[<span class="dv">28</span>]<span class="sc">+</span></span>
<span id="cb377-3"><a href="shrinkage-in-linear-mixed-models.html#cb377-3" aria-hidden="true" tabindex="-1"></a>      slopes<span class="sc">$</span>so[<span class="dv">28</span>])<span class="sc">-</span></span>
<span id="cb377-4"><a href="shrinkage-in-linear-mixed-models.html#cb377-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">exp</span>(intercepts<span class="sc">$</span><span class="st">`</span><span class="at">(Intercept)</span><span class="st">`</span>[<span class="dv">28</span>]<span class="sc">-</span></span>
<span id="cb377-5"><a href="shrinkage-in-linear-mixed-models.html#cb377-5" aria-hidden="true" tabindex="-1"></a>        slopes<span class="sc">$</span>so[<span class="dv">28</span>])</span></code></pre></div>
<pre><code>## [1] 413.2</code></pre>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb379-1"><a href="shrinkage-in-linear-mixed-models.html#cb379-1" aria-hidden="true" tabindex="-1"></a><span class="do">## subject 36&#39;s RC effect estimate:</span></span>
<span id="cb379-2"><a href="shrinkage-in-linear-mixed-models.html#cb379-2" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(intercepts<span class="sc">$</span><span class="st">`</span><span class="at">(Intercept)</span><span class="st">`</span>[<span class="dv">36</span>]<span class="sc">+</span></span>
<span id="cb379-3"><a href="shrinkage-in-linear-mixed-models.html#cb379-3" aria-hidden="true" tabindex="-1"></a>      slopes<span class="sc">$</span>so[<span class="dv">36</span>])<span class="sc">-</span></span>
<span id="cb379-4"><a href="shrinkage-in-linear-mixed-models.html#cb379-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">exp</span>(intercepts<span class="sc">$</span><span class="st">`</span><span class="at">(Intercept)</span><span class="st">`</span>[<span class="dv">36</span>]<span class="sc">-</span></span>
<span id="cb379-5"><a href="shrinkage-in-linear-mixed-models.html#cb379-5" aria-hidden="true" tabindex="-1"></a>        slopes<span class="sc">$</span>so[<span class="dv">36</span>])</span></code></pre></div>
<pre><code>## [1] 319.1</code></pre>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb381-1"><a href="shrinkage-in-linear-mixed-models.html#cb381-1" aria-hidden="true" tabindex="-1"></a><span class="do">## subject 37&#39;s RC effect estimate:</span></span>
<span id="cb381-2"><a href="shrinkage-in-linear-mixed-models.html#cb381-2" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(intercepts<span class="sc">$</span><span class="st">`</span><span class="at">(Intercept)</span><span class="st">`</span>[<span class="dv">37</span>]<span class="sc">+</span></span>
<span id="cb381-3"><a href="shrinkage-in-linear-mixed-models.html#cb381-3" aria-hidden="true" tabindex="-1"></a>      slopes<span class="sc">$</span>so[<span class="dv">37</span>])<span class="sc">-</span></span>
<span id="cb381-4"><a href="shrinkage-in-linear-mixed-models.html#cb381-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">exp</span>(intercepts<span class="sc">$</span><span class="st">`</span><span class="at">(Intercept)</span><span class="st">`</span>[<span class="dv">37</span>]<span class="sc">-</span></span>
<span id="cb381-5"><a href="shrinkage-in-linear-mixed-models.html#cb381-5" aria-hidden="true" tabindex="-1"></a>        slopes<span class="sc">$</span>so[<span class="dv">37</span>])</span></code></pre></div>
<pre><code>## [1] 542.7</code></pre>
<p>Subject 37’s estimate is the largest of all on the millisecond scale because that subject has the slowest average reading time of all the 42 subjects: a median of 748 ms. When we back-transform the estimates from the log ms to the ms scale, the non-linearity of the log scale has the effect that larger intercepts will translate to much larger mean effects of the OR-SR difference. For example, a slope of 0.3 on the log ms scale will translate to a much larger effect on the ms scale if the intercept is larger:</p>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb383-1"><a href="shrinkage-in-linear-mixed-models.html#cb383-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="dv">5</span><span class="fl">+0.3</span>)<span class="sc">-</span><span class="fu">exp</span>(<span class="dv">5</span><span class="fl">-0.3</span>)</span></code></pre></div>
<pre><code>## [1] 90.39</code></pre>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb385-1"><a href="shrinkage-in-linear-mixed-models.html#cb385-1" aria-hidden="true" tabindex="-1"></a><span class="fu">exp</span>(<span class="dv">6</span><span class="fl">+0.3</span>)<span class="sc">-</span><span class="fu">exp</span>(<span class="dv">6</span><span class="fl">-0.3</span>)</span></code></pre></div>
<pre><code>## [1] 245.7</code></pre>
<p>Interestingly, if these three extreme subjects’ data are removed and a one-sample t-test is done on the slopes (the repeated measures regression), the t-value is just on the border of being significant. Compare the t-test on the full data vs. data without these unusual subjects:</p>
<div class="sourceCode" id="cb387"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb387-1"><a href="shrinkage-in-linear-mixed-models.html#cb387-1" aria-hidden="true" tabindex="-1"></a><span class="do">## full data:</span></span>
<span id="cb387-2"><a href="shrinkage-in-linear-mixed-models.html#cb387-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary_ttest</span>(<span class="fu">t.test</span>(slopes<span class="sc">$</span>so))</span></code></pre></div>
<pre><code>## [1] &quot;t(41)=2.81 p=0.008&quot;
## [1] &quot;est.: 0.06 [0.02,0.11] ms&quot;</code></pre>
<div class="sourceCode" id="cb389"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb389-1"><a href="shrinkage-in-linear-mixed-models.html#cb389-1" aria-hidden="true" tabindex="-1"></a><span class="do">## without subjects 28, 36, and 37:</span></span>
<span id="cb389-2"><a href="shrinkage-in-linear-mixed-models.html#cb389-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary_ttest</span>(<span class="fu">t.test</span>(slopes<span class="sc">$</span>so[<span class="sc">-</span><span class="fu">c</span>(<span class="dv">28</span>,<span class="dv">36</span>,<span class="dv">37</span>)]))</span></code></pre></div>
<pre><code>## [1] &quot;t(38)=2.03 p=0.049&quot;
## [1] &quot;est.: 0.04 [0,0.07] ms&quot;</code></pre>
<p>The linear mixed model even shows that the relative clause effect <em>disappears</em> if the data from these three subjects are removed:</p>
<div class="sourceCode" id="cb391"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb391-1"><a href="shrinkage-in-linear-mixed-models.html#cb391-1" aria-hidden="true" tabindex="-1"></a>gg05e1_a<span class="ot">&lt;-</span><span class="fu">subset</span>(gg05e1,</span>
<span id="cb391-2"><a href="shrinkage-in-linear-mixed-models.html#cb391-2" aria-hidden="true" tabindex="-1"></a>                 subject<span class="sc">!=</span><span class="dv">28</span> <span class="sc">&amp;</span> </span>
<span id="cb391-3"><a href="shrinkage-in-linear-mixed-models.html#cb391-3" aria-hidden="true" tabindex="-1"></a>                 subject<span class="sc">!=</span><span class="dv">36</span> <span class="sc">&amp;</span> </span>
<span id="cb391-4"><a href="shrinkage-in-linear-mixed-models.html#cb391-4" aria-hidden="true" tabindex="-1"></a>                 subject<span class="sc">!=</span><span class="dv">37</span>)</span>
<span id="cb391-5"><a href="shrinkage-in-linear-mixed-models.html#cb391-5" aria-hidden="true" tabindex="-1"></a>m4_lmer_a<span class="ot">&lt;-</span><span class="fu">lmer</span>(logrt<span class="sc">~</span>so <span class="sc">+</span></span>
<span id="cb391-6"><a href="shrinkage-in-linear-mixed-models.html#cb391-6" aria-hidden="true" tabindex="-1"></a>                  (<span class="dv">1</span><span class="sc">+</span>so<span class="sc">|</span>subject)<span class="sc">+</span></span>
<span id="cb391-7"><a href="shrinkage-in-linear-mixed-models.html#cb391-7" aria-hidden="true" tabindex="-1"></a>                  (<span class="dv">1</span><span class="sc">+</span>so<span class="sc">||</span>item),gg05e1_a)</span>
<span id="cb391-8"><a href="shrinkage-in-linear-mixed-models.html#cb391-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m4_lmer_a)<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>##             Estimate Std. Error t value
## (Intercept)  5.85543    0.05134 114.048
## so           0.03642    0.01987   1.832</code></pre>
<p>The advantage of shrinkage is that these extreme subjects’ estimates are shrunk towards the grand mean in the linear mixed model. Compare the estimates from the <code>lmList</code> model (the repeated measures regression that analyzes each subject separately) with those from the linear mixed model:</p>
<div class="sourceCode" id="cb393"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb393-1"><a href="shrinkage-in-linear-mixed-models.html#cb393-1" aria-hidden="true" tabindex="-1"></a><span class="do">## slope estimates from lmList:</span></span>
<span id="cb393-2"><a href="shrinkage-in-linear-mixed-models.html#cb393-2" aria-hidden="true" tabindex="-1"></a>slopes<span class="sc">$</span>so[<span class="dv">28</span>];slopes<span class="sc">$</span>so[<span class="dv">36</span>];slopes<span class="sc">$</span>so[<span class="dv">37</span>]</span></code></pre></div>
<pre><code>## [1] 0.4481</code></pre>
<pre><code>## [1] 0.3825</code></pre>
<pre><code>## [1] 0.3554</code></pre>
<div class="sourceCode" id="cb397"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb397-1"><a href="shrinkage-in-linear-mixed-models.html#cb397-1" aria-hidden="true" tabindex="-1"></a><span class="do">## extract slope estimates from m4_lmer:</span></span>
<span id="cb397-2"><a href="shrinkage-in-linear-mixed-models.html#cb397-2" aria-hidden="true" tabindex="-1"></a>b1<span class="ot">&lt;-</span><span class="fu">fixef</span>(m4_lmer)[<span class="dv">2</span>]</span>
<span id="cb397-3"><a href="shrinkage-in-linear-mixed-models.html#cb397-3" aria-hidden="true" tabindex="-1"></a>lmerslopes<span class="ot">&lt;-</span>b1<span class="sc">+</span><span class="fu">ranef</span>(m4_lmer)<span class="sc">$</span>subject[,<span class="dv">2</span>]</span>
<span id="cb397-4"><a href="shrinkage-in-linear-mixed-models.html#cb397-4" aria-hidden="true" tabindex="-1"></a>lmerslopes[<span class="dv">28</span>];lmerslopes[<span class="dv">36</span>];lmerslopes[<span class="dv">37</span>]</span></code></pre></div>
<pre><code>## [1] 0.2757</code></pre>
<pre><code>## [1] 0.234</code></pre>
<pre><code>## [1] 0.2804</code></pre>
<p>The above example illustrates one important achievement of the linear mixed model: it conservatively down-weights extreme estimates of the slope for particular subjects toward the grand mean slope. This down-weighting is sometimes referred to as “shrinkage”, and sometimes as “borrowing strength from the mean”. Figure <a href="shrinkage-in-linear-mixed-models.html#fig:shrinkage">3.16</a> illustrates the above discussion graphically.</p>
<div class="figure"><span style="display:block;" id="fig:shrinkage"></span>
<img src="Freq_CogSci_files/figure-html/shrinkage-1.svg" alt="The figures show linear model fits (the grand mean estimates) for three subjects with unusually large intercepts and slopes; shown are the simple linear model fit on all the data (gray line), the `lmList` model fit to the individual subject's data (black line), and the linear mixed model fit (the broken line). In all three subjects' models, the linear mixed model estimates are shrunk towards the grand mean (gray line) estimates." width="99%" />
<p class="caption">
FIGURE 3.16: The figures show linear model fits (the grand mean estimates) for three subjects with unusually large intercepts and slopes; shown are the simple linear model fit on all the data (gray line), the <code>lmList</code> model fit to the individual subject’s data (black line), and the linear mixed model fit (the broken line). In all three subjects’ models, the linear mixed model estimates are shrunk towards the grand mean (gray line) estimates.
</p>
</div>
</div>
<div id="shrinkage-when-data-are-missing" class="section level3 hasAnchor" number="3.6.2">
<h3><span class="header-section-number">3.6.2</span> Shrinkage when data are missing<a href="shrinkage-in-linear-mixed-models.html#shrinkage-when-data-are-missing" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The importance and value of shrinkage becomes even clearer once we simulate a situation where there is some missing data. Missingness can happen in experiments, either due to lost measurements (arising from computer error or programming errors), or some other reason. To see what happens when we have missing data, let’s randomly delete some data from one subject. We will randomly delete 50% of subject 37’s data:</p>
<div class="sourceCode" id="cb401"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb401-1"><a href="shrinkage-in-linear-mixed-models.html#cb401-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4321</span>)</span>
<span id="cb401-2"><a href="shrinkage-in-linear-mixed-models.html#cb401-2" aria-hidden="true" tabindex="-1"></a><span class="do">## choose some data randomly to remove:</span></span>
<span id="cb401-3"><a href="shrinkage-in-linear-mixed-models.html#cb401-3" aria-hidden="true" tabindex="-1"></a>rand <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">1</span>, <span class="at">n =</span> <span class="dv">16</span>, <span class="at">prob =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p>Here are subject 37’s reading times (16 data points):</p>
<div class="sourceCode" id="cb402"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb402-1"><a href="shrinkage-in-linear-mixed-models.html#cb402-1" aria-hidden="true" tabindex="-1"></a>gg05e1[<span class="fu">which</span>(gg05e1<span class="sc">$</span>subject <span class="sc">==</span> <span class="dv">37</span>), ]<span class="sc">$</span>rawRT</span></code></pre></div>
<pre><code>##  [1]  770  536  686  578  457  487 2419  884 3365  233
## [11]  715  671 1104  281 1081  971</code></pre>
<p>Now, we randomly delete half the data:</p>
<div class="sourceCode" id="cb404"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb404-1"><a href="shrinkage-in-linear-mixed-models.html#cb404-1" aria-hidden="true" tabindex="-1"></a>gg05e1<span class="sc">$</span>deletedRT <span class="ot">&lt;-</span> gg05e1<span class="sc">$</span>rawRT</span>
<span id="cb404-2"><a href="shrinkage-in-linear-mixed-models.html#cb404-2" aria-hidden="true" tabindex="-1"></a>gg05e1[<span class="fu">which</span>(gg05e1<span class="sc">$</span>subject <span class="sc">==</span> <span class="dv">37</span>), ]<span class="sc">$</span>deletedRT <span class="ot">&lt;-</span></span>
<span id="cb404-3"><a href="shrinkage-in-linear-mixed-models.html#cb404-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ifelse</span>(rand, <span class="cn">NA</span>,</span>
<span id="cb404-4"><a href="shrinkage-in-linear-mixed-models.html#cb404-4" aria-hidden="true" tabindex="-1"></a>    gg05e1[<span class="fu">which</span>(gg05e1<span class="sc">$</span>subject <span class="sc">==</span> <span class="dv">37</span>), ]<span class="sc">$</span>rawRT</span>
<span id="cb404-5"><a href="shrinkage-in-linear-mixed-models.html#cb404-5" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p>Now subject 37’s estimates are going to be even more inaccurate than with 16 data points, because they are based on much less data (even one extreme value can strongly influence the mean):</p>
<div class="sourceCode" id="cb405"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb405-1"><a href="shrinkage-in-linear-mixed-models.html#cb405-1" aria-hidden="true" tabindex="-1"></a><span class="fu">subset</span>(gg05e1, subject <span class="sc">==</span> <span class="dv">37</span>)<span class="sc">$</span>deletedRT</span></code></pre></div>
<pre><code>##  [1]  770   NA  686  578   NA   NA   NA   NA 3365  233
## [11]   NA  671 1104   NA   NA  971</code></pre>
<p>Here are the original estimates of the intercept and slope for subject 37:</p>
<div class="sourceCode" id="cb407"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb407-1"><a href="shrinkage-in-linear-mixed-models.html#cb407-1" aria-hidden="true" tabindex="-1"></a>lmlist_m1_orig <span class="ot">&lt;-</span> <span class="fu">lmList</span>(<span class="fu">log</span>(rawRT) <span class="sc">~</span> so <span class="sc">|</span> subject, gg05e1)</span>
<span id="cb407-2"><a href="shrinkage-in-linear-mixed-models.html#cb407-2" aria-hidden="true" tabindex="-1"></a>intercepts_orig<span class="ot">&lt;-</span><span class="fu">coef</span>(lmlist_m1_orig)[<span class="dv">1</span>]</span>
<span id="cb407-3"><a href="shrinkage-in-linear-mixed-models.html#cb407-3" aria-hidden="true" tabindex="-1"></a>slopes_orig<span class="ot">&lt;-</span><span class="fu">coef</span>(lmlist_m1_orig)[<span class="dv">2</span>]</span>
<span id="cb407-4"><a href="shrinkage-in-linear-mixed-models.html#cb407-4" aria-hidden="true" tabindex="-1"></a>(intercept_orig37<span class="ot">&lt;-</span>intercepts_orig<span class="sc">$</span><span class="st">`</span><span class="at">(Intercept)</span><span class="st">`</span>[<span class="dv">37</span>])</span></code></pre></div>
<pre><code>## [1] 6.617</code></pre>
<div class="sourceCode" id="cb409"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb409-1"><a href="shrinkage-in-linear-mixed-models.html#cb409-1" aria-hidden="true" tabindex="-1"></a>(slope_orig37<span class="ot">&lt;-</span>slopes_orig<span class="sc">$</span>so[<span class="dv">37</span>])</span></code></pre></div>
<pre><code>## [1] 0.3554</code></pre>
<p>Now look at the estimates based on the deleted data:</p>
<div class="sourceCode" id="cb411"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb411-1"><a href="shrinkage-in-linear-mixed-models.html#cb411-1" aria-hidden="true" tabindex="-1"></a><span class="do">## on deleted data:</span></span>
<span id="cb411-2"><a href="shrinkage-in-linear-mixed-models.html#cb411-2" aria-hidden="true" tabindex="-1"></a>lmlist_m1_deleted <span class="ot">&lt;-</span> <span class="fu">lmList</span>(<span class="fu">log</span>(deletedRT) <span class="sc">~</span> so <span class="sc">|</span> subject, gg05e1)</span>
<span id="cb411-3"><a href="shrinkage-in-linear-mixed-models.html#cb411-3" aria-hidden="true" tabindex="-1"></a>intercepts_del <span class="ot">&lt;-</span> <span class="fu">coef</span>(lmlist_m1_deleted)[<span class="dv">1</span>]</span>
<span id="cb411-4"><a href="shrinkage-in-linear-mixed-models.html#cb411-4" aria-hidden="true" tabindex="-1"></a>slopes_del <span class="ot">&lt;-</span> <span class="fu">coef</span>(lmlist_m1_deleted)[<span class="dv">2</span>]</span>
<span id="cb411-5"><a href="shrinkage-in-linear-mixed-models.html#cb411-5" aria-hidden="true" tabindex="-1"></a><span class="do">## subject 37&#39;s new estimates on deleted data:</span></span>
<span id="cb411-6"><a href="shrinkage-in-linear-mixed-models.html#cb411-6" aria-hidden="true" tabindex="-1"></a>(intercept_del37<span class="ot">&lt;-</span>intercepts_del<span class="sc">$</span><span class="st">`</span><span class="at">(Intercept)</span><span class="st">`</span>[<span class="dv">37</span>])</span></code></pre></div>
<pre><code>## [1] 6.688</code></pre>
<div class="sourceCode" id="cb413"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb413-1"><a href="shrinkage-in-linear-mixed-models.html#cb413-1" aria-hidden="true" tabindex="-1"></a>(slope_del37<span class="ot">&lt;-</span>slopes_del<span class="sc">$</span>so[<span class="dv">37</span>])</span></code></pre></div>
<pre><code>## [1] 0.3884</code></pre>
<p>The estimates from subject 37 have become even more extreme once half the data from this subject have been deleted. The intercept goes from 6.62 in the original data to
6.69 in the deleted data; and the slope from 0.36 in the original data to
0.39 in the deleted data.</p>
<p>Now fit two linear mixed models (<code>m4_lmer</code>), one with the original data, and another with the deleted data, and examine subject 37’s estimates on undeleted vs. deleted data.</p>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb415-1"><a href="shrinkage-in-linear-mixed-models.html#cb415-1" aria-hidden="true" tabindex="-1"></a>m1_lmer_orig<span class="ot">&lt;-</span><span class="fu">lmer</span>(<span class="fu">log</span>(rawRT)<span class="sc">~</span>so <span class="sc">+</span> (<span class="dv">1</span><span class="sc">+</span>so<span class="sc">|</span>subject)<span class="sc">+</span></span>
<span id="cb415-2"><a href="shrinkage-in-linear-mixed-models.html#cb415-2" aria-hidden="true" tabindex="-1"></a>                     (<span class="dv">1</span><span class="sc">+</span>so<span class="sc">||</span>item),gg05e1)</span>
<span id="cb415-3"><a href="shrinkage-in-linear-mixed-models.html#cb415-3" aria-hidden="true" tabindex="-1"></a>b0_orig<span class="ot">&lt;-</span><span class="fu">summary</span>(m1_lmer_orig)<span class="sc">$</span>coefficients[<span class="dv">1</span>,<span class="dv">1</span>]</span>
<span id="cb415-4"><a href="shrinkage-in-linear-mixed-models.html#cb415-4" aria-hidden="true" tabindex="-1"></a>b1_orig<span class="ot">&lt;-</span><span class="fu">summary</span>(m1_lmer_orig)<span class="sc">$</span>coefficients[<span class="dv">2</span>,<span class="dv">1</span>]</span>
<span id="cb415-5"><a href="shrinkage-in-linear-mixed-models.html#cb415-5" aria-hidden="true" tabindex="-1"></a>u_orig<span class="ot">&lt;-</span><span class="fu">ranef</span>(m1_lmer_orig)<span class="sc">$</span>subject</span>
<span id="cb415-6"><a href="shrinkage-in-linear-mixed-models.html#cb415-6" aria-hidden="true" tabindex="-1"></a>u0_orig<span class="ot">&lt;-</span>u_orig<span class="sc">$</span><span class="st">`</span><span class="at">(Intercept)</span><span class="st">`</span></span>
<span id="cb415-7"><a href="shrinkage-in-linear-mixed-models.html#cb415-7" aria-hidden="true" tabindex="-1"></a>u1_orig<span class="ot">&lt;-</span>u_orig<span class="sc">$</span><span class="st">`</span><span class="at">so</span><span class="st">`</span></span>
<span id="cb415-8"><a href="shrinkage-in-linear-mixed-models.html#cb415-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb415-9"><a href="shrinkage-in-linear-mixed-models.html#cb415-9" aria-hidden="true" tabindex="-1"></a><span class="do">## subject 37&#39;s estimates:</span></span>
<span id="cb415-10"><a href="shrinkage-in-linear-mixed-models.html#cb415-10" aria-hidden="true" tabindex="-1"></a>b0_orig <span class="sc">+</span> u0_orig[<span class="dv">37</span>]</span></code></pre></div>
<pre><code>## [1] 6.576</code></pre>
<div class="sourceCode" id="cb417"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb417-1"><a href="shrinkage-in-linear-mixed-models.html#cb417-1" aria-hidden="true" tabindex="-1"></a>b1_orig <span class="sc">+</span> u1_orig[<span class="dv">37</span>]</span></code></pre></div>
<pre><code>## [1] 0.2804</code></pre>
<div class="sourceCode" id="cb419"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb419-1"><a href="shrinkage-in-linear-mixed-models.html#cb419-1" aria-hidden="true" tabindex="-1"></a><span class="do">## LMM on the deleted data:</span></span>
<span id="cb419-2"><a href="shrinkage-in-linear-mixed-models.html#cb419-2" aria-hidden="true" tabindex="-1"></a>m4_lmer_del<span class="ot">&lt;-</span><span class="fu">lmer</span>(<span class="fu">log</span>(deletedRT)<span class="sc">~</span>so <span class="sc">+</span> (<span class="dv">1</span><span class="sc">+</span>so<span class="sc">|</span>subject)<span class="sc">+</span></span>
<span id="cb419-3"><a href="shrinkage-in-linear-mixed-models.html#cb419-3" aria-hidden="true" tabindex="-1"></a>                    (<span class="dv">1</span><span class="sc">+</span>so<span class="sc">||</span>item),gg05e1)</span>
<span id="cb419-4"><a href="shrinkage-in-linear-mixed-models.html#cb419-4" aria-hidden="true" tabindex="-1"></a>b0_del<span class="ot">&lt;-</span><span class="fu">summary</span>(m4_lmer_del)<span class="sc">$</span>coefficients[<span class="dv">1</span>,<span class="dv">1</span>]</span>
<span id="cb419-5"><a href="shrinkage-in-linear-mixed-models.html#cb419-5" aria-hidden="true" tabindex="-1"></a>b1_del<span class="ot">&lt;-</span><span class="fu">summary</span>(m4_lmer_del)<span class="sc">$</span>coefficients[<span class="dv">2</span>,<span class="dv">1</span>]</span>
<span id="cb419-6"><a href="shrinkage-in-linear-mixed-models.html#cb419-6" aria-hidden="true" tabindex="-1"></a>u_del<span class="ot">&lt;-</span><span class="fu">ranef</span>(m4_lmer_del)<span class="sc">$</span>subject</span>
<span id="cb419-7"><a href="shrinkage-in-linear-mixed-models.html#cb419-7" aria-hidden="true" tabindex="-1"></a>u0_del<span class="ot">&lt;-</span>u_del<span class="sc">$</span><span class="st">`</span><span class="at">(Intercept)</span><span class="st">`</span></span>
<span id="cb419-8"><a href="shrinkage-in-linear-mixed-models.html#cb419-8" aria-hidden="true" tabindex="-1"></a>u1_del<span class="ot">&lt;-</span>u_del<span class="sc">$</span><span class="st">`</span><span class="at">so</span><span class="st">`</span></span>
<span id="cb419-9"><a href="shrinkage-in-linear-mixed-models.html#cb419-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb419-10"><a href="shrinkage-in-linear-mixed-models.html#cb419-10" aria-hidden="true" tabindex="-1"></a><span class="do">## subject 37&#39;s estimates:</span></span>
<span id="cb419-11"><a href="shrinkage-in-linear-mixed-models.html#cb419-11" aria-hidden="true" tabindex="-1"></a>b0_del <span class="sc">+</span> u0_del[<span class="dv">37</span>] </span></code></pre></div>
<pre><code>## [1] 6.605</code></pre>
<div class="sourceCode" id="cb421"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb421-1"><a href="shrinkage-in-linear-mixed-models.html#cb421-1" aria-hidden="true" tabindex="-1"></a>b1_del <span class="sc">+</span> u1_del[<span class="dv">37</span>]</span></code></pre></div>
<pre><code>## [1] 0.2654</code></pre>
<p>The two intercept and slope estimates for subject 37 are pretty similar despite half the data from that subject being missing in the second analysis.</p>
<p>Figure <a href="shrinkage-in-linear-mixed-models.html#fig:shrinkage2">3.17</a> illustrates the difference between the different models: there is hardly any difference between the two linear mixed model estimates; by contrast, the <code>lmList</code> estimates on the full vs. missing data differ quite a bit.</p>
<div class="figure"><span style="display:block;" id="fig:shrinkage2"></span>
<img src="Freq_CogSci_files/figure-html/shrinkage2-1.svg" alt="The figure shows linear model fits (the grand mean estimates) for subject 37. When using lmList, deleting data leads to very different estimates; but using lmer, deleting half the data from this subject hardly affects the individual subject's estimates." width="99%" />
<p class="caption">
FIGURE 3.17: The figure shows linear model fits (the grand mean estimates) for subject 37. When using lmList, deleting data leads to very different estimates; but using lmer, deleting half the data from this subject hardly affects the individual subject’s estimates.
</p>
</div>
<p>The conclusion to take away from Figure <a href="shrinkage-in-linear-mixed-models.html#fig:shrinkage2">3.17</a> is that the estimates from the hierarchical model are almost unaffected by the missing data, but the estimates from the <code>lmList</code> model are heavily affected by the mis-estimation due to less data.</p>
<p>Thus, shrinkage in linear mixed models has the beneficial effect that it yields more robust estimates (think Type M error!) compared to models which fit data separately for each subject. This property of shrinkage is one reason why linear mixed models are so important in cognitive science, and why they should be the standard workhorse for data analysis.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="linear-mixed-models.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="summary-2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown/edit/master/inst/examples/03-LinearModels.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Freq_CogSci.pdf", "Freq_CogSci.epub", "Freq_CogSci.mobi"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
