<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3.5 Linear mixed models | Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction</title>
  <meta name="description" content="Linear Mixed Models for Linguistics and Psychology: A Comprehensive Introduction" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="3.5 Linear mixed models | Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://github.com/vasishth/Freq_CogSci" />
  <meta property="og:image" content="https://github.com/vasishth/Freq_CogSciimages/temporarycover.jpg" />
  <meta property="og:description" content="Linear Mixed Models for Linguistics and Psychology: A Comprehensive Introduction" />
  <meta name="github-repo" content="rstudio/bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3.5 Linear mixed models | Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction" />
  
  <meta name="twitter:description" content="Linear Mixed Models for Linguistics and Psychology: A Comprehensive Introduction" />
  <meta name="twitter:image" content="https://github.com/vasishth/Freq_CogSciimages/temporarycover.jpg" />

<meta name="author" content="Shravan Vasishth, Daniel Schad, Audrey Bürki, Reinhold Kliegl" />


<meta name="date" content="2020-08-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="from-the-paired-t-test-to-the-linear-mixed-model.html"/>
<link rel="next" href="shrinkage-in-linear-mixed-models.html"/>
<script src="libs/jquery/jquery.min.js"></script>
<link href="libs/gitbook/css/style.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { background-color: #f8f8f8; }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Linear Mixed Models in Linguistics and Psychology</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="0.1" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>0.1</b> Prerequisites</a></li>
<li class="chapter" data-level="0.2" data-path="how-to-read-this-book.html"><a href="how-to-read-this-book.html"><i class="fa fa-check"></i><b>0.2</b> How to read this book</a></li>
<li class="chapter" data-level="0.3" data-path="online-materials.html"><a href="online-materials.html"><i class="fa fa-check"></i><b>0.3</b> Online materials</a></li>
<li class="chapter" data-level="0.4" data-path="software-needed.html"><a href="software-needed.html"><i class="fa fa-check"></i><b>0.4</b> Software needed</a></li>
<li class="chapter" data-level="0.5" data-path="acknowledgements.html"><a href="acknowledgements.html"><i class="fa fa-check"></i><b>0.5</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="about-the-authors.html"><a href="about-the-authors.html"><i class="fa fa-check"></i>About the Authors</a></li>
<li class="part"><span><b>I Foundational ideas</b></span></li>
<li class="chapter" data-level="1" data-path="some-important-facts-about-distributions.html"><a href="some-important-facts-about-distributions.html"><i class="fa fa-check"></i><b>1</b> Some important facts about distributions</a><ul>
<li class="chapter" data-level="1.1" data-path="discrete-random-variables-an-example-using-the-binomial-distribution.html"><a href="discrete-random-variables-an-example-using-the-binomial-distribution.html"><i class="fa fa-check"></i><b>1.1</b> Discrete random variables: An example using the Binomial distribution</a><ul>
<li class="chapter" data-level="1.1.1" data-path="discrete-random-variables-an-example-using-the-binomial-distribution.html"><a href="discrete-random-variables-an-example-using-the-binomial-distribution.html#the-mean-and-variance-of-the-binomial-distribution"><i class="fa fa-check"></i><b>1.1.1</b> The mean and variance of the Binomial distribution</a></li>
<li class="chapter" data-level="1.1.2" data-path="discrete-random-variables-an-example-using-the-binomial-distribution.html"><a href="discrete-random-variables-an-example-using-the-binomial-distribution.html#what-information-does-a-probability-distribution-provide"><i class="fa fa-check"></i><b>1.1.2</b> What information does a probability distribution provide?</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="continuous-random-variables-an-example-using-the-normal-distribution.html"><a href="continuous-random-variables-an-example-using-the-normal-distribution.html"><i class="fa fa-check"></i><b>1.2</b> Continuous random variables: An example using the Normal distribution</a></li>
<li class="chapter" data-level="1.3" data-path="bivariatemultivariate-distributions.html"><a href="bivariatemultivariate-distributions.html"><i class="fa fa-check"></i><b>1.3</b> Bivariate/multivariate distributions</a></li>
<li class="chapter" data-level="1.4" data-path="summary-of-useful-r-functions-relating-to-univariate-distributions.html"><a href="summary-of-useful-r-functions-relating-to-univariate-distributions.html"><i class="fa fa-check"></i><b>1.4</b> Summary of useful R functions relating to univariate distributions</a></li>
<li class="chapter" data-level="1.5" data-path="summary-of-random-variable-theory.html"><a href="summary-of-random-variable-theory.html"><i class="fa fa-check"></i><b>1.5</b> *Summary of random variable theory</a></li>
<li class="chapter" data-level="1.6" data-path="further-reading.html"><a href="further-reading.html"><i class="fa fa-check"></i><b>1.6</b> Further reading</a></li>
<li class="chapter" data-level="1.7" data-path="sec-Foundationsexercises.html"><a href="sec-Foundationsexercises.html"><i class="fa fa-check"></i><b>1.7</b> Exercises</a><ul>
<li class="chapter" data-level="1.7.1" data-path="sec-Foundationsexercises.html"><a href="sec-Foundationsexercises.html#sec:Foundationsexercisespnorm"><i class="fa fa-check"></i><b>1.7.1</b> Practice using the <code>pnorm</code> function</a></li>
<li class="chapter" data-level="1.7.2" data-path="sec-Foundationsexercises.html"><a href="sec-Foundationsexercises.html#sec:Foundationsexercisesqnorm"><i class="fa fa-check"></i><b>1.7.2</b> Practice using the <code>qnorm</code> function</a></li>
<li class="chapter" data-level="1.7.3" data-path="sec-Foundationsexercises.html"><a href="sec-Foundationsexercises.html#sec:Foundationsexercisesqt"><i class="fa fa-check"></i><b>1.7.3</b> Practice using <code>qt</code></a></li>
<li class="chapter" data-level="1.7.4" data-path="sec-Foundationsexercises.html"><a href="sec-Foundationsexercises.html#sec:FoundationsexercisesMLE1"><i class="fa fa-check"></i><b>1.7.4</b> Maximum likelihood estimation 1</a></li>
<li class="chapter" data-level="1.7.5" data-path="sec-Foundationsexercises.html"><a href="sec-Foundationsexercises.html#sec:FoundationsexercisesMLE2"><i class="fa fa-check"></i><b>1.7.5</b> Maximum likelihood estimation 2</a></li>
<li class="chapter" data-level="1.7.6" data-path="sec-Foundationsexercises.html"><a href="sec-Foundationsexercises.html#sec:Foundationsexercisesbivar"><i class="fa fa-check"></i><b>1.7.6</b> Generating bivariate data</a></li>
<li class="chapter" data-level="1.7.7" data-path="sec-Foundationsexercises.html"><a href="sec-Foundationsexercises.html#sec:Foundationsexercisesmultivar"><i class="fa fa-check"></i><b>1.7.7</b> Generating multivariate data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="hypothetical-repeated-sampling-and-the-t-test.html"><a href="hypothetical-repeated-sampling-and-the-t-test.html"><i class="fa fa-check"></i><b>2</b> Hypothetical repeated sampling and the t-test</a><ul>
<li class="chapter" data-level="2.1" data-path="the-central-limit-theorem-using-simulation.html"><a href="the-central-limit-theorem-using-simulation.html"><i class="fa fa-check"></i><b>2.1</b> The central limit theorem using simulation</a></li>
<li class="chapter" data-level="2.2" data-path="three-examples-of-the-sampling-distribution.html"><a href="three-examples-of-the-sampling-distribution.html"><i class="fa fa-check"></i><b>2.2</b> Three examples of the sampling distribution</a></li>
<li class="chapter" data-level="2.3" data-path="the-confidence-interval-and-what-its-good-for.html"><a href="the-confidence-interval-and-what-its-good-for.html"><i class="fa fa-check"></i><b>2.3</b> The confidence interval, and what it’s good for</a></li>
<li class="chapter" data-level="2.4" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html"><i class="fa fa-check"></i><b>2.4</b> Hypothesis testing: The one sample t-test</a><ul>
<li class="chapter" data-level="2.4.1" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#the-one-sample-t-test"><i class="fa fa-check"></i><b>2.4.1</b> The one-sample t-test</a></li>
<li class="chapter" data-level="2.4.2" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#type-i-ii-error-and-power"><i class="fa fa-check"></i><b>2.4.2</b> Type I, II error, and power</a></li>
<li class="chapter" data-level="2.4.3" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#how-to-compute-power-for-the-one-sample-t-test"><i class="fa fa-check"></i><b>2.4.3</b> How to compute power for the one-sample t-test</a></li>
<li class="chapter" data-level="2.4.4" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#the-p-value"><i class="fa fa-check"></i><b>2.4.4</b> The p-value</a></li>
<li class="chapter" data-level="2.4.5" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#type-m-and-s-error-in-the-face-of-low-power"><i class="fa fa-check"></i><b>2.4.5</b> Type M and S error in the face of low power</a></li>
<li class="chapter" data-level="2.4.6" data-path="hypothesis-testing-the-one-sample-t-test.html"><a href="hypothesis-testing-the-one-sample-t-test.html#searching-for-significance"><i class="fa fa-check"></i><b>2.4.6</b> Searching for significance</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="the-two-sample-t-test-vs-the-paired-t-test.html"><a href="the-two-sample-t-test-vs-the-paired-t-test.html"><i class="fa fa-check"></i><b>2.5</b> The two-sample t-test vs. the paired t-test</a><ul>
<li class="chapter" data-level="2.5.1" data-path="the-two-sample-t-test-vs-the-paired-t-test.html"><a href="the-two-sample-t-test-vs-the-paired-t-test.html#common-mistakes-involving-the-t-test"><i class="fa fa-check"></i><b>2.5.1</b> Common mistakes involving the t-test</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="sec-SamplingDistrnexercises.html"><a href="sec-SamplingDistrnexercises.html"><i class="fa fa-check"></i><b>2.6</b> Exercises</a><ul>
<li class="chapter" data-level="2.6.1" data-path="sec-SamplingDistrnexercises.html"><a href="sec-SamplingDistrnexercises.html#sec:SamplingDistrnexercisesPart1"><i class="fa fa-check"></i><b>2.6.1</b> Computing the p-value</a></li>
<li class="chapter" data-level="2.6.2" data-path="sec-SamplingDistrnexercises.html"><a href="sec-SamplingDistrnexercises.html#sec:SamplingDistrnexercisesPart2"><i class="fa fa-check"></i><b>2.6.2</b> Computing the t-value</a></li>
<li class="chapter" data-level="2.6.3" data-path="sec-SamplingDistrnexercises.html"><a href="sec-SamplingDistrnexercises.html#sec:SamplingDistrnexercisesPart3"><i class="fa fa-check"></i><b>2.6.3</b> Type I and II error</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-models-and-linear-mixed-models.html"><a href="linear-models-and-linear-mixed-models.html"><i class="fa fa-check"></i><b>3</b> Linear models and linear mixed models</a><ul>
<li class="chapter" data-level="3.1" data-path="from-the-t-test-to-the-linear-mixed-model.html"><a href="from-the-t-test-to-the-linear-mixed-model.html"><i class="fa fa-check"></i><b>3.1</b> From the t-test to the linear (mixed) model</a></li>
<li class="chapter" data-level="3.2" data-path="sum-coding.html"><a href="sum-coding.html"><i class="fa fa-check"></i><b>3.2</b> Sum coding</a></li>
<li class="chapter" data-level="3.3" data-path="checking-model-assumptions.html"><a href="checking-model-assumptions.html"><i class="fa fa-check"></i><b>3.3</b> Checking model assumptions</a></li>
<li class="chapter" data-level="3.4" data-path="from-the-paired-t-test-to-the-linear-mixed-model.html"><a href="from-the-paired-t-test-to-the-linear-mixed-model.html"><i class="fa fa-check"></i><b>3.4</b> From the paired t-test to the linear mixed model</a></li>
<li class="chapter" data-level="3.5" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>3.5</b> Linear mixed models</a><ul>
<li class="chapter" data-level="3.5.1" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#model-type-1-varying-intercepts"><i class="fa fa-check"></i><b>3.5.1</b> Model type 1: Varying intercepts</a></li>
<li class="chapter" data-level="3.5.2" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#the-formal-statement-of-the-varying-intercepts-model"><i class="fa fa-check"></i><b>3.5.2</b> The formal statement of the varying intercepts model</a></li>
<li class="chapter" data-level="3.5.3" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#model-type-2-varying-intercepts-and-slopes-without-a-correlation"><i class="fa fa-check"></i><b>3.5.3</b> Model type 2: Varying intercepts and slopes, without a correlation</a></li>
<li class="chapter" data-level="3.5.4" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html#model-type-3-varying-intercepts-and-varying-slopes-with-correlation"><i class="fa fa-check"></i><b>3.5.4</b> Model type 3: Varying intercepts and varying slopes, with correlation</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="shrinkage-in-linear-mixed-models.html"><a href="shrinkage-in-linear-mixed-models.html"><i class="fa fa-check"></i><b>3.6</b> Shrinkage in linear mixed models</a></li>
<li class="chapter" data-level="3.7" data-path="summary.html"><a href="summary.html"><i class="fa fa-check"></i><b>3.7</b> Summary</a></li>
<li class="chapter" data-level="3.8" data-path="sec-LMExercises.html"><a href="sec-LMExercises.html"><i class="fa fa-check"></i><b>3.8</b> Exercises</a><ul>
<li class="chapter" data-level="3.8.1" data-path="sec-LMExercises.html"><a href="sec-LMExercises.html#sec:LMExercisesPart1"><i class="fa fa-check"></i><b>3.8.1</b> By-subjects t-test</a></li>
<li class="chapter" data-level="3.8.2" data-path="sec-LMExercises.html"><a href="sec-LMExercises.html#sec:LMExercisesPart2"><i class="fa fa-check"></i><b>3.8.2</b> Fitting a linear mixed model</a></li>
<li class="chapter" data-level="3.8.3" data-path="sec-LMExercises.html"><a href="sec-LMExercises.html#sec:LMExercisesPart3"><i class="fa fa-check"></i><b>3.8.3</b> t-test vs. linear mixed model</a></li>
<li class="chapter" data-level="3.8.4" data-path="sec-LMExercises.html"><a href="sec-LMExercises.html#sec:LMExercisesPart4"><i class="fa fa-check"></i><b>3.8.4</b> Power calculation using power.t.test</a></li>
<li class="chapter" data-level="3.8.5" data-path="sec-LMExercises.html"><a href="sec-LMExercises.html#sec:LMExercisesPart5"><i class="fa fa-check"></i><b>3.8.5</b> Residuals</a></li>
<li class="chapter" data-level="3.8.6" data-path="sec-LMExercises.html"><a href="sec-LMExercises.html#sec:LMExercisesPart6"><i class="fa fa-check"></i><b>3.8.6</b> Understanding contrast coding</a></li>
<li class="chapter" data-level="3.8.7" data-path="sec-LMExercises.html"><a href="sec-LMExercises.html#sec:LMExercisesPart7"><i class="fa fa-check"></i><b>3.8.7</b> Understanding the fixed-effects output</a></li>
<li class="chapter" data-level="3.8.8" data-path="sec-LMExercises.html"><a href="sec-LMExercises.html#sec:LMExercisesPart8"><i class="fa fa-check"></i><b>3.8.8</b> Understanding the null hypothesis test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="hypothesis-testing-using-the-likelihood-ratio-test.html"><a href="hypothesis-testing-using-the-likelihood-ratio-test.html"><i class="fa fa-check"></i><b>4</b> Hypothesis testing using the likelihood ratio test</a><ul>
<li class="chapter" data-level="4.1" data-path="the-likelihood-ratio-test-the-theory.html"><a href="the-likelihood-ratio-test-the-theory.html"><i class="fa fa-check"></i><b>4.1</b> The likelihood ratio test: The theory</a></li>
<li class="chapter" data-level="4.2" data-path="a-practical-example-using-simulated-data.html"><a href="a-practical-example-using-simulated-data.html"><i class="fa fa-check"></i><b>4.2</b> A practical example using simulated data</a></li>
<li class="chapter" data-level="4.3" data-path="a-real-life-example-the-english-relative-clause-data.html"><a href="a-real-life-example-the-english-relative-clause-data.html"><i class="fa fa-check"></i><b>4.3</b> A real-life example: The English relative clause data</a></li>
<li class="chapter" data-level="4.4" data-path="sec-HypTestExercises.html"><a href="sec-HypTestExercises.html"><i class="fa fa-check"></i><b>4.4</b> Exercises</a><ul>
<li class="chapter" data-level="4.4.1" data-path="sec-HypTestExercises.html"><a href="sec-HypTestExercises.html#sec:HypTestExercisesChinese"><i class="fa fa-check"></i><b>4.4.1</b> Chinese relative clauses</a></li>
<li class="chapter" data-level="4.4.2" data-path="sec-HypTestExercises.html"><a href="sec-HypTestExercises.html#sec:HypTestExerciseAgrmt"><i class="fa fa-check"></i><b>4.4.2</b> Agreement attraction in comprehension</a></li>
<li class="chapter" data-level="4.4.3" data-path="sec-HypTestExercises.html"><a href="sec-HypTestExercises.html#sec:HypTestExerciseGramCE"><i class="fa fa-check"></i><b>4.4.3</b> The grammaticality illusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="using-simulation-to-understand-your-model.html"><a href="using-simulation-to-understand-your-model.html"><i class="fa fa-check"></i><b>5</b> Using simulation to understand your model</a><ul>
<li class="chapter" data-level="5.1" data-path="a-reminder-the-maximal-linear-mixed-model.html"><a href="a-reminder-the-maximal-linear-mixed-model.html"><i class="fa fa-check"></i><b>5.1</b> A reminder: The maximal linear mixed model</a></li>
<li class="chapter" data-level="5.2" data-path="obtain-estimates-from-a-previous-study.html"><a href="obtain-estimates-from-a-previous-study.html"><i class="fa fa-check"></i><b>5.2</b> Obtain estimates from a previous study</a></li>
<li class="chapter" data-level="5.3" data-path="decide-on-a-range-of-plausible-values-of-the-effect-size.html"><a href="decide-on-a-range-of-plausible-values-of-the-effect-size.html"><i class="fa fa-check"></i><b>5.3</b> Decide on a range of plausible values of the effect size</a></li>
<li class="chapter" data-level="5.4" data-path="extract-parameter-estimates.html"><a href="extract-parameter-estimates.html"><i class="fa fa-check"></i><b>5.4</b> Extract parameter estimates</a></li>
<li class="chapter" data-level="5.5" data-path="define-a-function-for-generating-data.html"><a href="define-a-function-for-generating-data.html"><i class="fa fa-check"></i><b>5.5</b> Define a function for generating data</a><ul>
<li class="chapter" data-level="5.5.1" data-path="define-a-function-for-generating-data.html"><a href="define-a-function-for-generating-data.html#generate-a-latin-square-design"><i class="fa fa-check"></i><b>5.5.1</b> Generate a Latin-square design</a></li>
<li class="chapter" data-level="5.5.2" data-path="define-a-function-for-generating-data.html"><a href="define-a-function-for-generating-data.html#generate-data-row-by-row"><i class="fa fa-check"></i><b>5.5.2</b> Generate data row-by-row</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="repeated-generation-of-data-to-compute-power.html"><a href="repeated-generation-of-data-to-compute-power.html"><i class="fa fa-check"></i><b>5.6</b> Repeated generation of data to compute power</a></li>
<li class="chapter" data-level="5.7" data-path="what-you-can-now-do.html"><a href="what-you-can-now-do.html"><i class="fa fa-check"></i><b>5.7</b> What you can now do</a></li>
<li class="chapter" data-level="5.8" data-path="sec-Simulationexercises.html"><a href="sec-Simulationexercises.html"><i class="fa fa-check"></i><b>5.8</b> Exercises</a><ul>
<li class="chapter" data-level="5.8.1" data-path="sec-Simulationexercises.html"><a href="sec-Simulationexercises.html#sec:SimulationexercisesPart1"><i class="fa fa-check"></i><b>5.8.1</b> Drawing a power curve given a range of effect sizes</a></li>
<li class="chapter" data-level="5.8.2" data-path="sec-Simulationexercises.html"><a href="sec-Simulationexercises.html#sec:SimulationexercisesPart2"><i class="fa fa-check"></i><b>5.8.2</b> Power and log-transformation</a></li>
<li class="chapter" data-level="5.8.3" data-path="sec-Simulationexercises.html"><a href="sec-Simulationexercises.html#sec:SimulationexercisesPart3"><i class="fa fa-check"></i><b>5.8.3</b> Evaluating models by generating simulated data</a></li>
<li class="chapter" data-level="5.8.4" data-path="sec-Simulationexercises.html"><a href="sec-Simulationexercises.html#sec:SimulationexercisesPart4"><i class="fa fa-check"></i><b>5.8.4</b> Using simulation to check parameter recovery</a></li>
<li class="chapter" data-level="5.8.5" data-path="sec-Simulationexercises.html"><a href="sec-Simulationexercises.html#sec:SimulationexercisesPart5"><i class="fa fa-check"></i><b>5.8.5</b> Sample size calculations using simulation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="important-distributions.html"><a href="important-distributions.html"><i class="fa fa-check"></i><b>6</b> Important distributions</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="_blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Linear Mixed Models in Linguistics and Psychology: A Comprehensive Introduction</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-mixed-models" class="section level2">
<h2><span class="header-section-number">3.5</span> Linear mixed models</h2>
<p>We return to our subject and object relative clause data from English (Grodner and Gibson, Expt 1). First we load the data as usual, define relative clause type as a sum coded predictor, and create a new column called <code>so</code> that represents the contrast coding (<span class="math inline">\(\pm 1\)</span> sum contrasts), and a column that holds log-transformed reading time.</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb201-1" data-line-number="1">gg05e1 &lt;-<span class="st"> </span><span class="kw">read.table</span>(<span class="st">&quot;data/grodnergibsonE1crit.txt&quot;</span>, </a>
<a class="sourceLine" id="cb201-2" data-line-number="2">  <span class="dt">header =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb201-3" data-line-number="3"></a>
<a class="sourceLine" id="cb201-4" data-line-number="4">gg05e1<span class="op">$</span>so &lt;-<span class="st"> </span><span class="kw">ifelse</span>(gg05e1<span class="op">$</span>condition <span class="op">==</span><span class="st"> &quot;objgap&quot;</span>, <span class="dv">1</span>, </a>
<a class="sourceLine" id="cb201-5" data-line-number="5">  <span class="dv">-1</span>)</a>
<a class="sourceLine" id="cb201-6" data-line-number="6">gg05e1<span class="op">$</span>logrt &lt;-<span class="st"> </span><span class="kw">log</span>(gg05e1<span class="op">$</span>rawRT)</a></code></pre></div>
<p>Recall that these data have multiple measurements from each subject for each condition:</p>
<div class="sourceCode" id="cb202"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb202-1" data-line-number="1"><span class="kw">t</span>(<span class="kw">xtabs</span>(<span class="op">~</span>subject <span class="op">+</span><span class="st"> </span>condition, gg05e1))</a></code></pre></div>
<pre><code>##          subject
## condition 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18
##   objgap  8 8 8 8 8 8 8 8 8  8  8  8  8  8  8  8  8  8
##   subjgap 8 8 8 8 8 8 8 8 8  8  8  8  8  8  8  8  8  8
##          subject
## condition 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33
##   objgap   8  8  8  8  8  8  8  8  8  8  8  8  8  8  8
##   subjgap  8  8  8  8  8  8  8  8  8  8  8  8  8  8  8
##          subject
## condition 34 35 36 37 38 39 40 41 42
##   objgap   8  8  8  8  8  8  8  8  8
##   subjgap  8  8  8  8  8  8  8  8  8</code></pre>
<p>We can visualize the different responses of subjects:</p>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="Freq_CogSci_files/figure-html/unnamed-chunk-90-1.svg" width="672" /></p>
<p>It’s clear that different subjects have different effects of the relative clause manipulation: some slopes are positive sloping, some are flat, and some are negatively sloping. There is between-subject variability in the relative clause effect.</p>
<p>Given these differences between subjects, you could fit a separate linear model for each subject, collect together the intercepts and slopes for each subject, and then check if the slopes are significantly different from zero. There is a function in the package  that computes separate linear models for each subject: <em>lmList</em>.</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb205-1" data-line-number="1"><span class="kw">library</span>(lme4)</a>
<a class="sourceLine" id="cb205-2" data-line-number="2"></a>
<a class="sourceLine" id="cb205-3" data-line-number="3">lmlist.fm1 &lt;-<span class="st"> </span><span class="kw">lmList</span>(logrt <span class="op">~</span><span class="st"> </span>so <span class="op">|</span><span class="st"> </span>subject, gg05e1)</a></code></pre></div>
<p>One can extract the intercept and slope estimates for each subject. For example, for subject 1:</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb206-1" data-line-number="1">lmlist.fm1<span class="op">$</span><span class="st">`</span><span class="dt">1</span><span class="st">`</span><span class="op">$</span>coefficients</a></code></pre></div>
<pre><code>## (Intercept)          so 
##     5.76962     0.04352</code></pre>
<p>One can plot the individual lines for each subject, as well as the fit of a simple linear model m0 for all the data taken together; this will show how each subject deviates in intercept and slope from the model m0’s intercept and slope.</p>
<p><img src="Freq_CogSci_files/figure-html/unnamed-chunk-93-1.svg" width="672" /></p>
<p>To find out if there is an effect of relative clause type, we simply need to check whether the slopes of the individual subjects’ fitted lines taken together are significantly different from zero. A one-sample t-test will achieve this:</p>
<div class="sourceCode" id="cb208"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb208-1" data-line-number="1"><span class="kw">t.test</span>(<span class="kw">coef</span>(lmlist.fm1)[<span class="dv">2</span>])</a></code></pre></div>
<pre><code>## 
## 	One Sample t-test
## 
## data:  coef(lmlist.fm1)[2]
## t = 2.8, df = 41, p-value = 0.008
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  0.01745 0.10658
## sample estimates:
## mean of x 
##   0.06202</code></pre>
<p>The above test is <em>exactly</em> the same as the paired t-test and the varying intercepts linear mixed model that we fit in the last chapter using the by-subject aggregated data:</p>
<div class="sourceCode" id="cb210"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb210-1" data-line-number="1">bysubj &lt;-<span class="st"> </span><span class="kw">aggregate</span>(<span class="kw">log</span>(rawRT) <span class="op">~</span><span class="st"> </span>subject <span class="op">+</span><span class="st"> </span>condition, </a>
<a class="sourceLine" id="cb210-2" data-line-number="2">  mean, <span class="dt">data =</span> gg05e1)</a>
<a class="sourceLine" id="cb210-3" data-line-number="3"></a>
<a class="sourceLine" id="cb210-4" data-line-number="4"><span class="kw">colnames</span>(bysubj)[<span class="dv">3</span>] &lt;-<span class="st"> &quot;logrt&quot;</span></a>
<a class="sourceLine" id="cb210-5" data-line-number="5"></a>
<a class="sourceLine" id="cb210-6" data-line-number="6"><span class="kw">t.test</span>(logrt <span class="op">~</span><span class="st"> </span>condition, bysubj, <span class="dt">paired =</span> <span class="ot">TRUE</span>)<span class="op">$</span>statistic</a></code></pre></div>
<pre><code>##    t 
## 2.81</code></pre>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb212-1" data-line-number="1"><span class="co">## compare with linear mixed model:</span></a>
<a class="sourceLine" id="cb212-2" data-line-number="2"><span class="kw">summary</span>(<span class="kw">lmer</span>(logrt <span class="op">~</span><span class="st"> </span>condition <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>subject), bysubj))<span class="op">$</span>coefficients[<span class="dv">2</span>, </a>
<a class="sourceLine" id="cb212-3" data-line-number="3">  ]</a></code></pre></div>
<pre><code>##   Estimate Std. Error    t value 
##   -0.12403    0.04414   -2.81021</code></pre>
<p>The above lmList model we just fit is called <em>repeated measures regression</em>. We now look at how to model unaggregated data using the linear mixed model. Incidentally, this repeated measures regression model is now only of historical interest, and useful only for understanding the linear mixed model, which is the modern standard approach.</p>
<p>We turn next to three main types of linear mixed model; other variants will be introduced in later chapters.</p>
<div id="model-type-1-varying-intercepts" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Model type 1: Varying intercepts</h3>
<p>The <em>linear mixed model</em> does something related to the above by-subject fits, but with some crucial twists, as we see below.
In the model shown below, the statement</p>
<p><span class="math display">\[\begin{equation}
(1 \mid \hbox{subject}) 
\end{equation}\]</span></p>
<p>adjusts the grand mean estimates of the intercept by a term (a number) for each subject.</p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb214-1" data-line-number="1">m0.lmer &lt;-<span class="st"> </span><span class="kw">lmer</span>(logrt <span class="op">~</span><span class="st"> </span>so <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">|</span><span class="st"> </span>subject), gg05e1)</a></code></pre></div>
<p>Notice that we did not aggregate the data.</p>
<p>Here is the abbreviated output:</p>
<pre><code>Random effects:
 Groups   Name        Variance Std.Dev.
 subject  (Intercept) 0.09983  0.3160  
 Residual             0.14618  0.3823  
Number of obs: 672, groups:  subject, 42

Fixed effects:
            Estimate Std. Error t value
(Intercept)  5.88306    0.05094 115.497
so           0.06202    0.01475   4.205</code></pre>
<p>One thing to notice is that the coefficients (intercept and slope) of the fixed effects of the above model are identical to those in the linear model <code>m0</code> above. What is different between the linear model and the linear mixed model is the standard error. In the latter, the standard error is determined by more than one source of variance, as we explain below.</p>
<p>The intercept adjustments for each subject can be viewed by typing:</p>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb216-1" data-line-number="1"><span class="co">## first 10 subjects&#39; intercept adjustments:</span></a>
<a class="sourceLine" id="cb216-2" data-line-number="2"><span class="kw">ranef</span>(m0.lmer)<span class="op">$</span>subject[, <span class="dv">1</span>][<span class="dv">1</span><span class="op">:</span><span class="dv">10</span>]</a></code></pre></div>
<pre><code>##  [1] -0.103928  0.077195 -0.230621  0.234198  0.008828
##  [6] -0.095363 -0.205571 -0.155371  0.075944 -0.364367</code></pre>
<p>Here is another way to summarize the adjustments to the grand mean intercept by subject. The error bars represent 95% confidence intervals.</p>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb218-1" data-line-number="1"><span class="kw">library</span>(lattice)</a>
<a class="sourceLine" id="cb218-2" data-line-number="2"><span class="kw">print</span>(<span class="kw">dotplot</span>(<span class="kw">ranef</span>(m0.lmer, <span class="dt">condVar =</span> <span class="ot">TRUE</span>)))</a></code></pre></div>
<pre><code>## $subject</code></pre>
<p><img src="Freq_CogSci_files/figure-html/unnamed-chunk-98-1.svg" width="672" /></p>
</div>
<div id="the-formal-statement-of-the-varying-intercepts-model" class="section level3">
<h3><span class="header-section-number">3.5.2</span> The formal statement of the varying intercepts model</h3>
<p>The model <code>m0.lmer</code> above prints out the following type of linear model. <span class="math inline">\(i\)</span> indexes subject, and <span class="math inline">\(j\)</span> indexes items.</p>
<p>Once we know the subject id and the item id, we know which subject saw which condition:</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb220-1" data-line-number="1"><span class="kw">subset</span>(gg05e1, subject <span class="op">==</span><span class="st"> </span><span class="dv">1</span> <span class="op">&amp;</span><span class="st"> </span>item <span class="op">==</span><span class="st"> </span><span class="dv">1</span>)</a></code></pre></div>
<pre><code>##   subject item condition rawRT so logrt
## 6       1    1    objgap   320  1 5.768</code></pre>
<p>The mathematical form of the linear mixed model is:</p>
<p><span class="math display">\[\begin{equation}
y_{ij} = \beta_0 + u_{0i}+\beta_1\times so_{ij} + \varepsilon_{ij}
\end{equation}\]</span></p>
<p>The <em>only</em> new thing here beyond the linear model we saw earlier is the by-subject adjustment to the intercept. These by-subject adjustments to the intercept <span class="math inline">\(u_{0i}\)</span> are assumed by lmer to come from a normal distribution centered around 0:</p>
<p><span class="math display">\[\begin{equation}
u_{0i} \sim Normal(0,\sigma_{u0})
\end{equation}\]</span></p>
<p>The ordinary linear model m0 has one intercept <span class="math inline">\(\beta_0\)</span> for all subjects, whereas this linear mixed model with varying intercepts <code>m0.lmer</code> has a different intercept (<span class="math inline">\(\beta_0 + u_{0i}\)</span>) for each subject <span class="math inline">\(i\)</span>.</p>
<p>We can visualize the adjustments for each subject to the intercepts as shown below.</p>
<p><img src="Freq_CogSci_files/figure-html/unnamed-chunk-100-1.svg" width="672" /></p>
<p>An important point is that in this model there are two variance components or sources of variance (cf. the linear model, which had only one):</p>
<ul>
<li><span class="math inline">\(u_0 \sim Normal(0,\sigma_{u0})\)</span></li>
<li><span class="math inline">\(\varepsilon \sim Normal(0,\sigma)\)</span></li>
</ul>
<p>These two standard deviations determine the standard error of the <span class="math inline">\(\beta_1\)</span> slope parameter.</p>
</div>
<div id="model-type-2-varying-intercepts-and-slopes-without-a-correlation" class="section level3">
<h3><span class="header-section-number">3.5.3</span> Model type 2: Varying intercepts and slopes, without a correlation</h3>
<p>Unlike the figure associated with the <code>lmlist.fm1</code> model above, which also involves fitting separate models for each subject, the model <code>m0.lmer</code> assumes <em>different intercepts</em> for each subject <em>but the same slope</em>.</p>
<p>We can choose to fit different intercepts as well as different slopes for each subject. To achieve this, assume now that each subject’s slope is also adjusted by subject:</p>
<p><span class="math display">\[\begin{equation}
y_{ij} = \beta_0 + u_{0i}+(\beta_1+u_{1i})\times so_{ij} + \varepsilon_{ij}
\end{equation}\]</span></p>
<p>That is, we additionally assume that <span class="math inline">\(u_{1i} \sim Normal(0,\sigma_{u1})\)</span>. The <code>lmer</code> notation for fitting separate intercepts and slopes is <code>(1+so||subject)</code>. We will just explain what the double vertical bars represent.</p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb222-1" data-line-number="1">m1.lmer &lt;-<span class="st"> </span><span class="kw">lmer</span>(logrt <span class="op">~</span><span class="st"> </span>so <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>so <span class="op">||</span><span class="st"> </span>subject), gg05e1)</a></code></pre></div>
<p>The output of this model will now show that there are not two but three sources of variability. These are:</p>
<ul>
<li><span class="math inline">\(u_0 \sim Normal(0,\sigma_{u0})\)</span></li>
<li><span class="math inline">\(u_1 \sim Normal(0,\sigma_{u1})\)</span></li>
<li><span class="math inline">\(\varepsilon \sim Normal(0,\sigma)\)</span></li>
</ul>
<p>In particular, the model estimates the following standard deviations:</p>
<ul>
<li><span class="math inline">\(\hat\sigma_{u0}=0.317\)</span></li>
<li><span class="math inline">\(\hat\sigma_{u0}=0.110\)</span></li>
<li><span class="math inline">\(\hat\sigma = 0.365\)</span>.</li>
</ul>
<pre><code>Random effects:
 Groups    Name        Variance Std.Dev.
 subject   (Intercept) 0.1006   0.317   
 subject.1 so          0.0121   0.110   
 Residual              0.1336   0.365   
Number of obs: 672, groups:  subject, 42

Fixed effects:
            Estimate Std. Error t value
(Intercept)   5.8831     0.0509  115.50
so            0.0620     0.0221    2.81</code></pre>
<p>These fits for each subject are visualized below (the gray line shows the model with a single intercept and slope, i.e., our old model <code>m0</code>):</p>
<p><img src="Freq_CogSci_files/figure-html/unnamed-chunk-102-1.svg" width="672" /></p>
<div id="comparing-lmlist-model-with-the-varying-intercepts-model" class="section level4">
<h4><span class="header-section-number">3.5.3.1</span> Comparing lmList model with the varying intercepts model</h4>
<p>Compare this model with the <code>lmlist.fm1</code> model we fitted earlier:</p>
<p><img src="Freq_CogSci_files/figure-html/unnamed-chunk-103-1.svg" width="672" /></p>
<p>What is striking is that each subject’s estimated best fit line is “smooothed out” compared to the lmList fits. This aspect of the linear mixed model is called shrinkage; we return to this point presently.</p>
</div>
<div id="visualizing-random-effects" class="section level4">
<h4><span class="header-section-number">3.5.3.2</span> Visualizing random effects</h4>
<p>As before, it is instructive to visualize the individual level adjustments to the intercept and slope:</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb224-1" data-line-number="1"><span class="kw">print</span>(<span class="kw">dotplot</span>(<span class="kw">ranef</span>(m1.lmer, <span class="dt">condVar =</span> <span class="ot">TRUE</span>)))</a></code></pre></div>
<pre><code>## $subject</code></pre>
<p><img src="Freq_CogSci_files/figure-html/unnamed-chunk-104-1.svg" width="672" /></p>
<p>What this is showing is wide variability in the mean reading times between subjects, but very little variation in the slope between subjects.</p>
</div>
<div id="the-formal-statement-of-varying-intercepts-and-varying-slopes-linear-mixed-model" class="section level4">
<h4><span class="header-section-number">3.5.3.3</span> The formal statement of varying intercepts and varying slopes linear mixed model</h4>
<p>Here is the full statement of the varying intercept and slopes model. Again, i indexes subjects, j items.</p>
<p><span class="math display">\[\begin{equation}
y_{ij} = \beta_0 + u_{0i}+(\beta_1+u_{1i})\times so_{ij} + \varepsilon_{ij}
\end{equation}\]</span></p>
<p>As mentioned before, there are now three variance components:</p>
<ul>
<li><span class="math inline">\(u_0 \sim Normal(0,\sigma_{u0})\)</span></li>
<li><span class="math inline">\(u_1 \sim Normal(0,\sigma_{u1})\)</span></li>
<li><span class="math inline">\(\varepsilon \sim Normal(0,\sigma)\)</span></li>
</ul>
</div>
<div id="crossed-random-effects-for-subjects-and-for-items" class="section level4">
<h4><span class="header-section-number">3.5.3.4</span> Crossed random effects for subjects and for items</h4>
<p>Now, one interesting fact about the varying intercepts and slopes model is that it doesn’t capture all the sources of variance yet. The items also contribute sources of variance: just like subjects, items may also have different intercepts and slopes.</p>
<p>Notice that subjects and items are fully crossed: each subject sees each item once.</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb226-1" data-line-number="1"><span class="kw">head</span>(<span class="kw">xtabs</span>(<span class="op">~</span>subject <span class="op">+</span><span class="st"> </span>item, gg05e1))</a></code></pre></div>
<pre><code>##        item
## subject 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
##       1 1 1 1 1 1 1 1 1 1  1  1  1  1  1  1  1
##       2 1 1 1 1 1 1 1 1 1  1  1  1  1  1  1  1
##       3 1 1 1 1 1 1 1 1 1  1  1  1  1  1  1  1
##       4 1 1 1 1 1 1 1 1 1  1  1  1  1  1  1  1
##       5 1 1 1 1 1 1 1 1 1  1  1  1  1  1  1  1
##       6 1 1 1 1 1 1 1 1 1  1  1  1  1  1  1  1</code></pre>
<p>Linear mixed model with crossed subject and items random effects can be defined with the following syntax:</p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb228-1" data-line-number="1">m2.lmer &lt;-<span class="st"> </span><span class="kw">lmer</span>(logrt <span class="op">~</span><span class="st"> </span>so <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>so <span class="op">||</span><span class="st"> </span>subject) <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb228-2" data-line-number="2"><span class="st">  </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>so <span class="op">||</span><span class="st"> </span>item), gg05e1)</a></code></pre></div>
<p>Analogously to the preceding example, now there are five variance components:</p>
<pre><code>Random effects:
 Groups    Name        Variance Std.Dev.
 subject   (Intercept) 0.10090  0.3177  
 subject.1 so          0.01224  0.1106  
 item      (Intercept) 0.00127  0.0356  
 item.1    so          0.00162  0.0402  
 Residual              0.13063  0.3614  
Number of obs: 672, groups:  subject, 42; item, 16

Fixed effects:
            Estimate Std. Error t value
(Intercept)   5.8831     0.0517  113.72
so            0.0620     0.0242    2.56</code></pre>
<p>The item intercept and slope adjustments can be visualized as well. Notice that there is a lot less item-level variation; this is often the case in planned experiments like this one, where the experimental items are carefully constructed to vary as little as possible.</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb230-1" data-line-number="1"><span class="kw">print</span>(<span class="kw">dotplot</span>(<span class="kw">ranef</span>(m2.lmer, <span class="dt">condVar =</span> <span class="ot">TRUE</span>))<span class="op">$</span>item)</a></code></pre></div>
<p><img src="Freq_CogSci_files/figure-html/unnamed-chunk-107-1.svg" width="672" /></p>
<p>One thing missing in the above models is any assumption about the relationship between the intercept and slope adjustements by subject and by item. It is possible that the intercept and slope adjustments are correlated: e.g., there could be a theoretical prediction that says that the slower a subject’s average reading time, the larger the difference between object and subject relative clause reading times. This kind of prediction can be tested by testing what the correlation is between the varying intercepts and slopes. We turn to this model next.</p>
</div>
</div>
<div id="model-type-3-varying-intercepts-and-varying-slopes-with-correlation" class="section level3">
<h3><span class="header-section-number">3.5.4</span> Model type 3: Varying intercepts and varying slopes, with correlation</h3>
<p>A correlation can be introduced between the intercept and slope adjustments by using a single vertical bar instead of two vertical bars in the random effects structure:</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb231-1" data-line-number="1">m3.lmer &lt;-<span class="st"> </span><span class="kw">lmer</span>(logrt <span class="op">~</span><span class="st"> </span>so <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>so <span class="op">|</span><span class="st"> </span>subject) <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb231-2" data-line-number="2"><span class="st">  </span>so <span class="op">|</span><span class="st"> </span>item), gg05e1)</a></code></pre></div>
<pre><code>## boundary (singular) fit: see ?isSingular</code></pre>
<p>To understand what this model is doing, we have to recall what a bivariate/multivariate distribution is.</p>
<pre><code>Random effects:
 Groups   Name        Variance Std.Dev. Corr
 subject  (Intercept) 0.10103  0.3178       
          so          0.01228  0.1108   0.58
 item     (Intercept) 0.00172  0.0415       
          so          0.00196  0.0443   1.00 &lt;= degeneracy
 Residual             0.12984  0.3603       
Number of obs: 672, groups:  subject, 42; item, 16

Fixed effects:
            Estimate Std. Error t value
(Intercept)   5.8831     0.0520  113.09
so            0.0620     0.0247    2.51</code></pre>
<p>The correlations (0.58 and 1.00) you see in the model output below are the correlations between the varying intercepts and slopes for subjects and for items. Notice that the variance covariance matrix for items is degenerate: its correlation is 1. This matrix cannot be inverted.</p>
<p>When the correlation is +1 or -1 or near these numbers, this means that the optimizer in lme4 is unable to estimate the correlation parameter, usually due to there not being enough data. If you are in such a situation, you are better off not trying to estimate this parameter with the data you have, and instead fitting one of the simpler models. We will return to this point when discussing model selection. For further discussion, see <span class="citation">Barr et al. (<a href="#ref-barr2013">2013</a>)</span>, <span class="citation">Bates et al. (<a href="#ref-BatesEtAlParsimonious">2015</a>)</span>, and <span class="citation">Matuschek et al. (<a href="#ref-hannesBEAP">2017</a>)</span>.</p>
<div id="formal-statement-of-varying-intercepts-and-varying-slopes-linear-mixed-model-with-correlation" class="section level4">
<h4><span class="header-section-number">3.5.4.1</span> Formal statement of varying intercepts and varying slopes linear mixed model with correlation</h4>
<p>As usual, i indexes subjects, j items. The vector <code>so</code> is the sum-coded factor levels: +1 for object relatives and -1 for subject relatives. The only new thing in this model is the item-level effects, and the specification of the variance-covariance matrix for subjects and items, in order to include the correlation parameters.</p>
<p><span class="math display">\[\begin{equation}
y_{ij} = \alpha + u_{0i} + w_{0j} + (\beta + u_{1i} + w_{1j}) \times so_{ij} + \varepsilon_{ij}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\varepsilon_{ij} \sim Normal(0,\sigma)\)</span> and</p>
<p><span class="math display">\[\begin{equation}\label{eq:covmatLM}
\Sigma_u
=
\begin{pmatrix}
\sigma _{u0}^2  &amp; \rho _{u}\sigma _{u0}\sigma _{u1}\\
\rho _{u}\sigma _{u0}\sigma _{u1}    &amp; \sigma _{u1}^2\\
\end{pmatrix}
\quad 
\Sigma _w
=
\begin{pmatrix}
\sigma _{w0}^2  &amp; \rho _{w}\sigma _{w0}\sigma _{w1}\\
\rho _{w}\sigma _{w0}\sigma _{w1}    &amp; \sigma _{w1}^2\\
\end{pmatrix}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}\label{eq:jointpriordistLM}
\begin{pmatrix}
  u_0 \\ 
  u_1 \\
\end{pmatrix}
\sim 
\mathcal{N} \left(
\begin{pmatrix}
  0 \\
  0 \\
\end{pmatrix},
\Sigma_{u}
\right),
\quad
\begin{pmatrix}
  w_0 \\ 
  w_1 \\
\end{pmatrix}
\sim 
\mathcal{N}\left(
\begin{pmatrix}
  0 \\
  0 \\
\end{pmatrix},
\Sigma_{w}
\right)
\end{equation}\]</span></p>
</div>
<div id="visualizing-the-random-effects" class="section level4">
<h4><span class="header-section-number">3.5.4.2</span> Visualizing the random effects</h4>
<p>One can visualize the correlation between intercepts and slopes by subjects. The positive correlation of 0.58 between subject intercept and slope adjustments implies that slower subjects show larger effects. However, the dotplot below doesn’t show a convincing pattern:</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb234-1" data-line-number="1"><span class="kw">print</span>(<span class="kw">dotplot</span>(<span class="kw">ranef</span>(m3.lmer, <span class="dt">condVar =</span> <span class="ot">TRUE</span>))<span class="op">$</span>subject)</a></code></pre></div>
<p><img src="Freq_CogSci_files/figure-html/unnamed-chunk-109-1.svg" width="672" /></p>
<p>The correlation pattern is easier to see if we plot the slope adjustments against the intercept adjustments.</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb235-1" data-line-number="1"><span class="kw">plot</span>(<span class="kw">ranef</span>(m3.lmer)<span class="op">$</span>subject[, <span class="dv">1</span>], <span class="kw">ranef</span>(m3.lmer)<span class="op">$</span>subject[, </a>
<a class="sourceLine" id="cb235-2" data-line-number="2">  <span class="dv">2</span>], <span class="dt">xlab =</span> <span class="st">&quot;Intercept adjustments (subject)&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;Slope adjustments&quot;</span>)</a></code></pre></div>
<p><img src="Freq_CogSci_files/figure-html/unnamed-chunk-110-1.svg" width="672" /></p>
<p>When we talk about hypothesis testing, we will look at what inferences we can draw from this correlation.</p>
<p>The dotplot showing the item-level effects shows a perfect correlation between intercept and slope adjustments, but as mentioned above these are from a degenerate variance covariance matrix and not meaningful.</p>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb236-1" data-line-number="1"><span class="kw">print</span>(<span class="kw">dotplot</span>(<span class="kw">ranef</span>(m3.lmer, <span class="dt">condVar =</span> <span class="ot">TRUE</span>))<span class="op">$</span>item)</a></code></pre></div>
<p><img src="Freq_CogSci_files/figure-html/unnamed-chunk-111-1.svg" width="672" /></p>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-barr2013">
<p>Barr, Dale J, Roger Levy, Christoph Scheepers, and Harry J Tily. 2013. “Random Effects Structure for Confirmatory Hypothesis Testing: Keep It Maximal.” <em>Journal of Memory and Language</em> 68 (3). Elsevier: 255–78.</p>
</div>
<div id="ref-BatesEtAlParsimonious">
<p>Bates, Douglas M., Reinhold Kliegl, Shravan Vasishth, and Harald Baayen. 2015. “Parsimonious Mixed Models.”</p>
</div>
<div id="ref-hannesBEAP">
<p>Matuschek, Hannes, Reinhold Kliegl, Shravan Vasishth, R. Harald Baayen, and Douglas M. Bates. 2017. “Balancing Type I Error and Power in Linear Mixed Models.” <em>Journal of Memory and Language</em> 94: 305–15. <a href="https://doi.org/10.1016/j.jml.2017.01.001">https://doi.org/10.1016/j.jml.2017.01.001</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="from-the-paired-t-test-to-the-linear-mixed-model.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="shrinkage-in-linear-mixed-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook/js/app.min.js"></script>
<script src="libs/gitbook/js/lunr.js"></script>
<script src="libs/gitbook/js/clipboard.min.js"></script>
<script src="libs/gitbook/js/plugin-search.js"></script>
<script src="libs/gitbook/js/plugin-sharing.js"></script>
<script src="libs/gitbook/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook/js/plugin-bookdown.js"></script>
<script src="libs/gitbook/js/jquery.highlight.js"></script>
<script src="libs/gitbook/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown/edit/master/inst/examples/03-LinearModels.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Freq_CogSci.pdf", "Freq_CogSci.epub", "Freq_CogSci.mobi"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
